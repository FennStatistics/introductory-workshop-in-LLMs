{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7102c40",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "\n",
    "\n",
    "**Information**\n",
    "\n",
    "**Tech Concept Generator**: Utilize LLMs to identify potential application scenarios for the \"Soft Robotic Walker\" (SRW) considering various combinations of options (highlighted in red).\n",
    "\n",
    "\n",
    "\n",
    "*** \n",
    "**Background information**\n",
    "\n",
    "* Conceptualization of current study with the demonstrator area in livmats.\n",
    "\n",
    "\n",
    "***\n",
    "**Coding sources**\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "**Aim of the code template**\n",
    "\n",
    "Utilize LLMs to identify potential application scenarios for the \"Soft Robotic Walker\" (SRW) considering various combinations of options (highlighted in red on the slide)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3711c0b",
   "metadata": {},
   "source": [
    "## Get API key(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f150b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Assuming 'src' is one level down (in the current directory or a subdirectory)\n",
    "path_to_src = os.path.join('../..','src')  # Moves one level down to 'src' folder\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(path_to_src)\n",
    "\n",
    "# Now you can import your API_key module\n",
    "import API_key as key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b15886",
   "metadata": {},
   "source": [
    "# Tech Concept Generator\n",
    "\n",
    "## set up table of all possible combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed11da9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "   ID                                   researchQuestion  \\\n",
      "0   0  Ergonomic Tool Design and Assessment: How do u...   \n",
      "1   1  Ergonomic Tool Design and Assessment: How do u...   \n",
      "2   2  Force Perception and Haptic Feedback Studies: ...   \n",
      "3   3  Force Perception and Haptic Feedback Studies: ...   \n",
      "4   4  Stress and Cognitive Load Evaluation: How do v...   \n",
      "5   5  Stress and Cognitive Load Evaluation: How do v...   \n",
      "6   6  Intuitive Control and Feedback Interfaces: How...   \n",
      "7   7  Intuitive Control and Feedback Interfaces: How...   \n",
      "8   8  Social Acceptance of Robotic Systems: How do f...   \n",
      "9   9  Social Acceptance of Robotic Systems: How do f...   \n",
      "\n",
      "                                         studyDesign  \n",
      "0  Within-Subjects Design: Test each participant ...  \n",
      "1  Between-Subjects Design: Assign participants t...  \n",
      "2  Within-Subjects Design: Test each participant ...  \n",
      "3  Between-Subjects Design: Assign participants t...  \n",
      "4  Within-Subjects Design: Test each participant ...  \n",
      "5  Between-Subjects Design: Assign participants t...  \n",
      "6  Within-Subjects Design: Test each participant ...  \n",
      "7  Between-Subjects Design: Assign participants t...  \n",
      "8  Within-Subjects Design: Test each participant ...  \n",
      "9  Between-Subjects Design: Assign participants t...  \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# Define lists for each variable\n",
    "#> Different Research Questions\n",
    "researchQuestions = [\n",
    "    'Ergonomic Tool Design and Assessment: How do user comfort, fatigue, and movement efficiency vary when interacting with ergonomically designed tools in simulated task scenarios?',\n",
    "    'Force Perception and Haptic Feedback Studies: How accurately can users perceive and differentiate forces and tactile feedback, and how does this perception influence task precision and performance in HRI?',\n",
    "    'Stress and Cognitive Load Evaluation: How do varying levels of physical and cognitive demands affect user performance, stress levels, and decision-making during human-robot interaction in complex tasks?',\n",
    "    'Intuitive Control and Feedback Interfaces: How effectively can laypersons adapt to and operate robotic systems using intuitive control and feedback interfaces, and what factors influence their performance and ease of use?',\n",
    "    'Social Acceptance of Robotic Systems: How do familiarity, experience, and robot behavior influence user trust, acceptance, and perceived usability of robotic systems in interactive tasks?',\n",
    "]\n",
    "studyDesigns = [\n",
    "    'Within-Subjects Design: Test each participant under multiple conditions, such as different levels of force feedback, task complexity, or robot responsiveness. This reduces individual variability.',\n",
    "    'Between-Subjects Design: Assign participants to distinct groups to test the effect of different interaction modalities (e.g., with/without VR, various haptic feedback levels).'\n",
    "]\n",
    "\n",
    "\n",
    "# Generate Cartesian product\n",
    "product = list(itertools.product(researchQuestions, studyDesigns))\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(product, columns=['researchQuestion', 'studyDesign'])\n",
    "\n",
    "# Add an ID column based on row index\n",
    "df['ID'] = df.index\n",
    "\n",
    "# Move ID column to the front\n",
    "df = df[['ID', 'researchQuestion', 'studyDesign']]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196634b1",
   "metadata": {},
   "source": [
    "## set up prompt templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90781bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_template_invoked:\n",
      "\n",
      "<Context>\n",
      "You are an advanced AI designed to generate innovative technological application scenarios for a Human-Robot Interaction (HRI) system.\n",
      "The system integrates multiple components to create an immersive and interactive experimental platform. The key components of the setup are as follows:\n",
      "\n",
      "1. **End Effector**: The robotic arm is equipped with a 6D shaker, enabling precise motion and force application in six degrees of freedom (translation along X, Y, Z axes, and rotation about these axes: pitch, yaw, roll).\n",
      "2. **Human Interface**: Participants interact with the system via an ergonomic hand grip designed to mimic the shape and functionality of a power tool handle.\n",
      "3. **Force Sensor**: A force sensor is installed between the hand grip and the shaker to measure real-time forces exerted during interaction.\n",
      "4. **Motion Tracking**: The Vicon system is used to capture precise movements of the participant and the setup, enabling detailed analysis of interaction dynamics.\n",
      "5. **Immersive Feedback**: Participants wear a VR headset to receive visual cues and experience simulated environments that enhance task immersion.\n",
      "\n",
      "Your task is to generate application scenarios for this HRI system based on a combination of a **Research Question (RQ)** and a **Study Design**. The RQ specifies the goal of the study, while the Study Design outlines how the study is structured. \n",
      "\n",
      "The Research Question is:\n",
      "Ergonomic Tool Design and Assessment: How do user comfort, fatigue, and movement efficiency vary when interacting with ergonomically designed tools in simulated task scenarios?\n",
      "\n",
      "The Study Designs is:\n",
      "Within-Subjects Design: Test each participant under multiple conditions, such as different levels of force feedback, task complexity, or robot responsiveness. This reduces individual variability.\n",
      "\n",
      "Think creatively and ensure the application scenarios leverage the unique features of this HRI system to address the selected Research Question. Ensure the proposed application aligns with the selected Study Design and integrates the system's components effectively.\n",
      "</Context>\n",
      "\n",
      "\n",
      "user_template_invoked:\n",
      "\n",
      "<Task>\n",
      "Generate one detailed application scenario for the described HRI system. The scenario should be specific, feasible, and clearly illustrate how the system's components are utilized in a real-world or innovative setting. \n",
      "\n",
      "Here is an example format for the scenario output:\n",
      "\n",
      "**Application Scenario**: [Detailed explanation of how the components of the system are utilized together to address a particular task or challenge];\n",
      "\n",
      "Ensure that the scenario reflects thoughtful integration of the system's components and highlights their unique capabilities. The scenario should be realistic or conceptually sound and reflect a practical or innovative alignment with the system's capabilities.\n",
      "Only return the scenario output which must end with an \";\" and nothing else.\n",
      "</Task>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_template = \"\"\"\n",
    "<Context>\n",
    "You are an advanced AI designed to generate innovative technological application scenarios for a Human-Robot Interaction (HRI) system.\n",
    "The system integrates multiple components to create an immersive and interactive experimental platform. The key components of the setup are as follows:\n",
    "\n",
    "1. **End Effector**: The robotic arm is equipped with a 6D shaker, enabling precise motion and force application in six degrees of freedom (translation along X, Y, Z axes, and rotation about these axes: pitch, yaw, roll).\n",
    "2. **Human Interface**: Participants interact with the system via an ergonomic hand grip designed to mimic the shape and functionality of a power tool handle.\n",
    "3. **Force Sensor**: A force sensor is installed between the hand grip and the shaker to measure real-time forces exerted during interaction.\n",
    "4. **Motion Tracking**: The Vicon system is used to capture precise movements of the participant and the setup, enabling detailed analysis of interaction dynamics.\n",
    "5. **Immersive Feedback**: Participants wear a VR headset to receive visual cues and experience simulated environments that enhance task immersion.\n",
    "\n",
    "Your task is to generate application scenarios for this HRI system based on a combination of a **Research Question (RQ)** and a **Study Design**. The RQ specifies the goal of the study, while the Study Design outlines how the study is structured. \n",
    "\n",
    "The Research Question is:\n",
    "{researchQuestion}\n",
    "\n",
    "The Study Designs is:\n",
    "{studyDesign}\n",
    "\n",
    "Think creatively and ensure the application scenarios leverage the unique features of this HRI system to address the selected Research Question. Ensure the proposed application aligns with the selected Study Design and integrates the system's components effectively.\n",
    "</Context>\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"\"\"\n",
    "<Task>\n",
    "Generate one detailed application scenario for the described HRI system. The scenario should be specific, feasible, and clearly illustrate how the system's components are utilized in a real-world or innovative setting. \n",
    "\n",
    "Here is an example format for the scenario output:\n",
    "\n",
    "**Application Scenario**: [Detailed explanation of how the components of the system are utilized together to address a particular task or challenge];\n",
    "\n",
    "Ensure that the scenario reflects thoughtful integration of the system's components and highlights their unique capabilities. The scenario should be realistic or conceptually sound and reflect a practical or innovative alignment with the system's capabilities.\n",
    "Only return the scenario output which must end with an \";\" and nothing else.\n",
    "</Task>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Example invocation values for characteristics\n",
    "example_values = {\n",
    "    \"researchQuestion\": 'Ergonomic Tool Design and Assessment: How do user comfort, fatigue, and movement efficiency vary when interacting with ergonomically designed tools in simulated task scenarios?',\n",
    "    \"studyDesign\": 'Within-Subjects Design: Test each participant under multiple conditions, such as different levels of force feedback, task complexity, or robot responsiveness. This reduces individual variability.'\n",
    "}\n",
    "\n",
    "# Generate the output by invoking the templates\n",
    "system_template_filled = system_template.format(**example_values)\n",
    "user_template_filled = user_template\n",
    "\n",
    "print(\"system_template_invoked:\")\n",
    "print(system_template_filled)\n",
    "print(\"\\nuser_template_invoked:\")\n",
    "print(user_template_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d511921",
   "metadata": {},
   "source": [
    "## call LLMs to generate ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abebd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Row 0: ID 0\n",
      "Processing Row 1: ID 1\n",
      "Processing Row 2: ID 2\n",
      "Processing Row 3: ID 3\n",
      "Processing Row 4: ID 4\n",
      "Processing Row 5: ID 5\n",
      "Processing Row 6: ID 6\n",
      "Processing Row 7: ID 7\n",
      "Processing Row 8: ID 8\n",
      "Processing Row 9: ID 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Initialize the client (assuming the client and API key are already set up)\n",
    "client = InferenceClient(headers={\"X-use-cache\": \"false\"}, token=key.hugging_api_key)\n",
    "\n",
    "def get_application_scenario(system_template_invoked, user_template_invoked):\n",
    "    chat_completion = client.chat_completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_template_invoked},\n",
    "            {\"role\": \"user\", \"content\": user_template_invoked}\n",
    "        ],\n",
    "        model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "        temperature=0.6,\n",
    "        stream=False,\n",
    "        max_tokens=1400\n",
    "    )\n",
    "    return chat_completion\n",
    "\n",
    "def process_application_scenario(message_content, row):\n",
    "    # Use regex to find the application scenario\n",
    "    match = re.search(r'\\*\\*Application Scenario\\*\\*: (.*?;)', message_content, re.DOTALL)\n",
    "    application_scenario = message_content\n",
    "\n",
    "    if not match:\n",
    "        print('The provided message content does not contain a valid Application Scenario, the \"message_content\" is taken.')\n",
    "        # raise ValueError(\"The provided message content does not contain a valid 'Application Scenario'.\"\n",
    "        # application_scenario = match.group(1).strip()\n",
    "\n",
    "    # Extract the application scenario\n",
    "    \n",
    "\n",
    "    # Convert to DataFrame format and include row information\n",
    "    df_scenarios = pd.DataFrame({\n",
    "        \"application_scenario\": [application_scenario],\n",
    "        \"ID\": row['ID'],\n",
    "        \"researchQuestion\": row['researchQuestion'],\n",
    "        \"studyDesign\": row['studyDesign']\n",
    "    })\n",
    "\n",
    "    return df_scenarios\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "     # Print the current processing ID for tracking\n",
    "     print(f\"Processing Row {index}: ID {row['ID']}\")\n",
    "     \n",
    "     # Set up the system and user templates\n",
    "     system_template_invoked = system_template.format(\n",
    "         researchQuestion=row['researchQuestion'],\n",
    "         studyDesign=row['studyDesign']\n",
    "     )\n",
    "     \n",
    "     user_template_invoked = user_template  # The user template is static as it refers to the task format\n",
    "     \n",
    "     # Get the application scenario from the LLM\n",
    "     chat_completion = get_application_scenario(system_template_invoked, user_template_invoked)\n",
    "     \n",
    "     # Process the returned content into a DataFrame\n",
    "     scenario_df = process_application_scenario(chat_completion.choices[0].message.content, row)\n",
    "     \n",
    "     # Combine the result into a master DataFrame\n",
    "     if index == 0:\n",
    "         combined_df = scenario_df\n",
    "     else:\n",
    "         combined_df = pd.concat([combined_df, scenario_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126006ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Application Scenario**: \"Robot-Assisted Assembly Training in Virtual Reality\"; \\n\\nIn this application scenario, the HRI system is used to investigate the impact of robotic assistance, haptic feedback, and virtual reality on user trust, acceptance, and performance in an assembly task. Participants are assigned to one of three groups: a control group without robotic assistance, a group with robotic assistance but without haptic feedback, and a group with robotic assistance and haptic feedback. Each participant wears the VR headset and grasps the ergonomic hand grip, which is equipped with the force sensor to measure the forces exerted during interaction. The 6D shaker end effector is programmed to provide precise motion and force cues to assist the participant in the assembly task. The Vicon motion tracking system captures the movement of the participant and the robotic arm, allowing researchers to analyze the interaction dynamics and task performance.\\n\\nThe study consists of two phases: a familiarization phase, where participants interact with the system without robotic assistance, and an assembly phase, where participants complete an assembly task with or without robotic assistance. The VR environment is designed to simulate a real-world assembly scenario, with visual cues and instructions provided to the participant. The force sensor data and motion tracking data are synchronized with the VR environment data to provide a comprehensive understanding of the user\\'s experience and performance.\\n\\nBy analyzing the data from the different groups, researchers can investigate how familiarity, experience, and robot behavior influence user trust, acceptance, and perceived usability of robotic systems in interactive tasks, addressing the research question on social acceptance of robotic systems.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db436fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame with Application Scenarios:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_scenario</th>\n",
       "      <th>ID</th>\n",
       "      <th>researchQuestion</th>\n",
       "      <th>studyDesign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Application Scenario**: \"Ergonomic Tool Desi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ergonomic Tool Design and Assessment: How do u...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>**Application Scenario**: \"Ergonomic Power Too...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ergonomic Tool Design and Assessment: How do u...</td>\n",
       "      <td>Between-Subjects Design: Assign participants t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>**Application Scenario**: \"Virtual Assembly Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>Force Perception and Haptic Feedback Studies: ...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**Application Scenario**: \"Haptic Training Sim...</td>\n",
       "      <td>3</td>\n",
       "      <td>Force Perception and Haptic Feedback Studies: ...</td>\n",
       "      <td>Between-Subjects Design: Assign participants t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>**Application Scenario**: \"Assembly Task with ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Stress and Cognitive Load Evaluation: How do v...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>**Application Scenario**: Virtual Reality-Base...</td>\n",
       "      <td>5</td>\n",
       "      <td>Stress and Cognitive Load Evaluation: How do v...</td>\n",
       "      <td>Between-Subjects Design: Assign participants t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>**Application Scenario**: \"Intuitive Robotic A...</td>\n",
       "      <td>6</td>\n",
       "      <td>Intuitive Control and Feedback Interfaces: How...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>**Application Scenario**: \"VR-Assisted Robotic...</td>\n",
       "      <td>7</td>\n",
       "      <td>Intuitive Control and Feedback Interfaces: How...</td>\n",
       "      <td>Between-Subjects Design: Assign participants t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>**Application Scenario**: \"Robotic Assembly Ta...</td>\n",
       "      <td>8</td>\n",
       "      <td>Social Acceptance of Robotic Systems: How do f...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>**Application Scenario**: \"Robot-Assisted Asse...</td>\n",
       "      <td>9</td>\n",
       "      <td>Social Acceptance of Robotic Systems: How do f...</td>\n",
       "      <td>Between-Subjects Design: Assign participants t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                application_scenario  ID  \\\n",
       "0  **Application Scenario**: \"Ergonomic Tool Desi...   0   \n",
       "1  **Application Scenario**: \"Ergonomic Power Too...   1   \n",
       "2  **Application Scenario**: \"Virtual Assembly Tr...   2   \n",
       "3  **Application Scenario**: \"Haptic Training Sim...   3   \n",
       "4  **Application Scenario**: \"Assembly Task with ...   4   \n",
       "5  **Application Scenario**: Virtual Reality-Base...   5   \n",
       "6  **Application Scenario**: \"Intuitive Robotic A...   6   \n",
       "7  **Application Scenario**: \"VR-Assisted Robotic...   7   \n",
       "8  **Application Scenario**: \"Robotic Assembly Ta...   8   \n",
       "9  **Application Scenario**: \"Robot-Assisted Asse...   9   \n",
       "\n",
       "                                    researchQuestion  \\\n",
       "0  Ergonomic Tool Design and Assessment: How do u...   \n",
       "1  Ergonomic Tool Design and Assessment: How do u...   \n",
       "2  Force Perception and Haptic Feedback Studies: ...   \n",
       "3  Force Perception and Haptic Feedback Studies: ...   \n",
       "4  Stress and Cognitive Load Evaluation: How do v...   \n",
       "5  Stress and Cognitive Load Evaluation: How do v...   \n",
       "6  Intuitive Control and Feedback Interfaces: How...   \n",
       "7  Intuitive Control and Feedback Interfaces: How...   \n",
       "8  Social Acceptance of Robotic Systems: How do f...   \n",
       "9  Social Acceptance of Robotic Systems: How do f...   \n",
       "\n",
       "                                         studyDesign  \n",
       "0  Within-Subjects Design: Test each participant ...  \n",
       "1  Between-Subjects Design: Assign participants t...  \n",
       "2  Within-Subjects Design: Test each participant ...  \n",
       "3  Between-Subjects Design: Assign participants t...  \n",
       "4  Within-Subjects Design: Test each participant ...  \n",
       "5  Between-Subjects Design: Assign participants t...  \n",
       "6  Within-Subjects Design: Test each participant ...  \n",
       "7  Between-Subjects Design: Assign participants t...  \n",
       "8  Within-Subjects Design: Test each participant ...  \n",
       "9  Between-Subjects Design: Assign participants t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display or use the combined DataFrame\n",
    "print(\"Combined DataFrame with Application Scenarios:\")\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401f07c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Application Scenario**: Virtual Reality-Based Assembly Task with Varying Haptic Feedback and Cognitive Loads; \\n\\nIn this scenario, the HRI system is used to investigate how different levels of haptic feedback and cognitive demands impact user performance, stress levels, and decision-making during a complex assembly task. Participants are assigned to one of four groups in a between-subjects design: (1) high haptic feedback with complex instructions, (2) low haptic feedback with complex instructions, (3) high haptic feedback with simple instructions, and (4) low haptic feedback with simple instructions. \\n\\nThe task involves assembling a virtual robotic arm within a simulated environment displayed through the VR headset. The virtual arm consists of multiple components that require precise alignment and connection. The 6D shaker integrated into the robotic arm provides varying levels of haptic feedback, allowing participants to feel resistance, texture, or vibrations during the assembly process. The force sensor measures the forces exerted by the participant, while the motion tracking system captures the movements of the participant and the robotic arm.\\n\\nThe complex instructions group receives a set of detailed, step-by-step instructions with additional cognitive loads, such as mental math problems or memory recall tasks, to complete during the assembly process. In contrast, the simple instructions group receives concise, easy-to-follow instructions without additional cognitive loads.\\n\\nThe immersive feedback provided by the VR headset and the haptic feedback from the 6D shaker work together to create a realistic and engaging environment. The system's components are synchronized to provide a seamless and interactive experience, allowing researchers to analyze the impact of different interaction modalities on user performance, stress levels, and decision-making during complex tasks.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"application_scenario\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b01c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_excel(\"applicationScenarios_IPEK.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d987d9",
   "metadata": {},
   "source": [
    "## The “Stuff” Strategy (priotize)\n",
    "\n",
    "for within subject designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa107b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_scenario</th>\n",
       "      <th>ID</th>\n",
       "      <th>researchQuestion</th>\n",
       "      <th>studyDesign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Application Scenario**: \"Ergonomic Tool Desi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ergonomic Tool Design and Assessment: How do u...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>**Application Scenario**: \"Virtual Assembly Tr...</td>\n",
       "      <td>2</td>\n",
       "      <td>Force Perception and Haptic Feedback Studies: ...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>**Application Scenario**: \"Assembly Task with ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Stress and Cognitive Load Evaluation: How do v...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>**Application Scenario**: \"Intuitive Robotic A...</td>\n",
       "      <td>6</td>\n",
       "      <td>Intuitive Control and Feedback Interfaces: How...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>**Application Scenario**: \"Robotic Assembly Ta...</td>\n",
       "      <td>8</td>\n",
       "      <td>Social Acceptance of Robotic Systems: How do f...</td>\n",
       "      <td>Within-Subjects Design: Test each participant ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                application_scenario  ID  \\\n",
       "0  **Application Scenario**: \"Ergonomic Tool Desi...   0   \n",
       "2  **Application Scenario**: \"Virtual Assembly Tr...   2   \n",
       "4  **Application Scenario**: \"Assembly Task with ...   4   \n",
       "6  **Application Scenario**: \"Intuitive Robotic A...   6   \n",
       "8  **Application Scenario**: \"Robotic Assembly Ta...   8   \n",
       "\n",
       "                                    researchQuestion  \\\n",
       "0  Ergonomic Tool Design and Assessment: How do u...   \n",
       "2  Force Perception and Haptic Feedback Studies: ...   \n",
       "4  Stress and Cognitive Load Evaluation: How do v...   \n",
       "6  Intuitive Control and Feedback Interfaces: How...   \n",
       "8  Social Acceptance of Robotic Systems: How do f...   \n",
       "\n",
       "                                         studyDesign  \n",
       "0  Within-Subjects Design: Test each participant ...  \n",
       "2  Within-Subjects Design: Test each participant ...  \n",
       "4  Within-Subjects Design: Test each participant ...  \n",
       "6  Within-Subjects Design: Test each participant ...  \n",
       "8  Within-Subjects Design: Test each participant ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame to get rows with specific conditions\n",
    "filtered_df = combined_df[combined_df['studyDesign'] == \"Within-Subjects Design: Test each participant under multiple conditions, such as different levels of force feedback, task complexity, or robot responsiveness. This reduces individual variability.\"]\n",
    "\n",
    "# Combine the application_scenario texts\n",
    "scenario_list = \" \".join(filtered_df['application_scenario'].tolist())\n",
    "\n",
    "# Display the filtered DataFrame and the combined scenario text (optional)\n",
    "print(\"Filtered DataFrame:\")\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40abee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Application Scenarios:\n",
      "**Application Scenario**: \"Ergonomic Tool Design Optimization for Simulated Assembly Tasks\"; \n",
      "\n",
      "In this scenario, the HRI system is used to investigate how user comfort, fatigue, and movement efficiency vary when interacting with ergonomically designed tools in simulated assembly tasks. The study employs a within-subjects design, where each participant performs a series of assembly tasks under different conditions.\n",
      "\n",
      "The experiment begins with participants wearing the VR headset, which provides an immersive simulated environment of an assembly workspace. They are then asked to hold the ergonomic hand grip, which is equipped with the force sensor, and use it to manipulate virtual objects in the simulated environment. The 6D shaker, attached to the robotic arm, provides precise motion and force application, simulating the sensations of assembling parts.\n",
      "\n",
      "The Vicon motion tracking system captures the participant's movements and the motion of the robotic arm, allowing for detailed analysis of interaction dynamics. The force sensor measures the forces exerted by the participant during interaction, providing insights into user comfort and fatigue.\n",
      "\n",
      "The study consists of multiple conditions, including different levels of force feedback, task complexity, and robot responsiveness. For example, in one condition, the robotic arm may provide a high level of force feedback, simulating the sensation of assembling a heavy part. In another condition, the task complexity may be increased by adding more virtual objects to the assembly workspace.\n",
      "\n",
      "By analyzing the data collected from the HRI system, researchers can gain a deeper understanding of how ergonomic tool design affects user comfort, fatigue, and movement efficiency in simulated assembly tasks. This knowledge can be used to optimize the design of real-world assembly tools, improving the safety and efficiency of workers in manufacturing and other industries; **Application Scenario**: \"Virtual Assembly Training with Haptic Feedback\" - In this scenario, participants wear the VR headset and hold the ergonomic hand grip, interacting with a virtual assembly environment that requires precise placement of parts. The robotic arm's 6D shaker provides varying levels of force feedback to simulate the physical constraints of the assembly task, while the force sensor measures the participant's applied forces in real-time. The Vicon motion tracking system captures the participant's movements, allowing for detailed analysis of their interaction dynamics. The study employs a within-subjects design, testing each participant under multiple conditions: low, medium, and high levels of force feedback, as well as varying levels of task complexity (e.g., simple vs. complex assemblies). The system's immersive feedback and haptic cues enable researchers to investigate how accurately participants perceive and differentiate forces and tactile feedback, and how this perception influences task precision and performance in HRI. By analyzing the collected data, researchers can identify optimal levels of force feedback and task complexity for training scenarios, ultimately enhancing the effectiveness of virtual assembly training programs; **Application Scenario**: \"Assembly Task with Varying Force Feedback and Cognitive Demands\" - In this scenario, participants wear a VR headset and hold the ergonomic hand grip while interacting with a virtual assembly task on a workbench in a simulated factory environment. The task requires participants to use the robotic arm to assemble complex mechanical parts with varying levels of force feedback, simulating real-world assembly challenges. The 6D shaker applies different levels of resistance and vibrations to simulate the physical demands of the task, while the force sensor measures the participant's real-time force exertion. The Vicon system tracks the participant's and robotic arm's movements, allowing for detailed analysis of interaction dynamics. The VR environment is designed to induce varying levels of cognitive demands by introducing distractions, such as alarms, or requiring participants to follow complex assembly instructions. The study consists of multiple conditions, including different levels of force feedback (e.g., low, medium, high), task complexity (e.g., simple, complex), and robot responsiveness (e.g., fast, slow). Participants complete the task under each condition, and their performance, stress levels, and decision-making are evaluated through physiological measures, such as heart rate and skin conductance, and subjective feedback. The results provide insights into how varying physical and cognitive demands affect user performance and stress levels during human-robot interaction in complex tasks; **Application Scenario**: \"Intuitive Robotic Assembly Task\" - In this scenario, participants wear a VR headset and hold the ergonomic hand grip attached to the force sensor, which is connected to the 6D shaker on the robotic arm. The task is to assemble a virtual puzzle within the simulated environment, requiring precise movements and force application. The Vicon motion tracking system captures the participant's movements and the robotic arm's motion, allowing for detailed analysis of interaction dynamics. The study utilizes a within-subjects design, where each participant performs the assembly task under three conditions: (1) with high force feedback, (2) with low force feedback, and (3) with visual cues only. The force sensor measures the real-time forces exerted by the participant, and the 6D shaker provides the corresponding force feedback. The VR headset displays the virtual environment and provides visual cues, such as highlighting the correct assembly sequence. The study aims to investigate how different levels of force feedback influence the participant's performance and ease of use in completing the assembly task. By analyzing the data from the force sensor, motion tracking system, and participant feedback, the study can identify the optimal level of force feedback for intuitive control and feedback interfaces in robotic assembly tasks; **Application Scenario**: \"Robotic Assembly Task Simulator\" - In this within-subjects study, participants wear the VR headset and hold the ergonomic hand grip, interacting with a virtual robotic assembly task environment designed to assess the impact of robot behavior on user trust and acceptance. The 6D shaker end effector applies varying levels of force feedback, simulating the physical resistance and vibrations experienced during real-world robotic assembly tasks. Three conditions are designed: (1) low resistance and high robot responsiveness, (2) medium resistance and adaptive robot responsiveness, and (3) high resistance and low robot responsiveness. Participants perform a series of assembly tasks under each condition, while the force sensor measures the forces exerted and the Vicon motion tracking system captures the movements of the participant and the robotic arm. After each condition, participants complete a survey assessing their trust, acceptance, and perceived usability of the robotic system. The immersive feedback from the VR headset and the realistic force feedback from the 6D shaker enable participants to fully engage with the task, providing valuable insights into how robot behavior influences user trust and acceptance in interactive tasks;\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCombined Application Scenarios:\")\n",
    "print(scenario_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12091606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System and user template setup\n",
    "system_template = \"\"\"\n",
    "<Context>\n",
    "You are a helpful AI designed to **summarize innovative technological application scenarios for a Human-Robot Interaction (HRI) system**.\n",
    "The system integrates multiple components that enable immersive and interactive experimental platforms for HRI research. \n",
    "The components include:\n",
    "1. **End Effector**: A robotic arm equipped with a 6D shaker for precise motion and force application.\n",
    "2. **Human Interface**: An ergonomic hand grip designed to mimic a power tool handle for intuitive interaction.\n",
    "3. **Force Sensor**: Measures real-time forces exerted during user interaction.\n",
    "4. **Motion Tracking**: Uses the Vicon system to capture precise movements of participants and setup for interaction analysis.\n",
    "5. **Immersive Feedback**: Employs VR headsets to simulate environments and provide visual cues, enhancing user immersion.\n",
    "\n",
    "Your task is to summarize and prioritize application scenarios based on a list of detailed descriptions. \n",
    "The goal is to identify the most significant and recurring applications of the HRI system based on the provided scenarios.\n",
    "</Context>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_template = f\"\"\"\n",
    "<Task>\n",
    "Provide a prioritized list of possible applications for the described HRI system based on the following application scenarios. \n",
    "Start with the most critical and frequently mentioned applications, highlighting recurring themes and innovative use cases.\n",
    "\n",
    "{scenario_list}\n",
    "\n",
    "Ensure the list is ordered by significance and includes a brief explanation of why each application is relevant or innovative. \n",
    "Focus on aligning the identified applications with the capabilities of the HRI system components.\n",
    "</Task>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2f6721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Application Scenarios:\n",
      "Based on the provided application scenarios, I've identified the most significant and recurring applications of the HRI system, prioritizing them according to their relevance and innovation. Here's the list:\n",
      "\n",
      "1. **Virtual Assembly Training with Haptic Feedback**: This application is crucial for industries that require precise assembly tasks, such as manufacturing and aerospace. The HRI system's immersive feedback and haptic cues enable researchers to investigate how accurately participants perceive and differentiate forces and tactile feedback, ultimately enhancing the effectiveness of virtual assembly training programs.\n",
      "\n",
      "2. **Ergonomic Tool Design Optimization for Simulated Assembly Tasks**: This application has significant implications for improving worker safety and efficiency in manufacturing and other industries. By analyzing the data collected from the HRI system, researchers can gain a deeper understanding of how ergonomic tool design affects user comfort, fatigue, and movement efficiency in simulated assembly tasks.\n",
      "\n",
      "3. **Assembly Task with Varying Force Feedback and Cognitive Demands**: This application is innovative in its approach to simulating real-world assembly challenges and investigating the impact of physical and cognitive demands on user performance and stress levels. The HRI system's ability to induce varying levels of cognitive demands and measure physiological responses makes it an ideal platform for this type of research.\n",
      "\n",
      "4. **Intuitive Robotic Assembly Task**: This application is relevant for the development of intuitive control and feedback interfaces in robotic assembly tasks. By analyzing the data from the force sensor, motion tracking system, and participant feedback, researchers can identify the optimal level of force feedback for intuitive control and feedback interfaces.\n",
      "\n",
      "5. **Robotic Assembly Task Simulator**: This application is significant for assessing the impact of robot behavior on user trust and acceptance. The HRI system's ability to simulate varying levels of force feedback and robot responsiveness makes it an ideal platform for investigating how robot behavior influences user trust and acceptance in interactive tasks.\n",
      "\n",
      "Recurring themes and innovative use cases:\n",
      "\n",
      "* **Haptic feedback and force feedback**: The HRI system's ability to provide realistic force feedback and haptic cues is a recurring theme across multiple application scenarios. This highlights the system's potential for simulating real-world assembly challenges and enhancing the effectiveness of virtual assembly training programs.\n",
      "* **Ergonomic tool design**: The HRI system's ability to analyze the impact of ergonomic tool design on user comfort, fatigue, and movement efficiency is an innovative use case with significant implications for improving worker safety and efficiency.\n",
      "* **Cognitive demands and user performance**: The HRI system's ability to induce varying levels of cognitive demands and measure physiological responses makes it an ideal platform for investigating the impact of physical and cognitive demands on user performance and stress levels.\n",
      "* **Intuitive control and feedback interfaces**: The HRI system's ability to analyze the optimal level of force feedback for intuitive control and feedback interfaces is an innovative use case with significant implications for the development of robotic assembly tasks.\n",
      "\n",
      "By aligning the identified applications with the capabilities of the HRI system components, we can unlock the full potential of this technology and drive innovation in various fields, including manufacturing, aerospace, and robotics.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Initialize the client (assuming the client and API key are already set up)\n",
    "client = InferenceClient(headers={\"X-use-cache\": \"false\"}, token=key.hugging_api_key)\n",
    "\n",
    "# Invoke the chat completion\n",
    "chat_completion = client.chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_template},\n",
    "        {\"role\": \"user\", \"content\": user_template}\n",
    "    ],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    temperature=0.6,\n",
    "    stream=False,\n",
    "    max_tokens=1400\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(\"\\nSummary of Application Scenarios:\")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f915b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary content saved to summary_of_application_scenarios_IPEK.txt\n"
     ]
    }
   ],
   "source": [
    "# Assuming chat_completion has been defined and contains the LLM response\n",
    "summary_content = chat_completion.choices[0].message.content\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'summary_of_application_scenarios_IPEK.txt'\n",
    "\n",
    "# Write the content to a file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(summary_content)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Summary content saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677217ef",
   "metadata": {},
   "source": [
    "## The “Stuff” Strategy (similarities)\n",
    "\n",
    "for within subject designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c353f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "<Context>\n",
    "You are a helpful AI designed to analyze and **summarize similarities across multiple innovative technological application scenarios** for a Human-Robot Interaction (HRI) system.\n",
    "The system integrates multiple components that enable immersive and interactive experimental platforms for HRI research. \n",
    "The components include:\n",
    "1. **End Effector**: A robotic arm equipped with a 6D shaker for precise motion and force application.\n",
    "2. **Human Interface**: An ergonomic hand grip designed to mimic a power tool handle for intuitive interaction.\n",
    "3. **Force Sensor**: Measures real-time forces exerted during user interaction.\n",
    "4. **Motion Tracking**: Uses the Vicon system to capture precise movements of participants and setup for interaction analysis.\n",
    "5. **Immersive Feedback**: Employs VR headsets to simulate environments and provide visual cues, enhancing user immersion.\n",
    "\n",
    "Your task is to analyze and identify recurring themes and shared features among the application scenarios. \n",
    "The goal is to create a clear and concise bullet list summarizing the commonalities across the different scenarios based on their descriptions.\n",
    "</Context>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_template = f\"\"\"\n",
    "<Task>\n",
    "Analyze the following application scenarios for the described HRI system and provide a concise bullet list summarizing their similarities. \n",
    "The summary should focus on recurring themes, shared system components, and common use cases across the scenarios.\n",
    "\n",
    "{scenario_list}\n",
    "\n",
    "Ensure that the bullet points are specific and highlight shared aspects such as system functionality, participant interaction, experimental setups, or application goals.\n",
    "</Task>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6516a988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Application Scenarios:\n",
      "**Similarities Across Application Scenarios:**\n",
      "\n",
      "*   **Immersive Feedback**: All scenarios utilize the VR headset to provide an immersive simulated environment, enhancing user engagement and interaction.\n",
      "*   **Ergonomic Hand Grip and Force Sensor**: Each scenario employs the ergonomic hand grip equipped with a force sensor, allowing participants to interact with virtual objects and providing real-time force exertion data.\n",
      "*   **6D Shaker and Robotic Arm**: The 6D shaker attached to the robotic arm is used in all scenarios to provide precise motion and force application, simulating real-world assembly tasks and physical constraints.\n",
      "*   **Vicon Motion Tracking**: The Vicon motion tracking system is used in all scenarios to capture participant movements and robotic arm motion, enabling detailed analysis of interaction dynamics.\n",
      "*   **Within-Subjects Design**: Most scenarios employ a within-subjects design, where participants perform tasks under multiple conditions, allowing for comparisons and analysis of individual performance and preferences.\n",
      "*   **Force Feedback and Haptic Cues**: Force feedback and haptic cues are used in all scenarios to simulate physical constraints and provide realistic feedback, influencing participant performance, comfort, and perception.\n",
      "*   **Assembly Tasks and Virtual Environments**: All scenarios involve assembly tasks within virtual environments, allowing researchers to investigate various aspects of human-robot interaction, such as user comfort, fatigue, movement efficiency, and trust.\n",
      "*   **Experimental Conditions and Variables**: Multiple conditions and variables are tested in each scenario, including levels of force feedback, task complexity, robot responsiveness, and cognitive demands, to analyze their impact on participant performance and interaction dynamics.\n",
      "*   **Data Analysis and Insights**: Data collected from the HRI system is analyzed to gain insights into human-robot interaction, informing the optimization of tool design, virtual assembly training, and robotic system development.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Initialize the client (assuming the client and API key are already set up)\n",
    "client = InferenceClient(headers={\"X-use-cache\": \"false\"}, token=key.hugging_api_key)\n",
    "\n",
    "# Invoke the chat completion\n",
    "chat_completion = client.chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_template},\n",
    "        {\"role\": \"user\", \"content\": user_template}\n",
    "    ],\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    temperature=0.6,\n",
    "    stream=False,\n",
    "    max_tokens=1400\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(\"\\nSummary of Application Scenarios:\")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be8a9ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary content saved to similarities_of_application_scenarios_IPEK.txt\n"
     ]
    }
   ],
   "source": [
    "# Assuming chat_completion has been defined and contains the LLM response\n",
    "summary_content = chat_completion.choices[0].message.content\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'similarities_of_application_scenarios_IPEK.txt'\n",
    "\n",
    "# Write the content to a file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(summary_content)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Summary content saved to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
