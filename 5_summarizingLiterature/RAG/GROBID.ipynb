{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732b82a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1:\n",
      "Title: Large Language Model for automobile\n",
      "DOI: 10.55415/deep-2024-0004.v1\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 2:\n",
      "Title: Chart Understanding with Large Language Model\n",
      "DOI: 10.31224/3401\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 3:\n",
      "Title: Large Language Model for automobile\n",
      "DOI: 10.33774/coe-2024-cdlwg\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 4:\n",
      "Title: Infinite-parameter Large Language Model\n",
      "DOI: 10.33774/coe-2024-7khtw\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 5:\n",
      "Title: Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models\n",
      "DOI: 10.2139/ssrn.4916298\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 6:\n",
      "Title: Large Language Model (LLM) Monthly Report (2024 Apr)\n",
      "DOI: 10.55277/researchhub.0ps6xenm\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 7:\n",
      "Title: Review for \"Pressure to publish introduces large‐language model risks\"\n",
      "DOI: 10.1111/2041-210x.14397/v1/review1\n",
      "Published Date: [2024, 5, 11]\n",
      "\n",
      "Article 8:\n",
      "Title: NTT’s Large Language Model “tsuzumi”: A High-performance and Low-energy-consumption Large Language Model with Expertise in Specific Fields\n",
      "DOI: 10.53829/ntr202408fr1\n",
      "Published Date: [2024, 8]\n",
      "\n",
      "Article 9:\n",
      "Title: Taxonomy Classification of Large Language Model Survey Papers\n",
      "DOI: 10.31224/3975\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 10:\n",
      "Title: GeoGPT, the large earth science language model system\n",
      "DOI: 10.5194/egusphere-egu24-18265\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 11:\n",
      "Title: Challenges in Large Language Model Development and AI Ethics\n",
      "DOI: 10.4018/979-8-3693-3860-5.ch002\n",
      "Published Date: [2024, 8, 30]\n",
      "\n",
      "Article 12:\n",
      "Title: Review for \"Pressure to publish introduces large‐language model risks\"\n",
      "DOI: 10.1111/2041-210x.14397/v1/review2\n",
      "Published Date: [2024, 5, 13]\n",
      "\n",
      "Article 13:\n",
      "Title: PEFT-Medaware: Large Language Model for Medical Awareness\n",
      "DOI: 10.2139/ssrn.4632133\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 14:\n",
      "Title: Application of the AIGC Large Language Model in College English Writing Teaching\n",
      "DOI: 10.57237/j.cll.2024.01.002\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 15:\n",
      "Title: Exploring Large Language Model survey papers via Machine and Ensemble Learning\n",
      "DOI: 10.31224/3992\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 16:\n",
      "Title: Advancing AI: Enhancing Large Language Model Performance through GPU Optimization Techniques\n",
      "DOI: 10.21275/sr24309100709\n",
      "Published Date: [2024, 3, 5]\n",
      "\n",
      "Article 17:\n",
      "Title: Engineering A Large Language Model From Scratch\n",
      "DOI: 10.20944/preprints202401.2120.v1\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 18:\n",
      "Title: Decision letter for \"Pressure to publish introduces large‐language model risks\"\n",
      "DOI: 10.1111/2041-210x.14397/v2/decision1\n",
      "Published Date: [2024, 7, 3]\n",
      "\n",
      "Article 19:\n",
      "Title: Consumption and Savings with Large Language Model Agents\n",
      "DOI: 10.2139/ssrn.4909749\n",
      "Published Date: ['Unknown']\n",
      "\n",
      "Article 20:\n",
      "Title: Decision letter for \"Pressure to publish introduces large‐language model risks\"\n",
      "DOI: 10.1111/2041-210x.14397/v1/decision1\n",
      "Published Date: [2024, 6, 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set the URL for the API request\n",
    "url = \"https://api.crossref.org/works\"\n",
    "\n",
    "# Set the parameters for the request\n",
    "params = {\n",
    "    \"query.bibliographic\": \"Large Language Model\",\n",
    "    \"filter\": \"from-pub-date:2017\",\n",
    "    \"rows\": 20\n",
    "}\n",
    "\n",
    "# Make the GET request\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "results = data.get(\"message\", {}).get(\"items\", [])\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    # Extract the articles\n",
    "    articles = data.get(\"message\", {}).get(\"items\", [])\n",
    "    # Display the results\n",
    "    for i, article in enumerate(articles, 1):\n",
    "        print(f\"Article {i}:\")\n",
    "        print(f\"Title: {article.get('title', ['No title'])[0]}\")\n",
    "        print(f\"DOI: {article.get('DOI')}\")\n",
    "        print(f\"Published Date: {article.get('published-print', {}).get('date-parts', [['Unknown']])[0]}\")\n",
    "        print()\n",
    "else:\n",
    "    print(f\"Failed to retrieve articles. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7bd541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Set the URL for the API request\n",
    "url = \"https://api.crossref.org/works\"\n",
    "\n",
    "# Set the parameters for the request\n",
    "params = {\n",
    "    \"query.bibliographic\": \"Large Language Model\",\n",
    "    \"filter\": \"from-pub-date:2017\",\n",
    "    \"rows\": 20\n",
    "}\n",
    "\n",
    "# Make the GET request\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28c1a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'indexed': {'date-parts': [[2024, 5, 7]],\n",
       "   'date-time': '2024-05-07T00:30:09Z',\n",
       "   'timestamp': 1715041809520},\n",
       "  'posted': {'date-parts': [[2024, 5, 1]]},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Deep Science',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'DOI': '10.55415/deep-2024-0004.v1',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2024, 5, 6]],\n",
       "   'date-time': '2024-05-06T05:10:57Z',\n",
       "   'timestamp': 1714972257000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Large Language Model for automobile'],\n",
       "  'prefix': '10.55415',\n",
       "  'author': [{'given': 'fei',\n",
       "    'family': 'ding',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '34139',\n",
       "  'deposited': {'date-parts': [[2024, 5, 6]],\n",
       "   'date-time': '2024-05-06T05:10:57Z',\n",
       "   'timestamp': 1714972257000},\n",
       "  'score': 20.983637,\n",
       "  'resource': {'primary': {'URL': 'https://www.deepscienceplus.com/index/view/0mLpjqm7bVv6bSr1'}},\n",
       "  'issued': {'date-parts': [[2024, 5, 1]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.55415/deep-2024-0004.v1',\n",
       "  'published': {'date-parts': [[2024, 5, 1]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2023, 12, 13]],\n",
       "   'date-time': '2023-12-13T00:57:13Z',\n",
       "   'timestamp': 1702429033809},\n",
       "  'posted': {'date-parts': [[2023, 12, 12]]},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Open Engineering Inc',\n",
       "  'license': [{'start': {'date-parts': [[2023, 12, 12]],\n",
       "     'date-time': '2023-12-12T00:00:00Z',\n",
       "     'timestamp': 1702339200000},\n",
       "    'content-version': 'unspecified',\n",
       "    'delay-in-days': 0,\n",
       "    'URL': 'https://creativecommons.org/licenses/by/4.0'}],\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'DOI': '10.31224/3401',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2023, 12, 12]],\n",
       "   'date-time': '2023-12-12T17:56:45Z',\n",
       "   'timestamp': 1702403805000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Chart Understanding with Large Language Model'],\n",
       "  'prefix': '10.31224',\n",
       "  'author': [{'given': 'John',\n",
       "    'family': 'Feng',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '33966',\n",
       "  'deposited': {'date-parts': [[2023, 12, 12]],\n",
       "   'date-time': '2023-12-12T17:56:45Z',\n",
       "   'timestamp': 1702403805000},\n",
       "  'score': 20.634922,\n",
       "  'resource': {'primary': {'URL': 'https://engrxiv.org/preprint/view/3401/version/4747'}},\n",
       "  'issued': {'date-parts': [[2023, 12, 12]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.31224/3401',\n",
       "  'published': {'date-parts': [[2023, 12, 12]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2024, 5, 12]],\n",
       "   'date-time': '2024-05-12T00:24:09Z',\n",
       "   'timestamp': 1715473449586},\n",
       "  'posted': {'date-parts': [[2024, 5, 11]]},\n",
       "  'group-title': 'Computer Science',\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Cambridge University Press (CUP)',\n",
       "  'license': [{'start': {'date-parts': [[2024, 5, 11]],\n",
       "     'date-time': '2024-05-11T00:00:00Z',\n",
       "     'timestamp': 1715385600000},\n",
       "    'content-version': 'unspecified',\n",
       "    'delay-in-days': 0,\n",
       "    'URL': 'https://www.cambridge.org/engage/coe/legal-information?show=terms-of-use'}],\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'accepted': {'date-parts': [[2024, 5, 2]]},\n",
       "  'abstract': '<jats:p>To deploy on cars , we trained a 7-billion-parameter automobile model, which outperforms GPT-3.5 in the automotive domain. Surpassing all models in areas such as automotive maintenance, navigation queries, and beyond.</jats:p>',\n",
       "  'DOI': '10.33774/coe-2024-cdlwg',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2024, 5, 11]],\n",
       "   'date-time': '2024-05-11T10:16:26Z',\n",
       "   'timestamp': 1715422586000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Large Language Model for automobile'],\n",
       "  'prefix': '10.33774',\n",
       "  'author': [{'ORCID': 'http://orcid.org/0009-0000-7964-6020',\n",
       "    'authenticated-orcid': False,\n",
       "    'given': 'Fei',\n",
       "    'family': 'Ding',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '56',\n",
       "  'link': [{'URL': 'https://www.cambridge.org/engage/api-gateway/coe/assets/orp/resource/item/6633b65e91aefa6ce1fb0c5e/original/large-language-model-for-automobile.pdf',\n",
       "    'content-type': 'unspecified',\n",
       "    'content-version': 'vor',\n",
       "    'intended-application': 'similarity-checking'}],\n",
       "  'deposited': {'date-parts': [[2024, 5, 11]],\n",
       "   'date-time': '2024-05-11T10:16:27Z',\n",
       "   'timestamp': 1715422587000},\n",
       "  'score': 20.274956,\n",
       "  'resource': {'primary': {'URL': 'https://www.cambridge.org/engage/coe/article-details/6633b65e91aefa6ce1fb0c5e'}},\n",
       "  'issued': {'date-parts': [[2024, 5, 11]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.33774/coe-2024-cdlwg',\n",
       "  'published': {'date-parts': [[2024, 5, 11]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2024, 7, 30]],\n",
       "   'date-time': '2024-07-30T00:22:05Z',\n",
       "   'timestamp': 1722298925721},\n",
       "  'posted': {'date-parts': [[2024, 7, 29]]},\n",
       "  'group-title': 'Computer Science',\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Cambridge University Press (CUP)',\n",
       "  'license': [{'start': {'date-parts': [[2024, 7, 29]],\n",
       "     'date-time': '2024-07-29T00:00:00Z',\n",
       "     'timestamp': 1722211200000},\n",
       "    'content-version': 'unspecified',\n",
       "    'delay-in-days': 0,\n",
       "    'URL': 'https://www.cambridge.org/engage/coe/legal-information?show=terms-of-use'}],\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'accepted': {'date-parts': [[2024, 7, 15]]},\n",
       "  'abstract': '<jats:p>In the standard transformer architecture, in creasing model parameters leads to linear growth in computational cost and activation memory. To address this issue, we propose a novel Infinite Parameter Large Language Model (IP-LLM) architecture that decouples model size from computational cost and de vice memory. Existing large language models Figure 1: Parameters A, B, C, and D store knowledge are all fixed-parameter models, while human knowledge is infinite and expands daily. Finite parameters are inherently limited in their capac ity to accommodate this boundless knowledge. Our IP-LLM architecture can potentially ac commodate infinite knowledge, resolving this issue and laying the foundation for realizing a truly omniscient and omnipotent artificial gen eral intelligence in the future.Our architecture surpasses MOE in performance while requiring significantly less memory.</jats:p>',\n",
       "  'DOI': '10.33774/coe-2024-7khtw',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2024, 7, 29]],\n",
       "   'date-time': '2024-07-29T14:54:34Z',\n",
       "   'timestamp': 1722264874000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Infinite-parameter Large Language Model'],\n",
       "  'prefix': '10.33774',\n",
       "  'author': [{'ORCID': 'http://orcid.org/0009-0000-7964-6020',\n",
       "    'authenticated-orcid': False,\n",
       "    'given': 'Fei',\n",
       "    'family': 'Ding',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '56',\n",
       "  'link': [{'URL': 'https://www.cambridge.org/engage/api-gateway/coe/assets/orp/resource/item/669532255101a2ffa8734ccf/original/infinite-parameter-large-language-model.pdf',\n",
       "    'content-type': 'unspecified',\n",
       "    'content-version': 'vor',\n",
       "    'intended-application': 'similarity-checking'}],\n",
       "  'deposited': {'date-parts': [[2024, 7, 29]],\n",
       "   'date-time': '2024-07-29T14:54:35Z',\n",
       "   'timestamp': 1722264875000},\n",
       "  'score': 20.242348,\n",
       "  'resource': {'primary': {'URL': 'https://www.cambridge.org/engage/coe/article-details/669532255101a2ffa8734ccf'}},\n",
       "  'issued': {'date-parts': [[2024, 7, 29]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.33774/coe-2024-7khtw',\n",
       "  'published': {'date-parts': [[2024, 7, 29]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2024, 8, 27]],\n",
       "   'date-time': '2024-08-27T00:12:55Z',\n",
       "   'timestamp': 1724717575998},\n",
       "  'posted': {'date-parts': [[2024]]},\n",
       "  'group-title': 'SSRN',\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Elsevier BV',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'DOI': '10.2139/ssrn.4916298',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2024, 8, 26]],\n",
       "   'date-time': '2024-08-26T17:14:05Z',\n",
       "   'timestamp': 1724692445000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models'],\n",
       "  'prefix': '10.2139',\n",
       "  'author': [{'given': 'Nunzio',\n",
       "    'family': 'Lorè',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []},\n",
       "   {'given': 'anon',\n",
       "    'family': 'Ilami',\n",
       "    'sequence': 'additional',\n",
       "    'affiliation': []},\n",
       "   {'given': 'Babak',\n",
       "    'family': 'Heydari',\n",
       "    'sequence': 'additional',\n",
       "    'affiliation': []}],\n",
       "  'member': '78',\n",
       "  'deposited': {'date-parts': [[2024, 8, 26]],\n",
       "   'date-time': '2024-08-26T17:14:05Z',\n",
       "   'timestamp': 1724692445000},\n",
       "  'score': 19.951237,\n",
       "  'resource': {'primary': {'URL': 'https://www.ssrn.com/abstract=4916298'}},\n",
       "  'issued': {'date-parts': [[2024]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.2139/ssrn.4916298',\n",
       "  'published': {'date-parts': [[2024]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2024, 5, 11]],\n",
       "   'date-time': '2024-05-11T00:22:43Z',\n",
       "   'timestamp': 1715386963996},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'ResearchHub Technologies, Inc.',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'DOI': '10.55277/researchhub.0ps6xenm',\n",
       "  'type': 'report',\n",
       "  'created': {'date-parts': [[2024, 5, 10]],\n",
       "   'date-time': '2024-05-10T17:29:58Z',\n",
       "   'timestamp': 1715362198000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Large Language Model (LLM) Monthly Report (2024 Apr)'],\n",
       "  'prefix': '10.55277',\n",
       "  'author': [{'given': 'Hao',\n",
       "    'family': 'Zhang',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '33940',\n",
       "  'published-online': {'date-parts': [[2024, 5, 10]]},\n",
       "  'deposited': {'date-parts': [[2024, 5, 10]],\n",
       "   'date-time': '2024-05-10T17:29:59Z',\n",
       "   'timestamp': 1715362199000},\n",
       "  'score': 19.931744,\n",
       "  'resource': {'primary': {'URL': 'https://www.researchhub.com/post/2240/large-language-model-llm-monthly-report-2024-apr'}},\n",
       "  'issued': {'date-parts': [[2024, 5, 10]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.55277/researchhub.0ps6xenm',\n",
       "  'published': {'date-parts': [[2024, 5, 10]]}},\n",
       " {'indexed': {'date-parts': [[2024, 10, 4]],\n",
       "   'date-time': '2024-10-04T04:27:36Z',\n",
       "   'timestamp': 1728016056509},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Wiley',\n",
       "  'content-domain': {'domain': []},\n",
       "  'published-print': {'date-parts': [[2024, 5, 11]]},\n",
       "  'DOI': '10.1111/2041-210x.14397/v1/review1',\n",
       "  'type': 'peer-review',\n",
       "  'created': {'date-parts': [[2024, 10, 3]],\n",
       "   'date-time': '2024-10-03T21:05:13Z',\n",
       "   'timestamp': 1727989513000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Review for \"Pressure to publish introduces large‐language model risks\"'],\n",
       "  'prefix': '10.1111',\n",
       "  'member': '311',\n",
       "  'review': {'type': 'referee-report',\n",
       "   'running-number': 'PR1V1',\n",
       "   'revision-round': '1',\n",
       "   'stage': 'pre-publication'},\n",
       "  'deposited': {'date-parts': [[2024, 10, 3]],\n",
       "   'date-time': '2024-10-03T21:05:15Z',\n",
       "   'timestamp': 1727989515000},\n",
       "  'score': 19.921438,\n",
       "  'resource': {'primary': {'URL': 'https://www.webofscience.com/api/gateway/wos/peer-review/10.1111/2041-210X.14397'}},\n",
       "  'issued': {'date-parts': [[2024, 5, 11]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.1111/2041-210x.14397/v1/review1',\n",
       "  'relation': {'is-review-of': [{'id-type': 'doi',\n",
       "     'id': '10.1111/2041-210X.14397',\n",
       "     'asserted-by': 'subject'}]},\n",
       "  'published': {'date-parts': [[2024, 5, 11]]}},\n",
       " {'indexed': {'date-parts': [[2024, 8, 14]],\n",
       "   'date-time': '2024-08-14T00:27:43Z',\n",
       "   'timestamp': 1723595263152},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'NTT Science and Core Technology Laboratory Group',\n",
       "  'issue': '8',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'published-print': {'date-parts': [[2024, 8]]},\n",
       "  'DOI': '10.53829/ntr202408fr1',\n",
       "  'type': 'journal-article',\n",
       "  'created': {'date-parts': [[2024, 8, 13]],\n",
       "   'date-time': '2024-08-13T22:10:16Z',\n",
       "   'timestamp': 1723587016000},\n",
       "  'page': '6-12',\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['NTT’s Large Language Model “tsuzumi”: A High-performance and Low-energy-consumption Large Language Model with Expertise in Specific Fields'],\n",
       "  'prefix': '10.53829',\n",
       "  'volume': '22',\n",
       "  'author': [{'given': 'Kyosuke',\n",
       "    'family': 'Nishida',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': [{'name': 'NTT Human Informatics Laboratories, NTT Corporation'}]}],\n",
       "  'member': '32006',\n",
       "  'container-title': ['NTT Technical Review'],\n",
       "  'language': 'en',\n",
       "  'deposited': {'date-parts': [[2024, 8, 13]],\n",
       "   'date-time': '2024-08-13T22:10:16Z',\n",
       "   'timestamp': 1723587016000},\n",
       "  'score': 19.918713,\n",
       "  'resource': {'primary': {'URL': 'https://ntt-review.jp/archive/ntttechnical.php?contents=ntr202408fr1.html'}},\n",
       "  'issued': {'date-parts': [[2024, 8]]},\n",
       "  'references-count': 0,\n",
       "  'journal-issue': {'issue': '8', 'published-print': {'date-parts': [[2024]]}},\n",
       "  'URL': 'http://dx.doi.org/10.53829/ntr202408fr1',\n",
       "  'ISSN': ['2436-5327'],\n",
       "  'issn-type': [{'value': '2436-5327', 'type': 'electronic'}],\n",
       "  'published': {'date-parts': [[2024, 8]]}},\n",
       " {'indexed': {'date-parts': [[2024, 10, 2]],\n",
       "   'date-time': '2024-10-02T15:40:16Z',\n",
       "   'timestamp': 1727883616930},\n",
       "  'posted': {'date-parts': [[2024, 10, 2]]},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Open Engineering Inc',\n",
       "  'license': [{'start': {'date-parts': [[2024, 10, 2]],\n",
       "     'date-time': '2024-10-02T00:00:00Z',\n",
       "     'timestamp': 1727827200000},\n",
       "    'content-version': 'unspecified',\n",
       "    'delay-in-days': 0,\n",
       "    'URL': 'https://creativecommons.org/licenses/by/4.0'}],\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'abstract': '<jats:p>This study develops a taxonomy classification model using traditional and deep learning methods. After data exploration, a Linear Support Vector Classifier (SVC) provides a baseline performance. However, a deep learning model with TF-IDF vectorization, dynamic learning rate scheduling, and early stopping proves more effective.</jats:p>',\n",
       "  'DOI': '10.31224/3975',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2024, 10, 2]],\n",
       "   'date-time': '2024-10-02T15:04:31Z',\n",
       "   'timestamp': 1727881471000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Taxonomy Classification of Large Language Model Survey Papers'],\n",
       "  'prefix': '10.31224',\n",
       "  'author': [{'given': 'Desmond',\n",
       "    'family': 'Boateng',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '33966',\n",
       "  'deposited': {'date-parts': [[2024, 10, 2]],\n",
       "   'date-time': '2024-10-02T15:04:31Z',\n",
       "   'timestamp': 1727881471000},\n",
       "  'score': 19.897987,\n",
       "  'resource': {'primary': {'URL': 'https://engrxiv.org/preprint/view/3975/version/5463'}},\n",
       "  'issued': {'date-parts': [[2024, 10, 2]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.31224/3975',\n",
       "  'published': {'date-parts': [[2024, 10, 2]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2024, 3, 12]],\n",
       "   'date-time': '2024-03-12T00:31:21Z',\n",
       "   'timestamp': 1710203481840},\n",
       "  'posted': {'date-parts': [[2024, 3, 11]]},\n",
       "  'group-title': 'display',\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Copernicus GmbH',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'abstract': '<jats:p>GeoGPT, a large earth science language model system for geoscientists, was designed and developed in response to the Deep-time Digital Earth (DDE) International Science Initiative, which was officially launched at DDE Open Science Forum co-organized by UNESCO in 2021.\\nStarting with leading open-source large language models, GeoGPT has built fundamental capabilities, including extraction of key information from geoscience documents, question-and-answer interaction, logical reasoning, automatic code generation, and numerical computation analysis. Smart incremental training strategy based on open-source large-scale models rapidly enhances the adaptability and performance of GeoGPT in the field of Earth sciences. GeoGPT is architected to be flexible in adapting to different foundation models in the future.\\nTo ensure accuracy and professionalism in the field of earth science, GeoGPT has specifically constructed a large high-quality geoscience corpus covering 8 secondary disciplines of earth science and innovatively developed a software system designed for annotating geoscience data more efficiently. Hundreds of Earth scientists have collaborated to complete the annotation of nearly one hundred thousand highly specialized question-and-answer pairs, which greatly enriched the training data resources for this geoscience model.\\nGeoGPT is a global effort of open science practice across research institutes, universities, industry, and other organizations. GeoGPT model is open to the global research community today. It is also being planned to provide open access to large-scale datasets used in GeoGPT and GeoGPT API to Earth science community. GeoGPT is helping to transform the research paradigm of earth science through its potential capabilities of generating scientific hypotheses, constructing theoretical models, and doing research plans.</jats:p>',\n",
       "  'DOI': '10.5194/egusphere-egu24-18265',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2024, 3, 11]],\n",
       "   'date-time': '2024-03-11T10:07:27Z',\n",
       "   'timestamp': 1710151647000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['GeoGPT, the large earth science language model system'],\n",
       "  'prefix': '10.5194',\n",
       "  'author': [{'given': 'Jian',\n",
       "    'family': 'Wang',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '3145',\n",
       "  'deposited': {'date-parts': [[2024, 3, 11]],\n",
       "   'date-time': '2024-03-11T10:40:36Z',\n",
       "   'timestamp': 1710153636000},\n",
       "  'score': 19.597057,\n",
       "  'resource': {'primary': {'URL': 'https://meetingorganizer.copernicus.org/EGU24/EGU24-18265.html'}},\n",
       "  'issued': {'date-parts': [[2024, 3, 11]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.5194/egusphere-egu24-18265',\n",
       "  'published': {'date-parts': [[2024, 3, 11]]},\n",
       "  'subtype': 'other'},\n",
       " {'indexed': {'date-parts': [[2024, 8, 16]],\n",
       "   'date-time': '2024-08-16T00:25:31Z',\n",
       "   'timestamp': 1723767931563},\n",
       "  'reference-count': 7,\n",
       "  'publisher': 'IGI Global',\n",
       "  'isbn-type': [{'value': '9798369338605', 'type': 'print'},\n",
       "   {'value': '9798369338612', 'type': 'electronic'}],\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'published-print': {'date-parts': [[2024, 8, 30]]},\n",
       "  'abstract': \"<jats:p>In the digital era, ethical AI development is crucial. This chapter outlines an ethics framework emphasizing fairness, accountability, and transparency. It advocates integrating ethical considerations throughout the AI lifecycle and forming multidisciplinary teams, including ethicists, to ensure alignment with ethical norms. Deployment requires adaptable decision-making frameworks to address evolving ethical challenges. Continuous assessment of AI's societal impact, including stakeholder feedback, is vital. The chapter stresses ongoing vigilance, inclusive discourse, and adaptability to meet AI's evolving challenges and promote societal betterment.</jats:p>\",\n",
       "  'DOI': '10.4018/979-8-3693-3860-5.ch002',\n",
       "  'type': 'book-chapter',\n",
       "  'created': {'date-parts': [[2024, 8, 15]],\n",
       "   'date-time': '2024-08-15T21:20:36Z',\n",
       "   'timestamp': 1723756836000},\n",
       "  'page': '25-81',\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Challenges in Large Language Model Development and AI Ethics'],\n",
       "  'prefix': '10.4018',\n",
       "  'author': [{'family': 'Sandfreni',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': [{'name': 'Universitas Esa Unggul, Indonesia'}]},\n",
       "   {'given': 'Ritika',\n",
       "    'family': 'Bansal',\n",
       "    'sequence': 'additional',\n",
       "    'affiliation': [{'name': 'Insights2Techinfo, India'}]}],\n",
       "  'member': '2432',\n",
       "  'reference': [{'key': '979-8-3693-3860-5.ch002.-1',\n",
       "    'unstructured': 'Australian National Greenhouse Accounts. (2021). National Inventory Report 2019: The Australian Government Submission to the United Nations Framework Convention on Climate Change. In The Australian Government Submission to the United Nations Framework Convention on Climate Change Australian National Greenhouse Accounts.'},\n",
       "   {'key': '979-8-3693-3860-5.ch002.-2',\n",
       "    'doi-asserted-by': 'publisher',\n",
       "    'DOI': '10.1145/3017680.3022340'},\n",
       "   {'key': '979-8-3693-3860-5.ch002.-3',\n",
       "    'doi-asserted-by': 'publisher',\n",
       "    'DOI': '10.1007/s11023-018-9482-5'},\n",
       "   {'key': '979-8-3693-3860-5.ch002.-4',\n",
       "    'doi-asserted-by': 'publisher',\n",
       "    'DOI': '10.1109/WAIN52551.2021.00020'},\n",
       "   {'key': '979-8-3693-3860-5.ch002.-5',\n",
       "    'doi-asserted-by': 'publisher',\n",
       "    'DOI': '10.1038/s42256-019-0088-2'},\n",
       "   {'key': '979-8-3693-3860-5.ch002.-6',\n",
       "    'article-title': 'AI Ethics Principles in Practice: Perspectives of Designers and Developers. 1–8.',\n",
       "    'author': 'C.Sanderson',\n",
       "    'year': '2021',\n",
       "    'unstructured': 'SandersonC.DouglasD.LuQ.SchleigerE.WhittleJ.LaceyJ.NewnhamG.HajkowiczS.RobinsonC.HansenD. (2021). AI Ethics Principles in Practice: Perspectives of Designers and Developers. 1–8.http://arxiv.org/abs/2112.07467'},\n",
       "   {'key': '979-8-3693-3860-5.ch002.-7',\n",
       "    'doi-asserted-by': 'publisher',\n",
       "    'DOI': '10.1109/ACCESS.2022.3174115'}],\n",
       "  'container-title': ['Advances in Computational Intelligence and Robotics',\n",
       "   'Challenges in Large Language Model Development and AI Ethics'],\n",
       "  'link': [{'URL': 'https://www.igi-global.com/viewtitle.aspx?TitleId=354392',\n",
       "    'content-type': 'unspecified',\n",
       "    'content-version': 'vor',\n",
       "    'intended-application': 'similarity-checking'}],\n",
       "  'deposited': {'date-parts': [[2024, 8, 15]],\n",
       "   'date-time': '2024-08-15T21:21:21Z',\n",
       "   'timestamp': 1723756881000},\n",
       "  'score': 19.407175,\n",
       "  'resource': {'primary': {'URL': 'https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/979-8-3693-3860-5.ch002'}},\n",
       "  'subtitle': [''],\n",
       "  'issued': {'date-parts': [[2024, 8, 30]]},\n",
       "  'ISBN': ['9798369338605', '9798369338612'],\n",
       "  'references-count': 7,\n",
       "  'URL': 'http://dx.doi.org/10.4018/979-8-3693-3860-5.ch002',\n",
       "  'ISSN': ['2327-0411', '2327-042X'],\n",
       "  'issn-type': [{'value': '2327-0411', 'type': 'print'},\n",
       "   {'value': '2327-042X', 'type': 'electronic'}],\n",
       "  'published': {'date-parts': [[2024, 8, 30]]}},\n",
       " {'indexed': {'date-parts': [[2024, 10, 4]],\n",
       "   'date-time': '2024-10-04T04:27:36Z',\n",
       "   'timestamp': 1728016056777},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Wiley',\n",
       "  'content-domain': {'domain': []},\n",
       "  'published-print': {'date-parts': [[2024, 5, 13]]},\n",
       "  'DOI': '10.1111/2041-210x.14397/v1/review2',\n",
       "  'type': 'peer-review',\n",
       "  'created': {'date-parts': [[2024, 10, 3]],\n",
       "   'date-time': '2024-10-03T21:05:13Z',\n",
       "   'timestamp': 1727989513000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Review for \"Pressure to publish introduces large‐language model risks\"'],\n",
       "  'prefix': '10.1111',\n",
       "  'author': [{'family': 'Natalie Cooper',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '311',\n",
       "  'review': {'type': 'referee-report',\n",
       "   'running-number': 'PR2V1',\n",
       "   'revision-round': '1',\n",
       "   'stage': 'pre-publication'},\n",
       "  'deposited': {'date-parts': [[2024, 10, 3]],\n",
       "   'date-time': '2024-10-03T21:05:14Z',\n",
       "   'timestamp': 1727989514000},\n",
       "  'score': 19.275288,\n",
       "  'resource': {'primary': {'URL': 'https://www.webofscience.com/api/gateway/wos/peer-review/10.1111/2041-210X.14397'}},\n",
       "  'issued': {'date-parts': [[2024, 5, 13]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.1111/2041-210x.14397/v1/review2',\n",
       "  'relation': {'is-review-of': [{'id-type': 'doi',\n",
       "     'id': '10.1111/2041-210X.14397',\n",
       "     'asserted-by': 'subject'}]},\n",
       "  'published': {'date-parts': [[2024, 5, 13]]}},\n",
       " {'indexed': {'date-parts': [[2023, 11, 18]],\n",
       "   'date-time': '2023-11-18T00:40:38Z',\n",
       "   'timestamp': 1700268038836},\n",
       "  'posted': {'date-parts': [[2023]]},\n",
       "  'group-title': 'SSRN',\n",
       "  'reference-count': 11,\n",
       "  'publisher': 'Elsevier BV',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'DOI': '10.2139/ssrn.4632133',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2023, 11, 17]],\n",
       "   'date-time': '2023-11-17T03:38:41Z',\n",
       "   'timestamp': 1700192321000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['PEFT-Medaware: Large Language Model for Medical Awareness'],\n",
       "  'prefix': '10.2139',\n",
       "  'author': [{'given': 'Keivalya Bhartendu',\n",
       "    'family': 'Pandya',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '78',\n",
       "  'reference': [{'key': 'ref1',\n",
       "    'author': 'H Liu',\n",
       "    'year': '2022',\n",
       "    'journal-title': 'Fewshot parameter-efficient fine-tuning is better and cheaper than in-context learning'},\n",
       "   {'key': 'ref2',\n",
       "    'author': 'G Penedo',\n",
       "    'year': '2023',\n",
       "    'journal-title': 'The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only'},\n",
       "   {'key': 'ref3',\n",
       "    'author': 'P Lewis',\n",
       "    'year': '2021',\n",
       "    'journal-title': 'Retrieval-augmented generation for knowledge-intensive nlp tasks'},\n",
       "   {'key': 'ref4',\n",
       "    'author': 'C Xu',\n",
       "    'year': '2023',\n",
       "    'journal-title': 'Baize: An open-source chat model with parameter-efficient tuning on self-chat data'},\n",
       "   {'key': 'ref5',\n",
       "    'doi-asserted-by': 'crossref',\n",
       "    'first-page': '370',\n",
       "    'DOI': '10.18653/v1/W19-5039',\n",
       "    'article-title': 'Overview of the MEDIQA 2019 shared task on textual inference, question entailment and question answering',\n",
       "    'author': 'A Ben Abacha',\n",
       "    'year': '2019',\n",
       "    'journal-title': 'Proceedings of the 18th BioNLP Workshop and Shared Task, Association for Computational Linguistics'},\n",
       "   {'key': 'ref6',\n",
       "    'first-page': '3840',\n",
       "    'article-title': 'Question answering with long multiple-span answers',\n",
       "    'author': 'M Zhu',\n",
       "    'year': '2020',\n",
       "    'journal-title': 'Findings of the Association for Computational Linguistics: EMNLP 2020'},\n",
       "   {'key': 'ref7',\n",
       "    'first-page': '181',\n",
       "    'article-title': 'Federated learning over heterogeneous question answering data',\n",
       "    'author': 'J Chen',\n",
       "    'year': '2021',\n",
       "    'journal-title': \"Proceedings of the 30th ACM International Conference on Information & Knowledge Management, CIKM '21, Association for Computing Machinery\"},\n",
       "   {'issue': '1',\n",
       "    'key': 'ref8',\n",
       "    'article-title': 'A question-entailment approach to question answering',\n",
       "    'volume': '20',\n",
       "    'author': 'A B Abacha',\n",
       "    'year': '2019',\n",
       "    'journal-title': 'BMC Bioinformatics'},\n",
       "   {'key': 'ref9',\n",
       "    'author': 'S P Sourab Mangrulkar',\n",
       "    'year': '2023',\n",
       "    'journal-title': 'Peft: Parameterefficient fine-tuning of billion-scale models on low-resource hardware'},\n",
       "   {'key': 'ref10',\n",
       "    'author': 'Y Belkada',\n",
       "    'year': '2022',\n",
       "    'journal-title': 'Making llms even more accessible with bitsandbytes, 4-bit quantization and qlora'},\n",
       "   {'key': 'ref11',\n",
       "    'author': 'Huggingface',\n",
       "    'year': '2022',\n",
       "    'journal-title': 'Quantize transformers models'}],\n",
       "  'deposited': {'date-parts': [[2023, 11, 17]],\n",
       "   'date-time': '2023-11-17T05:20:56Z',\n",
       "   'timestamp': 1700198456000},\n",
       "  'score': 19.275288,\n",
       "  'resource': {'primary': {'URL': 'https://www.ssrn.com/abstract=4632133'}},\n",
       "  'issued': {'date-parts': [[2023]]},\n",
       "  'references-count': 11,\n",
       "  'URL': 'http://dx.doi.org/10.2139/ssrn.4632133',\n",
       "  'published': {'date-parts': [[2023]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2024, 8, 8]],\n",
       "   'date-time': '2024-08-08T23:11:46Z',\n",
       "   'timestamp': 1723158706210},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'International Science Group Inc.',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'short-container-title': ['cll'],\n",
       "  'accepted': {'date-parts': [[2024, 2, 4]]},\n",
       "  'DOI': '10.57237/j.cll.2024.01.002',\n",
       "  'type': 'journal-article',\n",
       "  'created': {'date-parts': [[2024, 2, 4]],\n",
       "   'date-time': '2024-02-04T09:06:23Z',\n",
       "   'timestamp': 1707037583000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 1,\n",
       "  'title': ['Application of the AIGC Large Language Model in College English Writing Teaching'],\n",
       "  'prefix': '10.57237',\n",
       "  'author': [{'given': 'Tang',\n",
       "    'family': 'Yingying',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': [{'name': 'Department of Fundamental Courses, Tianjin College of Media and Arts, Tianjin 300000, China;'}]}],\n",
       "  'member': '36881',\n",
       "  'published-online': {'date-parts': [[2024, 2, 4]]},\n",
       "  'container-title': ['Chinese Language and Literature'],\n",
       "  'language': 'en',\n",
       "  'deposited': {'date-parts': [[2024, 2, 4]],\n",
       "   'date-time': '2024-02-04T09:06:24Z',\n",
       "   'timestamp': 1707037584000},\n",
       "  'score': 19.063816,\n",
       "  'resource': {'primary': {'URL': 'http://www.isciencegroup.com/articleinfo/10440067'}},\n",
       "  'issued': {'date-parts': [[2024, 2, 4]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.57237/j.cll.2024.01.002',\n",
       "  'published': {'date-parts': [[2024, 2, 4]]}},\n",
       " {'indexed': {'date-parts': [[2024, 10, 2]],\n",
       "   'date-time': '2024-10-02T21:40:24Z',\n",
       "   'timestamp': 1727905224136},\n",
       "  'posted': {'date-parts': [[2024, 10, 2]]},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Open Engineering Inc',\n",
       "  'license': [{'start': {'date-parts': [[2024, 10, 2]],\n",
       "     'date-time': '2024-10-02T00:00:00Z',\n",
       "     'timestamp': 1727827200000},\n",
       "    'content-version': 'unspecified',\n",
       "    'delay-in-days': 0,\n",
       "    'URL': 'https://creativecommons.org/licenses/by/4.0'}],\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'abstract': '<jats:p>Nowadays, there is an influx of researchers emphasizing Large Language Models (LLMs). While the field is broadening, it becomes difficult to keep up all the models, and techniques associated with the novel idea. To tackle this problem, a study has been conducted for assigning survey papers to taxonomy in an automated way. In this assignment, I am using their dataset for the task of exploration, manipulation, and evaluation. After finishing the instructed part, I did further exploration by using a cross tab between taxonomy and date, representing different visualizations for survey papers by taxonomy over time, and plotting the box of release day by taxonomy title. The experimental analysis indicates that Logistic Regression (LR) outperformed all the 8 Classifiers in terms of accuracy score, while GaussianNB (GNB) shows the most commendable precision score. For weighted recall and f1 score, LR shows the highest performance in text classification data.</jats:p>',\n",
       "  'DOI': '10.31224/3992',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2024, 10, 2]],\n",
       "   'date-time': '2024-10-02T21:01:42Z',\n",
       "   'timestamp': 1727902902000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Exploring Large Language Model survey papers via Machine and Ensemble Learning'],\n",
       "  'prefix': '10.31224',\n",
       "  'author': [{'given': 'Mehenaz',\n",
       "    'family': 'Afrin',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '33966',\n",
       "  'deposited': {'date-parts': [[2024, 10, 2]],\n",
       "   'date-time': '2024-10-02T21:01:42Z',\n",
       "   'timestamp': 1727902902000},\n",
       "  'score': 18.931793,\n",
       "  'resource': {'primary': {'URL': 'https://engrxiv.org/preprint/view/3992/version/5482'}},\n",
       "  'issued': {'date-parts': [[2024, 10, 2]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.31224/3992',\n",
       "  'published': {'date-parts': [[2024, 10, 2]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2024, 5, 14]],\n",
       "   'date-time': '2024-05-14T00:35:51Z',\n",
       "   'timestamp': 1715646951979},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'International Journal of Science and Research',\n",
       "  'issue': '3',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'short-container-title': ['IJSR'],\n",
       "  'published-print': {'date-parts': [[2024, 3, 5]]},\n",
       "  'DOI': '10.21275/sr24309100709',\n",
       "  'type': 'journal-article',\n",
       "  'created': {'date-parts': [[2024, 5, 13]],\n",
       "   'date-time': '2024-05-13T09:30:14Z',\n",
       "   'timestamp': 1715592614000},\n",
       "  'page': '630-633',\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Advancing AI: Enhancing Large Language Model Performance through GPU Optimization Techniques'],\n",
       "  'prefix': '10.21275',\n",
       "  'volume': '13',\n",
       "  'author': [{'given': 'Sriram',\n",
       "    'family': 'Sagi',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '8810',\n",
       "  'published-online': {'date-parts': [[2024, 3, 5]]},\n",
       "  'container-title': ['International Journal of Science and Research (IJSR)'],\n",
       "  'original-title': ['Advancing AI: Enhancing Large Language Model Performance through GPU Optimization Techniques'],\n",
       "  'deposited': {'date-parts': [[2024, 5, 13]],\n",
       "   'date-time': '2024-05-13T09:44:50Z',\n",
       "   'timestamp': 1715593490000},\n",
       "  'score': 18.796173,\n",
       "  'resource': {'primary': {'URL': 'https://www.ijsr.net/archive/v13i3/SR24309100709.pdf'}},\n",
       "  'issued': {'date-parts': [[2024, 3, 5]]},\n",
       "  'references-count': 0,\n",
       "  'journal-issue': {'issue': '3',\n",
       "   'published-online': {'date-parts': [[2024, 3, 5]]},\n",
       "   'published-print': {'date-parts': [[2024, 3, 5]]}},\n",
       "  'URL': 'http://dx.doi.org/10.21275/sr24309100709',\n",
       "  'ISSN': ['2319-7064'],\n",
       "  'issn-type': [{'value': '2319-7064', 'type': 'electronic'}],\n",
       "  'published': {'date-parts': [[2024, 3, 5]]}},\n",
       " {'indexed': {'date-parts': [[2024, 2, 1]],\n",
       "   'date-time': '2024-02-01T00:33:58Z',\n",
       "   'timestamp': 1706747638552},\n",
       "  'posted': {'date-parts': [[2024, 1, 31]]},\n",
       "  'group-title': 'Computer Science and Mathematics',\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'MDPI AG',\n",
       "  'license': [{'start': {'date-parts': [[2024, 1, 31]],\n",
       "     'date-time': '2024-01-31T00:00:00Z',\n",
       "     'timestamp': 1706659200000},\n",
       "    'content-version': 'unspecified',\n",
       "    'delay-in-days': 0,\n",
       "    'URL': 'http://creativecommons.org/licenses/by/4.0'}],\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'accepted': {'date-parts': [[2024, 1, 29]]},\n",
       "  'abstract': '<jats:p>The proliferation of deep learning in natural language processing (NLP) has led to the development and release of innovative technologies capable of understanding and generating human language with remarkable proficiency. Atinuke, a Transformer-based neural network, optimises performance across various language tasks by utilising a unique configuration. The architecture interweaves layers for processing sequential data with attention mechanisms to draw meaningful affinities between inputs and outputs. Due to the configuration of its topology and hyperparameter tuning, it can emulate human-like language by extracting features and learning complex mappings. Atinuke is modular, extensible, and integrates seamlessly with existing machine learning pipelines. Advanced matrix operations like softmax, embeddings, and multi-head attention enable nuanced handling of textual, acoustic, and visual signals. By unifying modern deep learning techniques with software design principles and mathematical theory, the system achieves state-of-the-art results on natural language tasks whilst remaining interpretable and robust.</jats:p>',\n",
       "  'DOI': '10.20944/preprints202401.2120.v1',\n",
       "  'type': 'posted-content',\n",
       "  'created': {'date-parts': [[2024, 1, 31]],\n",
       "   'date-time': '2024-01-31T06:34:51Z',\n",
       "   'timestamp': 1706682891000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Engineering A Large Language Model From Scratch'],\n",
       "  'prefix': '10.20944',\n",
       "  'author': [{'ORCID': 'http://orcid.org/0009-0006-4248-6098',\n",
       "    'authenticated-orcid': False,\n",
       "    'given': 'Abiodun Finbarrs',\n",
       "    'family': 'Oketunji',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '1968',\n",
       "  'deposited': {'date-parts': [[2024, 1, 31]],\n",
       "   'date-time': '2024-01-31T06:36:48Z',\n",
       "   'timestamp': 1706683008000},\n",
       "  'score': 18.661146,\n",
       "  'resource': {'primary': {'URL': 'https://www.preprints.org/manuscript/202401.2120/v1'}},\n",
       "  'issued': {'date-parts': [[2024, 1, 31]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.20944/preprints202401.2120.v1',\n",
       "  'published': {'date-parts': [[2024, 1, 31]]},\n",
       "  'subtype': 'preprint'},\n",
       " {'indexed': {'date-parts': [[2024, 10, 4]],\n",
       "   'date-time': '2024-10-04T04:28:29Z',\n",
       "   'timestamp': 1728016109188},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Wiley',\n",
       "  'content-domain': {'domain': []},\n",
       "  'published-print': {'date-parts': [[2024, 7, 3]]},\n",
       "  'DOI': '10.1111/2041-210x.14397/v2/decision1',\n",
       "  'type': 'peer-review',\n",
       "  'created': {'date-parts': [[2024, 10, 3]],\n",
       "   'date-time': '2024-10-03T21:05:13Z',\n",
       "   'timestamp': 1727989513000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Decision letter for \"Pressure to publish introduces large‐language model risks\"'],\n",
       "  'prefix': '10.1111',\n",
       "  'member': '311',\n",
       "  'review': {'type': 'editor-report',\n",
       "   'running-number': 'E1V2',\n",
       "   'revision-round': '2',\n",
       "   'stage': 'pre-publication'},\n",
       "  'deposited': {'date-parts': [[2024, 10, 3]],\n",
       "   'date-time': '2024-10-03T21:05:13Z',\n",
       "   'timestamp': 1727989513000},\n",
       "  'score': 18.661146,\n",
       "  'resource': {'primary': {'URL': 'https://www.webofscience.com/api/gateway/wos/peer-review/10.1111/2041-210X.14397'}},\n",
       "  'editor': [{'family': \"Robert B. O'Hara\",\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'issued': {'date-parts': [[2024, 7, 3]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.1111/2041-210x.14397/v2/decision1',\n",
       "  'relation': {'is-review-of': [{'id-type': 'doi',\n",
       "     'id': '10.1111/2041-210X.14397',\n",
       "     'asserted-by': 'subject'}]},\n",
       "  'published': {'date-parts': [[2024, 7, 3]]}},\n",
       " {'indexed': {'date-parts': [[2024, 10, 4]],\n",
       "   'date-time': '2024-10-04T04:28:29Z',\n",
       "   'timestamp': 1728016109197},\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'Wiley',\n",
       "  'content-domain': {'domain': []},\n",
       "  'published-print': {'date-parts': [[2024, 6, 2]]},\n",
       "  'DOI': '10.1111/2041-210x.14397/v1/decision1',\n",
       "  'type': 'peer-review',\n",
       "  'created': {'date-parts': [[2024, 10, 3]],\n",
       "   'date-time': '2024-10-03T21:05:13Z',\n",
       "   'timestamp': 1727989513000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['Decision letter for \"Pressure to publish introduces large‐language model risks\"'],\n",
       "  'prefix': '10.1111',\n",
       "  'member': '311',\n",
       "  'review': {'type': 'editor-report',\n",
       "   'running-number': 'E1V1',\n",
       "   'revision-round': '1',\n",
       "   'stage': 'pre-publication'},\n",
       "  'deposited': {'date-parts': [[2024, 10, 3]],\n",
       "   'date-time': '2024-10-03T21:05:14Z',\n",
       "   'timestamp': 1727989514000},\n",
       "  'score': 18.648445,\n",
       "  'resource': {'primary': {'URL': 'https://www.webofscience.com/api/gateway/wos/peer-review/10.1111/2041-210X.14397'}},\n",
       "  'editor': [{'family': \"Robert B. O'Hara\",\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'issued': {'date-parts': [[2024, 6, 2]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.1111/2041-210x.14397/v1/decision1',\n",
       "  'relation': {'is-review-of': [{'id-type': 'doi',\n",
       "     'id': '10.1111/2041-210X.14397',\n",
       "     'asserted-by': 'subject'}]},\n",
       "  'published': {'date-parts': [[2024, 6, 2]]}},\n",
       " {'institution': [{'name': 'Comprehensive R Archive Network',\n",
       "    'acronym': ['CRAN']}],\n",
       "  'indexed': {'date-parts': [[2024, 10, 22]],\n",
       "   'date-time': '2024-10-22T01:40:27Z',\n",
       "   'timestamp': 1729561227193,\n",
       "   'version': '3.28.0'},\n",
       "  'description': \"A unified interface to interact with various Large Language Model (LLM) APIs such as 'OpenAI' (see <https://platform.openai.com/docs/quickstart> for details), 'Anthropic' (see <https://docs.anthropic.com/en/api/getting-started> for details), 'Groq' (see <https://console.groq.com/docs/api-reference> for details), and 'Together AI' (see <https://docs.together.ai/docs/quickstart> for details). Allows users to configure API parameters, send messages, and retrieve responses seamlessly within R.\",\n",
       "  'reference-count': 0,\n",
       "  'publisher': 'The R Foundation',\n",
       "  'content-domain': {'domain': [], 'crossmark-restriction': False},\n",
       "  'content-updated': {'date-parts': [[2024, 10, 21]]},\n",
       "  'published-print': {'date-parts': [[2024, 10, 21]]},\n",
       "  'DOI': '10.32614/cran.package.llmr',\n",
       "  'type': 'dataset',\n",
       "  'created': {'date-parts': [[2024, 10, 22]],\n",
       "   'date-time': '2024-10-22T01:15:12Z',\n",
       "   'timestamp': 1729559712000},\n",
       "  'source': 'Crossref',\n",
       "  'is-referenced-by-count': 0,\n",
       "  'title': ['LLMR: Interface for Large Language Model APIs in R'],\n",
       "  'prefix': '10.32614',\n",
       "  'author': [{'given': 'Ali',\n",
       "    'family': 'Sanaei',\n",
       "    'sequence': 'first',\n",
       "    'affiliation': []}],\n",
       "  'member': '17266',\n",
       "  'content-created': {'date-parts': [[2024, 10, 21]]},\n",
       "  'container-title': ['CRAN: Contributed Packages'],\n",
       "  'deposited': {'date-parts': [[2024, 10, 22]],\n",
       "   'date-time': '2024-10-22T01:15:28Z',\n",
       "   'timestamp': 1729559728000},\n",
       "  'score': 18.648445,\n",
       "  'resource': {'primary': {'URL': 'https://CRAN.R-project.org/package=LLMR'}},\n",
       "  'issued': {'date-parts': [[2024, 10, 21]]},\n",
       "  'references-count': 0,\n",
       "  'URL': 'http://dx.doi.org/10.32614/cran.package.llmr',\n",
       "  'published': {'date-parts': [[2024, 10, 21]]}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c97c36",
   "metadata": {},
   "source": [
    "aaaaaaaaaaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55bc9b5",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/671d0150-ddd8-8007-af71-3bacc6bddf88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948e2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Define namespaces\n",
    "namespaces = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('example XML file (s00146-021-01327-5).xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1173ca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element '{http://www.tei-c.org/ns/1.0}TEI' at 0x74d350b327a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69fe143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A philosophical view on singularity and strong AI\n",
      "Publisher: Springer Science and Business Media LLC\n",
      "Date: 17 January 2022\n",
      "Author: Christian Hugo Hoffmann\n",
      "Keywords: ['Intelligence', 'Superintelligence', 'AI', 'Strong AI', 'Singularity', 'Artificial general intelligence']\n",
      "Abstract: More intellectual modesty, but also conceptual clarity is urgently needed in AI, perhaps more than in many other disciplines. AI research has been coined by hypes and hubris since its early beginnings in the 1950s. For instance, the Nobel laureate Herbert Simon predicted after his participation in the Dartmouth workshop that \"machines will be capable, within 20 years, of doing any work that a man can do\". And expectations are in some circles still high to overblown today. This paper addresses the demand for conceptual clarity and introduces precise definitions of \"strong AI\", \"superintelligence\", the \"technological singularity\", and \"artificial general intelligence\" which ground in the work by the computer scientist Judea Pearl and the psychologist Howard Gardner. These clarifications allow us to embed famous arguments from the philosophy of AI in a more analytic context.\n",
      "\n",
      "Body Content:\n",
      "\n",
      "Head: Introduction\n",
      "Paragraph: Human-level AI is still the standard 15-to-25 years away, just as it always has been.\n",
      "Paragraph: Steven \n",
      "                    \n",
      "Paragraph: Notwithstanding, it has since a long time transcended the circle of scientists and computer engineers by far. For example, the UK House of Lords Select Committee on AI opens the second chapter of their 2018 report \"AI in the UK: ready, willing and able?\" with the sharp critique that prevalent AI narratives, reflected in Terminator-style stories, \"were concentrating attention on threats which are still remote, such as the possibility of 'superintelligent' artificial general intelligence, while distracting attention away from more immediate risks and problems\" (Select Committee on Artificial Intelligence 2018: 23).\n",
      "Paragraph: By contrast, there is the potential for those who frown on restraints on the design of strong AI to propagate narratives skeptical of its capacities, so that policymakers see no need for regulation \n",
      "                    \n",
      "Paragraph: More systematically, \n",
      "                    \n",
      "Paragraph: Digital utopians (e.g., Larry Page from Google) and techno-skeptics (like Andrew Ng from China's Google, Baidu, or Rodney Brooks from MIT or Steven Pinker) concord that we should not worry about singularity, but for very different reasons: the latter are convinced that human level machine intelligence will not happen in the foreseeable future or not at all, while the former believe it will happen but it is virtually guaranteed to be a good thing (ibid.). The beneficial-AI movement (i.e., all the proponents of AI safety research like Elon Musk who founded OpenAI or Nick Bostrom who runs the Future of Humanity Institute in Oxford) feels that concern is warranted and useful, because AI risk analysis and discussion now increases the chances of a positive outcome. Finally, luddites (like Peter Krakaur and his blog Lopsider) expect an adverse outcome or cataclysmic events and, thus, oppose AI. The upshot and bottom line from this matrix is perhaps simply that it is not clear if or when we humans or the machines we teach will succeed in building strong AI. Notwithstanding, most AI experts and practitioners are cautious about making predictions about both the timescale and successes of AI.\n",
      "Paragraph: According to \n",
      "                    \n",
      "Paragraph: In this paper, we take a step back from this heated debate. Ex ante, we are against over-hyping technologies as well as the counter-myth that singularity will not happen. We do not have any a priori reasons to completely dispel the possibility that we will eventually build strong AI. Therefore, we devote this article to canvassing what speaks in favor of and what speaks against the hypothesis of technological singularity or strong AI, based on clearly specified terms of Artificial General Intelligence, Strong AI, Superintelligence, and Singularity. Here the rubber finally meets the road. Source: \n",
      "                    \n",
      "\n",
      "Head: General\n",
      "Paragraph: Third wave AI Fourth wave AI\n",
      "\n",
      "Head: Narrow\n",
      "\n",
      "Head: Status quo Not possible\n",
      "\n",
      "Head: AI\n",
      "\n",
      "Head: Weak Strong\n",
      "\n",
      "Head: Time\n",
      "Paragraph: The remainder of this article is organized as follows: in the next chapter, we present and draw on two pieces of prior work, namely \n",
      "                    \n",
      "\n",
      "Head: Prior work: the causal ladder and the theory of multiple intelligences\n",
      "Paragraph: We hold the computer scientist Judea Pearl's (2018a) so called causal ladder as well as the psychologist Howard \n",
      "                    \n",
      "Paragraph: In other words, we do not refer to Pearl to claim to exhaust \"intelligence\"; rather, \"intelligence\" is a family concept. A corollary of, or hypothesis following from drawing on both Pearl and Gardner as the building block for the definitions in Sect. 3 is that also the highest form of, let's say, personal and musical intelligence come with imagination powers. If we attempted to harmonize or streamline intelligence outside of Pearl's taxonomy of causal learning to be presented in the next section, then we would simply violate the facts collected about the multidirectionality of intelligence.\n",
      "\n",
      "Head: Pearl's causal hierarchy\n",
      "Paragraph: This work sets up the hypothesis that learning, and, more precisely, causal learning is at the center of intelligence. The reason learning is so central to intelligence and intelligent behavior is, according to \n",
      "                    \n",
      "Paragraph: There are two ways we can get (firsthand) evidence about an event: we can perceive the event happen, or we can make the event happen. These two ways of receiving data-seeing and doing-can lead to radically divergent conclusions in terms of learning, even when the evidence itself is otherwise identical \n",
      "                    \n",
      "\n",
      "Head: Rung one of the ladder\n",
      "Paragraph: The first rung, seeing or observing or, as we will also denote it, identifying, entails the detection of regularities, patterns and associations in our environment and is shared, according to \n",
      "                    \n",
      "Paragraph: We say that one event is associated with another if observing one changes the likelihood of observing the other. In statistics, a thriving, but after all causality-free enterprise, this type of relationship is called correlation, thereby reducing a large body of data. But, data per se is profoundly dumb. Naked data can tell you that this author is more into philosophy (books) than economics (books), but they cannot tell you why. In many situations more like this, in everyday life, science or business, we witness that mere data is not enough. No system, human, animal or machine, can determine what is going on in the world merely by \"looking out\" and seeing or sampling it \n",
      "                    \n",
      "\n",
      "Head: Rung two of the ladder\n",
      "Paragraph: We step up the next level of causal queries when we begin to change the world by taking actions. In other words, a new kind of knowledge, absent from data, which we find at rung two of the ladder, is needed and consists of doing or intervention (which we wish to perform mentally before we decide whether and how to do it in real life). Intervention ranks higher than association because it encapsulates not just seeing but amending what is and entails planning as well as predicting the effect(s) of deliberate alterations to produce a desired outcome. Pearl spots tool users, such as early humans on the second rung if they act by planning and not merely by imitation. An effect of such tool use is a sharpened \"understanding of causality of events and of the self as one of the drivers of the causality\" (Hiraiwa-Hasegawa 2019: 171). Or as \n",
      "                    \n",
      "Paragraph: While reasoning about interventions is a vital step on the causal ladder, it is not sufficient to answer all causal questions of interest. We might wonder, my bad mood is gone, but why? Was it the comedy I watched? The birds that I have heard singing during a warm and sunny spring day? The phone call I received from a good friend of mine? These queries take us to the top rung of the ladder of causation, the level of counterfactuals, because to answer them we must go back in time, change history, and ask: \"What would have happened if I had not watched the comedy?\" Or more generally speaking: \"Was it X that caused Y? What if X had not occurred? What if I had acted differently?\" No experiment in the world can deny the effect of a measure that has already been taken and compare the two outcomes. Therefore, we have to import a whole new kind of knowledge.\n",
      "\n",
      "Head: Rung three of the ladder\n",
      "Paragraph: Good predictions crop up in tandem with good explanations \n",
      "                    \n",
      "Paragraph: Counterfactual reasoning is retrospective reasoning; an ability that according to Pearl most distinguishes humans from animal intelligence, as well as from model-blind versions of AI and machine learning. It tells us what would have happened if events other than the ones we are currently observing had happened.\n",
      "Paragraph: Counterfactuals are placed at the top of the hierarchy since they subsume interventional and associational questions \n",
      "                    \n",
      "Paragraph: Counterfactuals possess an eminently problematic relationship with data since data are, by definition, facts \n",
      "                    \n",
      "\n",
      "Head: Gardner's theory of eight human intelligences\n",
      "Paragraph: We have sympathies for \n",
      "                    \n",
      "Paragraph: According to this view, people can be intelligent in a variety of ways (cf. e.g., \n",
      "                    \n",
      "Paragraph: sometimes those intelligences work in concert within a domain and are valued in a wide range of cultures \n",
      "                    \n",
      "Paragraph: 1. Linguistic intelligence encompasses our use of language to predict, explain, convince and remember information as well as to clarify meaning. 2. Logical-mathematical intelligence captures the ability to operate on relationships in abstract symbol systems and to assess ideas and quantities in accordance with the laws of (formal) logic. 3. Spatial intelligence involves skill in perceiving and transforming visual-spatial relationships, i.e., relationships of objects' position in space.\n",
      "Paragraph: Even though the remaining five types are not measured by conventional intelligence tests, they are valued in most cultures. 4. Bodily-kinesthetic intelligence denotes the adept use of one's body. 5. Musical intelligence includes sensitivity to various musical properties as well as the ability to produce, appreciate and combine pitch, tones, and rhythms. 6. Intrapersonal intelligence reflects the understanding of one's own motives, strengths, weaknesses and emotions. 7. Interpersonal intelligence accordingly reflects the understanding of, and sensitivity to, other people's motives, behaviors, and emotions. Finally, 8. Naturalist intelligence indicates an understanding of the patterns found in natural environments.\n",
      "Paragraph: Gardner's proposal of multiple intelligences is a refreshing exception to the general rule that social and emotional intelligence play little role in scientific theories of intelligence \n",
      "                    \n",
      "Paragraph: Apart from that, we also venerate the opening of Gardner's list and submit that it is no coincidence that he lists linguistic intelligence first. Language is arguably the most efficacious tool for learning-the mother of all learning mechanisms and the single thing that most makes humans stand out \n",
      "                    \n",
      "Paragraph: Gardner invokes evidence to underpin the existence of the eight relatively independent intelligences. One type of evidence, for example, consists of neuropsychological data showing that damage to certain areas of the brain impairs some abilities, but not others \n",
      "                    \n",
      "Paragraph: Much work on intelligence and the brain where it is embedded has been anthropocentric-\"intelligence, the ability to make human-like decisions\" \n",
      "                    \n",
      "\n",
      "Head: Concept clarification: artificial general intelligence, strong AI, superintelligence, and singularity\n",
      "Paragraph: We identify four waves of AI development: the first between the 1950s and 1990s is marked by so-called good old-fashioned AI (GOFAI, cf. Haugeland 1997), and currently, since the late 1990s, we have been living in a time of the machine learning paradigm, the second wave. If the next, third, wave AI after the machine learning paradigm is about more general intelligence compared to today where AI systems can either \"play\" Go or chess or write op-eds for the Guardian (Marcus 2020), then the fourth wave is about strong intelligence in artifacts or, simply, about strong AI. Broad intelligence, I suppose, will be reached earlier since it would consolidate extant machine capabilities (like not just \"playing\" chess, but also Go), whereas we are not anywhere near to endowing machines with fully-fledged understanding which is on a higher level (see Sect. 2.1. and Fig. \n",
      "                    \n",
      "Paragraph: Weak AI purports only that computers, we are all too well acquainted with, provide an expedient tool for rigorous formulation and testing of hypotheses about the mind \n",
      "                    \n",
      "Paragraph: In light of the alleged accelerating advancements in disruptive technologies, not limited to AI, but also counting genetic engineering and nanotechnology, the notion of singularity was brought into wider circulation by \n",
      "                    \n",
      "Paragraph: The other, radically different scenario, which is of higher relevance for our purposes, postulates that, at some future (omega) point S, AI in the sense of software-based synthetic minds materializes as the \"singular\" outcome of accelerating advancements in computer technology \n",
      "                    \n",
      "Paragraph: In essence, the argument runs like this in the words of \n",
      "                    \n",
      "Paragraph: (3) If it does continue, our technological achievements will become so great that our bodies, minds, societies, and economies will be radically transformed. (4) Therefore, it is likely that this disruptive transformation will occur.\" Or a bit more formally, in the spirit of \n",
      "                    \n",
      "Paragraph: Premise 1:\n",
      "Paragraph: There will be SAI (created by HI and such that SAI = HI; and due to SAI S will occur) Premise 2:\n",
      "Paragraph: If there is SAI, there will be SAI+ (created by SAI) Premise 3:\n",
      "Paragraph: If there is SAI+, there will be SAI++ (created by SAI+) Conclusion:\n",
      "Paragraph: There will be SAI++ (= superintelligence will occur, sometimes also denoted by S or singularity; cf. \n",
      "                    \n",
      "Paragraph: Apart from the twin notions of acceleration and discontinuity, accounts of singularity seem to dissent from each other on quite a number of aspects: causes and consequences, empirical content of the conjecture, on the timescale (e.g., an event or a period), and even on its nature: e.g., the dual use of S in the previous argument or the arrival of Homo Deus vs. of (super-) strong AI (not belonging to the genus Homo)? These dissents, casting doubt whether there is a coherent notion of singularity at all, are paired with a plethora of open guiding questions for research such as, what, if anything, can be said to be accelerating?\n",
      "Paragraph: To prevent this Babylonian confusion of tongues to grow any further, we thus suggest specifying the key terms as follows.\n",
      "Paragraph: We first propose to specify \n",
      "                    \n",
      "Paragraph: A second clarification concerns then the concept \"superintelligent AI\" (SIAI): X is a SIAI if, and only if, X covers all three levels of Pearl's causal hierarchy for the eight human intelligences of Gardner's theory of multiple intelligences and at least one additional and distinct intelligence on par with the eight or only those eight intelligences with a superhuman performance for at least one of the four intelligences (\"super-human performance\" as coined by Rajani 2011) and no sub-human performance for any of the intelligences.\n",
      "Paragraph: Finally, the adjusted definition of (technological) singularity runs as follows: an event E qualifies as a singularity S if, and only if, SAI emerges in E and SIAI directly thereafter, whereby \"directly\" signifies that there is either a direct causal relationship or a short causal chain between SAI and SIAI in the sense that the former brings about the latter.\n",
      "Paragraph: (For the sake of completeness, \"artificial general intelligence\" (AGI) brings up the rear even though it is not at stake in the following chapter 4, but in order to sharpen the demarcation lines between the terms: X is a AGI if, and only if, X is not a SAI and covers more than one intelligence for possibly varying causal learning capabilities. We concede that this initial definition is not satisfactory and in need of an overhaul by future work because, while it is clear what multiple intelligences stand for in the human case (cf. \n",
      "                    \n",
      "\n",
      "Head: Reviewing three arguments in the debate on singularity and strong AI\n",
      "Paragraph: The next three subchapters portray one argument in favor of reckoning with SAI and a singularity S. (4.1.). The last two subchapters are devoted to the opposite standpoint, sketching two reasons sowing the seeds of doubt about the occurrence of S and SAI. In both cases, we pin down the arguments by bringing in our precise definitions from Sect. 3. \n",
      "                    \n",
      "\n",
      "Head: Hardware-based arguments by Moravec and Kurzweil\n",
      "\n",
      "Head: Presentation of the argument\n",
      "Paragraph: The hardware-based argument for singularity rests on a solid foundation in the sense that it is quite common to hear intelligence explained in part as some form of mental speed \n",
      "                    \n",
      "Paragraph: The former is per se unproblematic, the latter as well as the following are not. \n",
      "                    \n",
      "Paragraph: Moore's law is named after one of the founders of the Intel microprocessor manufacturing company, and states that the number of transistors in a dense integrated circuit, i.e., the computational capacities (e.g., electronic component densities and electronic signal processing speeds) of integrated circuits double about every two years. The density of components on an integrated circuit is closely tied to the price-performance of computing power. The law was established because it has been observed that the number of transistors in Intel microprocessors has in fact doubled every two years since the early 1970s \n",
      "                    \n",
      "Paragraph: Premise The singularity S will be reached\n",
      "Paragraph: Our formal comment on C1 aside, C1 has also been under attack content-wise, rendering the collapse of the argument inescapable. For at least four decades, computing power has increased exponentially, roughly in accordance with Moore's law. However, a speed bump is on the horizon as an end to Moore's law is probable: \"Though several information technologies have been advanced at an exponential or superexponential [i.e., hyperbolic, C.H.] rate for many decades, this trend may not hold for much longer\" \n",
      "                    \n",
      "Paragraph: Growth processes, including Moore's law, that (for some time) are observed to follow exponential patterns eventually reveal themselves to be following S-curves thus banning runaway situations which would be prescribed by a singularity S (Modis 2012: 311): \"It is now unanimously expected that this growth pattern [according to Moore's law] will eventually turn into an S-curve and reach a ceiling\" (ibid.: 316). (In this context, allow me also the mathematical subtlety that, unlike the advocates of a technological singularity, one should not speak of exponential but hyperbolic growth if one believes in singularity, since the increase of an exponential function is relatively slow and always finite.)\n",
      "Paragraph: If we assume for a transient moment that the soundness of the hardware-based argument would only hinge on the empirical support for C1 (which is what Kurzweil 2012, seems to be implying), \n",
      "                    \n",
      "Paragraph: In other words, when Kurzweil spells out computer hardware advancements according to his LOAR, then he delineates a pattern of ongoing exponential growth made up of a cascade of S-curves, each of them related to one out of many what he calls paradigms. Where could another boost for hardware development, another \"paradigm\", come from? Perhaps, from a new kind of computing dubbed quantum computing. Its essential feature is easy enough to grasp at the intuitive level, e.g. following \n",
      "                    \n",
      "Paragraph: [Our conventional c]omputers today work by converting information to a series of binary digits, or bits, and operating on these bits using integrated circuits (ICs) containing billions of transistors. Each bit has only two possible values, 0 or 1. Through manipulations of these so-called binary representations, computers [do all their computations]. A quantum computer also represents information as a series of bits, called quantum bits, or qubits. Like a normal bit, a qubit can be either 0 or 1, but unlike a normal bit, which can only be 0 or 1, a qubit can also be in a state where it is both at the same time [a superposition between the two states of zero and one]. When extended to systems of many qubits, this ability to be in all possible binary states at the same time gives rise to the potential computational power of quantum computing (National Academies of Sciences: Engineering, and Medicine, 2019: 24), which could be \"truly trillions of trillions of trillions of times above those of current classical computing capacities\" \n",
      "                    \n",
      "\n",
      "Head: Discussion of the argument\n",
      "Paragraph: At the risk of stating the obvious, \"[t]he chief challenges in AI, relative to the human case, consist in finding the right computer programs, not faster and faster computers upon which to implement these programs\" \n",
      "                    \n",
      "Paragraph: Firstly, the intelligence explosion, unleashed by S and culminating in SIAIs, and the speed explosion, characterized by colossal hardware improvements (along with software improvements which are fatally neglected by the hardwarebased arguments), are logically independent of each other. In principle, there could be an intelligence explosion without a speed explosion and a speed explosion without an intelligence explosion. AI may have an advantage over human brains when it comes to data storage and the speed of data processing. But storage capacity and speed do not mean proliferated intelligence.\n",
      "Paragraph: Speed deserves only secondary attention, speed matters for intelligence only in the ceteris paribus sense (see also our definition of SIAI): all other things being equal, the faster the test subject performs on an adequate task, the smarter she is.\n",
      "Paragraph: A further pervasive fallacy which thus underlies this singularity idea reliant on Moravec's hardware-based argument is the monolithic view of intelligence that moreover usually confounds the subject with the intellectual faculty itself. To grosso modo extrapolate from success in one aspect relevant to cognition (like better hardware) to success in all aspects of cognition is to succumb to the illusion of progress. In other words, C3, which presupposes human-level learning capabilities for at least eight intelligences, does not follow from C2.\n",
      "Paragraph: Finally, computational capacities either just represent a tiny fraction of the gamut of intelligence (i.e., computation as a cognitive trait or, when interpreted even more narrowly, computation as one pillar of logical-mathematical intelligence). Or computing is taken as such a basic and abstract unit that the mind itself is treated as a computational system (e.g., see the computational metaphor or the computational theory of mind; Rescorla 2020). \n",
      "                    \n",
      "Paragraph: With regard to the multidimensionality of intelligence, systems' mere computational power leaves us in the dark about their causal learning capabilities which, following Pearl, we identified as the principal theme of intelligence. Today's deep learning systems like GPT-3 or AlphaGo and their relatives excel at computing; yet, no matter how much more computational power and speed they gain (ceteris paribus), they will never get past level one (the level of associations, correlations, seeing, and observing, see 2.1.).\n",
      "Paragraph: Hence, SAI, S, and SIAI, as specified in this paper, remain at an unattainable distance; Moravec, Kurzweil, and adherents pose utterly deceptive questions with their argument.\n",
      "\n",
      "Head: The Gödelian attacks\n",
      "Paragraph: To begin with, everyone can concord that Kurt Gödel's contributions to formal logic as a discipline of mathematics, in particular his Incompleteness Theorems \n",
      "                    \n",
      "Paragraph: And indeed, in (at least prima facie) stark contrast to obvious and curious misapprehensions of Gödel's findings, the connection between formal systems, i.e. what his work is actually about, and computers is not difficult to make out because the former and the latter are simply equivalent if the latter are seen as Turing machines-but beware of an inflationary use \n",
      "                    \n",
      "\n",
      "Head: Presentation of the argument\n",
      "Paragraph: In nuce, the Gödelian arguments (from \n",
      "                    \n",
      "Paragraph: The story begins with Gödel who proved in 1931 that for any consistent formal system powerful enough to do a certain sort of arithmetic like the Principia Mathematica, there will be a true sentence-the system's Gödel sentence -that the system cannot prove (for more detailed and accurate accounts of his proof, cf. Nagel and Newman 2001, or Raatikainen 2020). Gödel thought that his incompleteness theorems had bearing on the question of mechanism, of whether the human mathematician can be replaced by a machine, and he thought that \"will never be possible\" \n",
      "                    \n",
      "Paragraph: But as usually, Gödel was cautious and his position was quite subtle -even though he went so far as to call his finding, the disjunction (see the next sentence), a \"mathematically established fact\" \n",
      "                    \n",
      "Paragraph: The first to exceed that prudency and to produce a fullfledged Gödelian argument against SAI-i.e., to establish that Gödel's incompleteness theorems imply that the first disjunct holds-was the Oxford philosopher J. R. \n",
      "                    \n",
      "Paragraph: We try to suppose that the totality of methods of (unassailable) mathematical reasoning that are in principle humanly accessible can be encapsulated in some (not necessarily computational) sound formal system FF. A human mathematician, if presented with FF, could argue as follows (bearing in mind that the phrase \"I am FF\" is merely a shorthand for \"FF encapsulates all the humanly accessible methods of mathematical proof\"): (A) \"Though I don't know that I necessarily am FF, I conclude that if I were, then the system FF would have to be sound and, more to the point, F′F′ would have to be sound, where F′F′ is FF supplemented by the further assertion \"I am FF.\" I perceive that it follows from the assumption that I am FF that the Gödel statement G(F′) G(F′) would have to be true and, furthermore, that it would not be a consequence of F′F′. But I have just perceived that \"If I happened to be FF, then G(F′)G(F′) would have to be true,\" and perceptions of this nature would be precisely what F′F′ is supposed to achieve. Since I am therefore capable of perceiving something beyond the powers of F′F′, I deduce that I cannot be FF after all. Moreover, this applies to any other (Gödelizable) system, in place of FF.\"\n",
      "\n",
      "Head: Discussion of the argument\n",
      "Paragraph: The close examination of the cogency of that sophisticated argument for the first disjunct becomes very technical and elaborate as the argument involves sentences that are provably indeterminate (just as the Liar sentence itself), and it applies to these sentences inference rules that are legitimate only when applied to determinate sentences \n",
      "                    \n",
      "Paragraph: Instead, I summarize that the assessment of Gödel's work is ongoing and not completed and I contribute to it by four more short comments in reference to my own paper on that matter. Firstly, the Gödelian arguments against SAI, so far, do not appear to carry much force. Those attempts suffer from the shortcoming that Gödelian limitations have not been convincingly shown to not apply to humans. Moreover, the theses that Gödel, Lucas, Penrose, and others develop from the incompleteness theorems depend on highly idealized assumptions about both the nature of the human mind and the nature of machines. Coming from our definitions of SAI and S we ought to remain more agnostic though.\n",
      "Paragraph: What about the assumption that the human mind is consistent? In practice, mathematicians certainly make errors and thence arrive at false conclusions that in some cases go long undetected. Penrose, among others, has pointed out that when errors are detected, mathematicians seek out their source and correct them (cf. \n",
      "                    \n",
      "Paragraph: Thirdly, barring the pessimistic notion of the accidental inexplicability of the brain or mind, the project of AI could even receive a boost from Gödel's groundwork on the constructive side which is very much in line with Pearl's thrust in chapter 2.1. If we recognize that Gödel's proof nurtures the notion that \"a high-level view of a system may contain certain explanatory power which simply is absent on the low levels \" \n",
      "                    \n",
      "Paragraph: Finally, in light of our plea for the multidirectionality and plurality of intelligence, it is tantamount to hubris to think that mathematics and metamathematics alone could determine what minds in general are capable of and what they are not capable of. With our definitions of SAI in mind (where logical-mathematical intelligence is only one out of eight intelligences), routes towards SAI and S (which are far from being discovered) are not necessarily blocked by Gödelian arguments, no matter if they prove to be sound or not.\n",
      "\n",
      "Head: Searle's Chinese Room thought experiment\n",
      "Paragraph: In what may be the most influential thought experiment in the history of AI \n",
      "                    \n",
      "\n",
      "Head: Presentation of the argument\n",
      "Paragraph: This intriguing and seminal essay on minds, brains, and programs offered an argument against the contention of strong AI. \"The argument\", Searle writes in a brief restatement, \"proceeds by the following thought experiment\": Imagine a native English speaker who knows no Chinese locked in a room full of boxes of Chinese symbols (a data base) together with a book of instructions for manipulating the symbols (the program). Imagine that people outside the room send in other Chinese symbols which, unknown to the person in the room, are questions in Chinese (the input). And imagine that by following the instructions in the program the man in the room is able to pass out Chinese symbols which are correct answers to the questions (the output). The program enables the person in the room to pass the Turing Test for understanding Chinese but he does not understand a word of Chinese. \n",
      "                    \n",
      "Paragraph: Searle's conclusion on the constructive side: The Chinese Room demonstrates that something more is needed for intentionality than formal computations. And that \"something\" is, following Searle, the causal powers of neuroprotein. Our main takeaway from his imaginative (albeit ethnocentric) illustration is quite tangible-simulation is not the real thing. Merely shifting symbols around in a way that looks like (linguistic) understanding is not sufficient for it. A computer, as Terry \n",
      "                    \n",
      "\n",
      "Head: Discussion of the argument\n",
      "Paragraph: Searle was attacking a by now largely superseded understanding of AI, i.e., GOFAI (good old-fashioned AI). Nonetheless, the Chinese Room spawned a flourishing philosophical industry whose mills are still spinning merrily. Many readers acknowledged that Searle's empty-symbolism argument proved just what he said it proved, while not less readers saw it as fundamentally wrong-headed (Boden 2015: 98). On top of that, those who saw it as going astray gave different accounts of just what was fatal with it, and to some Searle (2014) has replied too. This is not the place to summarize the ever-lengthening debate or to rehearse what is wrong with Searle's Chinese Room argument (for an account at length cf. Cole 2020). Instead, we poke three holes in Searle's original argument (against the backdrop of our definitions) in the following and derive some learnings.\n",
      "Paragraph: Firstly, we concord that understanding is indispensable for SAI: no SAI without understanding. We diverge from \n",
      "                    \n",
      "Paragraph: We, by contrast, took another, earlier exit (out of the Searlian edifice) in this paper by discarding the identification of understanding with intentionality right away because the latter presupposes that an agent possesses inner or mental states which would expel many machines (and probably many animals) in the sense of different kinds of intelligence ex ante, i.e., on dogmatic grounds. If we embark on the endeavor of making sense of human, animal and machine intelligence with preformed concepts (of understanding or intelligence for that matter) that are not even applicable to the objects of investigation, then the whole journey is thwarted before it has even begun. Furthermore, we argued following Pearl in 2.1. that understanding is sufficient for intelligence, but not necessary; and, conversely, it is necessary for SAI, but not sufficient for it: understanding is sufficient for intelligence because we saw in Fig. \n",
      "                    \n",
      "Paragraph: So, shall we just conclude that our and Searle's (1980) understanding of \"understanding\", and \"intelligence\", respectively, are incompatible since they rest on different foundations? Not really. It is neither prerequisite nor desirable to stop at that point, the latter not least due to the observation that \"[u]nderstanding can still sound frighteningly unempirical and elusive\" \n",
      "                    \n",
      "Paragraph: By this, we do not mean that mere programs, which are abstract computational objects and purely syntactic, are candidates for possession of comprehension. The crucial role of implementation has to be respected since implementations can have semantic content. Searle's Chinese Room argument \"gains its purchase on our intuitions by implementing the program in a bizarre way that obscures the realization of the relevant causal dynamics [a sense of 'syntax', so to say, in which implementations are syntactic]\" \n",
      "                    \n",
      "Paragraph: Understanding is not a matter of black and white, but, following the well-tested Darwinian perspective of gradualism, it comes in degrees. Understanding entails making inferences and results in the ability to make further inferences. There are, of course, a great many possible levels of understanding and, accordingly, different kinds of inference lead to different depths of understanding. So we have argued.\n",
      "Paragraph: Secondly, even more from our today's standpoint in the midst of the predominance of machine and deep learning, Searle is attacking a straw man. Even though \n",
      "                    \n",
      "Paragraph: \"One of the most notorious failures of the early days of computers was machine translation. […] What the machine translation programs lacked \n",
      "                    \n",
      "Paragraph: When we bemoan that Alexa, Siri, and their relatives of the second AI wave do not know what they are talking about when they \"tell\" you about the weather forecast or about what wine goes with your meal-or to that matter, that their utterances matter only under interpretation by us -, then we are not referring to formality. Unlike Searle, we do not make the case that a formal system cannot have real semantics, since the interpretations are unanchored, and can be assigned at whim: \"I would go to court to deny that the symbols in present day AI systems are 'formal' in [the Searlian] sense. Some contemporary systems, in particular, are plugged into the world in such a way that their symbols are unambiguously grounded.\" \n",
      "                    \n",
      "Paragraph: As a final upshot of the debate we wish to point out that at least some philosophers, being vocal about AI, lack the technical knowledge in computer science to assess the activities and progress in the field. To those who refuse to live in the present, they are more foolish commentators than experts. Then, against the principle of charity or of vouchsafing the benefit of a doubt, they simplistically take it for granted that all computation is Turing computation, and as such semantically empty; that there is erroneously just the abstract, in lieu of the implementations of programs where the implementation relation relates the abstract and concrete domains.\n",
      "\n",
      "Head: Conclusion\n",
      "Paragraph: The often nebulous terms \"Strong AI\" (SAI), \"Superintelligence\" (SIAI), \"Singularity\" (S), and \"Artificial General Intelligence\" (AGI) were specified and put to work. Based on our contribution to concept clarification in Sect. 3, we reviewed three arguments from philosophy of AI. We found that none of the three arguments portrayed and discussed is sound. The conclusion is that there appear to be neither enforcers of singularity S or strong AI SAI, nor any in-principle barriers to the ambitions of SAI.\n",
      "Paragraph: My own take on S and SAI is that I do not relegate the possibility that AI will eventually reach human or superhuman intelligences. However, I am also convinced that there will be no uncontrolled exponential growth. Given empirical evidence, it is much more likely that we humans will have to program most of the intelligence into the AIs ourselves. Scientific knowledge, commonsense, education, and innate templates are all indispensable for achieving SAI; and, as we learned from Pearl, only creatures that are already on the third rung of the causal ladder (i.e., humans) can pass it on.\n",
      "Paragraph: Our experience with most AI systems so far suggests that the marginal yield is rapidly decreasing and frequent trend changes are taking place, which will not spare deep learning as one of the most popular and hyped applications of AI nowadays \n",
      "                    \n",
      "Paragraph: Maybe global AI may improve infinitely, but to what extent its overall intelligence increases could be limited. If, for instance, each generation increases by 50% compared to the previous one, then, according to old insights such as from Zeno's \"paradox\" on Achilles and the tortoise, the initial intelligence can at most double, because the infinite sum adds up to a maximum of 2.\n",
      "Paragraph: The declaration that SAI and S can happen concerns still most distant possible worlds and is rather uninteresting because it lacks operational significance. However, anything beyond is long on faith, and short on rigorous argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to extract text from an element\n",
    "def get_text(element):\n",
    "    return element.text if element is not None else None\n",
    "\n",
    "# Extract required elements\n",
    "title = get_text(root.find('.//tei:titleStmt/tei:title', namespaces))\n",
    "publisher = get_text(root.find('.//tei:publicationStmt/tei:publisher', namespaces))\n",
    "date = get_text(root.find('.//tei:publicationStmt/tei:date', namespaces))\n",
    "\n",
    "# Extract author information\n",
    "author_elem = root.find('.//tei:author/tei:persName', namespaces)\n",
    "author = \" \".join(filter(None, [\n",
    "    get_text(author_elem.find('tei:forename[@type=\"first\"]', namespaces)),\n",
    "    get_text(author_elem.find('tei:forename[@type=\"middle\"]', namespaces)),\n",
    "    get_text(author_elem.find('tei:surname', namespaces))\n",
    "]))\n",
    "\n",
    "# Extract keywords\n",
    "keywords = [get_text(term) for term in root.findall('.//tei:keywords/tei:term', namespaces)]\n",
    "\n",
    "# Extract abstract\n",
    "abstract_elem = root.find('.//tei:abstract/tei:div/tei:p', namespaces)\n",
    "abstract = get_text(abstract_elem)\n",
    "\n",
    "# Recursive function to extract headings and paragraphs from the body\n",
    "def extract_body_content(element):\n",
    "    content = []\n",
    "    for div in element.findall('tei:div', namespaces):\n",
    "        head = get_text(div.find('tei:head', namespaces))\n",
    "        paragraphs = [get_text(p) for p in div.findall('tei:p', namespaces)]\n",
    "        content.append({\n",
    "            'head': head,\n",
    "            'paragraphs': paragraphs\n",
    "        })\n",
    "        # Recursive call to capture nested content\n",
    "        content.extend(extract_body_content(div))\n",
    "    return content\n",
    "\n",
    "# Extract content from the body\n",
    "body_content = extract_body_content(root.find('.//tei:body', namespaces))\n",
    "\n",
    "# Print extracted data\n",
    "print(\"Title:\", title)\n",
    "print(\"Publisher:\", publisher)\n",
    "print(\"Date:\", date)\n",
    "print(\"Author:\", author)\n",
    "print(\"Keywords:\", keywords)\n",
    "print(\"Abstract:\", abstract)\n",
    "print(\"\\nBody Content:\")\n",
    "for section in body_content:\n",
    "    print(\"\\nHead:\", section['head'])\n",
    "    for paragraph in section['paragraphs']:\n",
    "        print(\"Paragraph:\", paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc9f1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notwithstanding, it has since a long time transcended the circle of scientists and computer engineers by far. For example, the UK House of Lords Select Committee on AI opens the second chapter of their 2018 report \"AI in the UK: ready, willing and able?\" with the sharp critique that prevalent AI narratives, reflected in Terminator-style stories, \"were concentrating attention on threats which are still remote, such as the possibility of \\'superintelligent\\' artificial general intelligence, while distracting attention away from more immediate risks and problems\" (Select Committee on Artificial Intelligence 2018: 23).'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(root.findall('.//tei:p', namespaces)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13c22f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A philosophical view on singularity and strong AI'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(root.find('.//tei:titleStmt/tei:title', namespaces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa27a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A philosophical view on singularity and strong AI\n",
      "Publisher: Springer Science and Business Media LLC\n",
      "Date: 17 January 2022\n",
      "Author: Christian Hugo Hoffmann\n",
      "Keywords: ['Intelligence', 'Superintelligence', 'AI', 'Strong AI', 'Singularity', 'Artificial general intelligence']\n",
      "Abstract: More intellectual modesty, but also conceptual clarity is urgently needed in AI, perhaps more than in many other disciplines. AI research has been coined by hypes and hubris since its early beginnings in the 1950s. For instance, the Nobel laureate Herbert Simon predicted after his participation in the Dartmouth workshop that \"machines will be capable, within 20 years, of doing any work that a man can do\". And expectations are in some circles still high to overblown today. This paper addresses the demand for conceptual clarity and introduces precise definitions of \"strong AI\", \"superintelligence\", the \"technological singularity\", and \"artificial general intelligence\" which ground in the work by the computer scientist Judea Pearl and the psychologist Howard Gardner. These clarifications allow us to embed famous arguments from the philosophy of AI in a more analytic context.\n",
      "\n",
      "Body Content:\n",
      "\n",
      "Head: Introduction\n",
      "Paragraph: Human-level AI is still the standard 15-to-25 years away, just as it always has been.\n",
      "Paragraph: Steven \n",
      "                    Pinker (in Brockman 2015) If past predictions are any indication, the only thing we know today about tomorrow's science and technology is that it will be radically different than whatever we predict it will be like. The controversy over singularity serves as good evidence for this adage.\n",
      "                \n",
      "Paragraph: Notwithstanding, it has since a long time transcended the circle of scientists and computer engineers by far. For example, the UK House of Lords Select Committee on AI opens the second chapter of their 2018 report \"AI in the UK: ready, willing and able?\" with the sharp critique that prevalent AI narratives, reflected in Terminator-style stories, \"were concentrating attention on threats which are still remote, such as the possibility of 'superintelligent' artificial general intelligence, while distracting attention away from more immediate risks and problems\" (Select Committee on Artificial Intelligence 2018: 23).\n",
      "Paragraph: By contrast, there is the potential for those who frown on restraints on the design of strong AI to propagate narratives skeptical of its capacities, so that policymakers see no need for regulation \n",
      "                    (Baum 2018). And the idea of or phantasies on strong AI have not ceased from entering philosophy either, but, for example, unleashed visions of grandeur: \"If we could just 'program things up', we dreamed, we could put paid to thousands of years of philosophy, surround ourselves with intelligent companions, and understand the human condition\" (Cantwell Smith 2019: 1). That bravado has been both fueled (e.g., \n",
      "                    Chalmers 2010) and disparaged (e.g., Searle 2014) in the literature.\n",
      "                \n",
      "Paragraph: More systematically, \n",
      "                    Tegmark (2018: 31) portrayed passionate disagreements about strong AI, even or especially among experts \n",
      "                    (Tetlock 2005), reminding us of \n",
      "                    Turing's (1950) reservations about polls. The dissent is centered around two questions: When (if ever) will strong AI or singularity happen (for this poll and Table \n",
      "                    1, respectively, the two terms can be used interchangeably because of how sloppy people deal with them), and will it be a good or bad thing for humanity? For now, we conceive of the shiny notion of technological singularity (henceforth, simply singularity) as \"an event or phase that will radically change human civilization, and perhaps even human nature itself […]\" \n",
      "                    (Eden et al. 2012: 1) (Table \n",
      "                    2).\n",
      "                \n",
      "Paragraph: Digital utopians (e.g., Larry Page from Google) and techno-skeptics (like Andrew Ng from China's Google, Baidu, or Rodney Brooks from MIT or Steven Pinker) concord that we should not worry about singularity, but for very different reasons: the latter are convinced that human level machine intelligence will not happen in the foreseeable future or not at all, while the former believe it will happen but it is virtually guaranteed to be a good thing (ibid.). The beneficial-AI movement (i.e., all the proponents of AI safety research like Elon Musk who founded OpenAI or Nick Bostrom who runs the Future of Humanity Institute in Oxford) feels that concern is warranted and useful, because AI risk analysis and discussion now increases the chances of a positive outcome. Finally, luddites (like Peter Krakaur and his blog Lopsider) expect an adverse outcome or cataclysmic events and, thus, oppose AI. The upshot and bottom line from this matrix is perhaps simply that it is not clear if or when we humans or the machines we teach will succeed in building strong AI. Notwithstanding, most AI experts and practitioners are cautious about making predictions about both the timescale and successes of AI.\n",
      "Paragraph: According to \n",
      "                    Tegmark (2018: 130), the world's leading AI authorities are divided, most of them making estimates ranging from decades to centuries and some even guessing never, which instigates him to draw the nice metaphoric conclusion: \"Forecasting is tough because, when you're exploring uncharted territory, you don't know how many mountains separate you from your destination. Typically you see only the closest one, and need to climb it before you can discover your next obstacle.\"\n",
      "                \n",
      "Paragraph: In this paper, we take a step back from this heated debate. Ex ante, we are against over-hyping technologies as well as the counter-myth that singularity will not happen. We do not have any a priori reasons to completely dispel the possibility that we will eventually build strong AI. Therefore, we devote this article to canvassing what speaks in favor of and what speaks against the hypothesis of technological singularity or strong AI, based on clearly specified terms of Artificial General Intelligence, Strong AI, Superintelligence, and Singularity. Here the rubber finally meets the road. Source: \n",
      "                    Tegmark (2018: 31) *An example of the few irrational fideists with some authority is the market crier Jürgen Schmidhuber based in Lugano who blares out that his \"Gödel machines formalize I.J. Good's informal remarks \n",
      "                    (1965) on an 'intelligence explosion through self-improving superintelligences'\" \n",
      "                    (Schmidhuber 2012: 65). The style of his essay makes Schmidhuber's bold statements hard to digest because it repeatedly says how good his AI systems (Gödel machines) are and reports that they \"beat\" rivals, but does not help an outsider (probably including AI experts outside of his lab too) to get a feel for the nature of the tasks and the ability of the techniques to \"scale out\" into other tasks. His essay is, in nuce, long on faith, and short on rigorous argument Table \n",
      "                    2 A triplet of stages for big leaps in AI engineering. Legend: I deem the lower right quadrant not only practically impossible (engineering-wise, the fourth wave necessitates the progress realized with the third wave), but also logically: according to my reading of \n",
      "                    Searle (1980: 417), a real mind cannot just excel at one task (see also our precise definitions in the following)\n",
      "                \n",
      "\n",
      "Head: General\n",
      "Paragraph: Third wave AI Fourth wave AI\n",
      "\n",
      "Head: Narrow\n",
      "\n",
      "Head: Status quo Not possible\n",
      "\n",
      "Head: AI\n",
      "\n",
      "Head: Weak Strong\n",
      "\n",
      "Head: Time\n",
      "Paragraph: The remainder of this article is organized as follows: in the next chapter, we present and draw on two pieces of prior work, namely \n",
      "                    Pearl's (2018a) ladder of causal learning abilities and \n",
      "                    Gardner's (1983\n",
      "                    Gardner's ( /2011) theory of multiple intelligences. On this solid fundament, we are able to derive a sound understanding of the terms \"Artificial General Intelligence\", \"Strong AI\", \"Superintelligence\", and \"Singularity\" in Sect. 3. With our silos filled up like this, we revisit and review three arguments in the field of strong AI and singularity in Sect. 4. Section 5 concludes that, coming from useful and more precise definitions of strong AI and singularity to be introduced in Sect. 3, neither arguments in favor of, nor arguments against strong AI turn out to be cogent.\n",
      "                \n",
      "\n",
      "Head: Prior work: the causal ladder and the theory of multiple intelligences\n",
      "Paragraph: We hold the computer scientist Judea Pearl's (2018a) so called causal ladder as well as the psychologist Howard \n",
      "                    Gardner's (1983\n",
      "                    Gardner's ( /2011) ) proposal that human intelligence is a non-unitary faculty with pluralistic forms eminently fruitful for informing our notions of singularity and strong AI. Therefore, we briefly present their respective contributions in the following two subsections. However, prior to that, we give a note of warning already at this point as it might astound the reader that we base our proposals in Sect. 3 on the combination of Pearl's monothematic view on intelligence (namely in terms of causal learning abilities) and Gardner's theory of multiple intelligences. How can such views be brought together? The solution to this latent paradox is simply that the former endows the common denominator to capture and assess intelligence of all creatures, be it intelligence of humans, biological or artificial animals. Beyond that, it is a daunting exercise to account for the multidirectionality of different kinds of intelligences, which, however, is unavoidable as we learn from the latter.\n",
      "                \n",
      "Paragraph: In other words, we do not refer to Pearl to claim to exhaust \"intelligence\"; rather, \"intelligence\" is a family concept. A corollary of, or hypothesis following from drawing on both Pearl and Gardner as the building block for the definitions in Sect. 3 is that also the highest form of, let's say, personal and musical intelligence come with imagination powers. If we attempted to harmonize or streamline intelligence outside of Pearl's taxonomy of causal learning to be presented in the next section, then we would simply violate the facts collected about the multidirectionality of intelligence.\n",
      "\n",
      "Head: Pearl's causal hierarchy\n",
      "Paragraph: This work sets up the hypothesis that learning, and, more precisely, causal learning is at the center of intelligence. The reason learning is so central to intelligence and intelligent behavior is, according to \n",
      "                    Dretske (1988: 104), that \"learning is the process in which internal indicators \n",
      "                    […] are harnessed to output and thus become relevant […] to the explanation of the behavior of which they are a part. It is in the learning process that information-carrying elements get a job to do because of the information they carry and hence acquire, by means of their content, a role in the explanation of behavior.\"\n",
      "                \n",
      "Paragraph: There are two ways we can get (firsthand) evidence about an event: we can perceive the event happen, or we can make the event happen. These two ways of receiving data-seeing and doing-can lead to radically divergent conclusions in terms of learning, even when the evidence itself is otherwise identical \n",
      "                    (Schulz et al. 2007: 77). What you can learn depends not only on what you know already, but also on how you know it (ibid.). A causal learner must master three distinct levels of cognitive ability: seeing, doing, imagining; and, as Pearl's argument runs, only us humans bestride all three sectors of the causal ladder (see Fig. \n",
      "                    1).\n",
      "                \n",
      "\n",
      "Head: Rung one of the ladder\n",
      "Paragraph: The first rung, seeing or observing or, as we will also denote it, identifying, entails the detection of regularities, patterns and associations in our environment and is shared, according to \n",
      "                    Pearl (2018a: 27), by most animals, modern and prehistoric humans, but also by our present-day learning machines. All these creatures learn from associations. This rung calls for predictions predicated on passive observations or, better, regularities in observations. This is what a dog does when observing how a cat moves and figuring out where it is likely to be a moment after, and it is what the computer program AlphaGo by DeepMind Technologies (Alphabet/ Google) does when it studies a database of millions of Go games so that it can derive which moves are geared with a higher percentage of wins. This first rung of the ladder is characterized by the question \"What if I perceive/see… ?\".\n",
      "                \n",
      "Paragraph: We say that one event is associated with another if observing one changes the likelihood of observing the other. In statistics, a thriving, but after all causality-free enterprise, this type of relationship is called correlation, thereby reducing a large body of data. But, data per se is profoundly dumb. Naked data can tell you that this author is more into philosophy (books) than economics (books), but they cannot tell you why. In many situations more like this, in everyday life, science or business, we witness that mere data is not enough. No system, human, animal or machine, can determine what is going on in the world merely by \"looking out\" and seeing or sampling it \n",
      "                    (Cantwell Smith 2019: 14). Therefore, let us now explore the epistemically significant disparities between observing and intervening.\n",
      "                \n",
      "\n",
      "Head: Rung two of the ladder\n",
      "Paragraph: We step up the next level of causal queries when we begin to change the world by taking actions. In other words, a new kind of knowledge, absent from data, which we find at rung two of the ladder, is needed and consists of doing or intervention (which we wish to perform mentally before we decide whether and how to do it in real life). Intervention ranks higher than association because it encapsulates not just seeing but amending what is and entails planning as well as predicting the effect(s) of deliberate alterations to produce a desired outcome. Pearl spots tool users, such as early humans on the second rung if they act by planning and not merely by imitation. An effect of such tool use is a sharpened \"understanding of causality of events and of the self as one of the drivers of the causality\" (Hiraiwa-Hasegawa 2019: 171). Or as \n",
      "                    Pearl (2018a: 31) puts it neatly: \"Seeing smoke tells us a totally different story about the likelihood of fire than making smoke\". We cannot answer questions about interventions, generally \"What would Y be if I do X?\" or \"How can we… ?\", with passively collected data, no matter how big the data set is. A very direct way to learn about the results of an intervention is to use experiments-be it under prudently controlled conditions in the lab or simply by trial and error, which presumably is how babies acquire much of their causal knowledge-to predict the effects of interventions.\n",
      "                \n",
      "Paragraph: While reasoning about interventions is a vital step on the causal ladder, it is not sufficient to answer all causal questions of interest. We might wonder, my bad mood is gone, but why? Was it the comedy I watched? The birds that I have heard singing during a warm and sunny spring day? The phone call I received from a good friend of mine? These queries take us to the top rung of the ladder of causation, the level of counterfactuals, because to answer them we must go back in time, change history, and ask: \"What would have happened if I had not watched the comedy?\" Or more generally speaking: \"Was it X that caused Y? What if X had not occurred? What if I had acted differently?\" No experiment in the world can deny the effect of a measure that has already been taken and compare the two outcomes. Therefore, we have to import a whole new kind of knowledge.\n",
      "\n",
      "Head: Rung three of the ladder\n",
      "Paragraph: Good predictions crop up in tandem with good explanations \n",
      "                    (Toulmin 1963). We often desire something more than mere prediction. We need to have information about the underlying mechanisms to make accurate and robust predictions about what will happen when the system we are in breaks down or modifies itself in various ways; instrumentalist theories provide no such information to get there. To embark on this arduous journey, counterfactual learners, on the final rung, can imagine worlds that do not exist and infer reasons for observed phenomena.\n",
      "                \n",
      "Paragraph: Counterfactual reasoning is retrospective reasoning; an ability that according to Pearl most distinguishes humans from animal intelligence, as well as from model-blind versions of AI and machine learning. It tells us what would have happened if events other than the ones we are currently observing had happened.\n",
      "Paragraph: Counterfactuals are placed at the top of the hierarchy since they subsume interventional and associational questions \n",
      "                    (Pearl 2018b: 2). If we have a model that can answer counterfactual queries, we can also answer questions about interventions and observations (ibid.). For instance, the interventional question, \"What will happen if I knock over my mug?\" can be answered by asking the counterfactual question: \"What would happen had the mug been knocked over?\" Likewise, associational queries can be covered once we can address interventional queries; we plainly ignore the action part and let observations take over (ibid.). (And, as seen, the translation does not work in the opposite direction.)\n",
      "                \n",
      "Paragraph: Counterfactuals possess an eminently problematic relationship with data since data are, by definition, facts \n",
      "                    (Pearl 2018a: 33). They cannot tell us what would happen in a counterfactual or imaginary world where some known facts are bluntly negated.\n",
      "                \n",
      "\n",
      "Head: Gardner's theory of eight human intelligences\n",
      "Paragraph: We have sympathies for \n",
      "                    Gardner's (1983\n",
      "                    Gardner's ( /2011) ) proposal of multiple intelligences for pragmatic reasons, discarding the idea of a single and general intelligence, of intelligence as a unitary faculty. By contrast, rooting in an adoption of a systemic point of view, intelligence is characterized by multidirectionality and pluralistic forms. 1  Gardner (1983/2011: 8f.) spots eight fairly independent, equally important distinct types of human intelligences that have evolved in the human species. This is the principal point about his theory which is of pertinence to our inquiry.\n",
      "                \n",
      "Paragraph: According to this view, people can be intelligent in a variety of ways (cf. e.g., \n",
      "                    Hofstadter's, 1979, \"Gödel [logical-mathematical], Escher [spatial], Bach [musical]\") and 1 From those sympathies, it cannot be inferred that we would embrace Gardner's \"theory\" of multiple intelligences, MI, or take it for granted which would be premature given that it has engendered abrasive criticisms due to its apparently little experimental evidence \n",
      "                    (Waterhouse 2006;\n",
      "                    Herrnstein & Murray 1994;\n",
      "                    Traub & Gardner 1999). We do not engage in psychology here, a field where this author is not qualified to contribute to, but in philosophy. And what matters for our philosophical position is that Gardner's proposal is grounded in a systemic perspective, which is what we embrace (not the complete or exact theory by \n",
      "                    Gardner). Of course, we invite readers to critically respond to this premise, i.e., our fundamental belief (in systemics).\n",
      "                \n",
      "Paragraph: sometimes those intelligences work in concert within a domain and are valued in a wide range of cultures \n",
      "                    (Davidson and Downing 2000: 44). The eight different intelligences unfold themselves through interactions between one's biological predispositions and the opportunities provided by one's milieu. Out of those, the first three are related to abilities that are measured by conventional intelligence tests (cf. \n",
      "                    Davidson and Downing 2000: 44).\n",
      "                \n",
      "Paragraph: 1. Linguistic intelligence encompasses our use of language to predict, explain, convince and remember information as well as to clarify meaning. 2. Logical-mathematical intelligence captures the ability to operate on relationships in abstract symbol systems and to assess ideas and quantities in accordance with the laws of (formal) logic. 3. Spatial intelligence involves skill in perceiving and transforming visual-spatial relationships, i.e., relationships of objects' position in space.\n",
      "Paragraph: Even though the remaining five types are not measured by conventional intelligence tests, they are valued in most cultures. 4. Bodily-kinesthetic intelligence denotes the adept use of one's body. 5. Musical intelligence includes sensitivity to various musical properties as well as the ability to produce, appreciate and combine pitch, tones, and rhythms. 6. Intrapersonal intelligence reflects the understanding of one's own motives, strengths, weaknesses and emotions. 7. Interpersonal intelligence accordingly reflects the understanding of, and sensitivity to, other people's motives, behaviors, and emotions. Finally, 8. Naturalist intelligence indicates an understanding of the patterns found in natural environments.\n",
      "Paragraph: Gardner's proposal of multiple intelligences is a refreshing exception to the general rule that social and emotional intelligence play little role in scientific theories of intelligence \n",
      "                    (Kihlstrom and Cantor 2000: 364;\n",
      "                    Flynn 1997): \"Most simply, emotions matter because if we did not have them nothing else would matter. Creatures without emotion would have no reason for living nor, for that matter, for committing suicide. Emotions are the stuff of life.\" \n",
      "                    (Elster 1999: 403). More than any other philosopher, Aristotle shows in the Rhetoric (cf. Elster 1999: 52f.) that emotions are rooted not merely in individual psychology (intrapersonal intelligence), but also in social interaction (interpersonal intelligence). For example, with regard to the latter, we do not misapprehend it as \"general intelligence applied to social situation\" \n",
      "                    (Wechsler 1958: 75)-firstly, arguments about what intelligence really is are fruitless, and secondly, the social domain has peculiarities that can be captured in Gardner's seventh intelligence. One such crucial difference is that in social cognition the object (i.e., the person) represented in the subject's mind is intelligent and conscious. Thus, the person being perceived may try to control or manipulate the impression being formed by the perceiver through a variety of impression-management strategies \n",
      "                    (Jones and Pittman 1982), which, in turn, might get anticipated by the perceiver, and so on. Such an entangled web of interaction rituals is unlikely to occur in nonsocial perception and cognition. Not less is Gardner's framework vocal in incorporating emotional intelligence under 6. which is all too often not associated with the hallmark of intelligence \n",
      "                    (Sternberg 1997).\n",
      "                \n",
      "Paragraph: Apart from that, we also venerate the opening of Gardner's list and submit that it is no coincidence that he lists linguistic intelligence first. Language is arguably the most efficacious tool for learning-the mother of all learning mechanisms and the single thing that most makes humans stand out \n",
      "                    (Marcus 2004: 124): Through language, we are able to tell ourselves what we think, to tell others what we think, to engage in cooperative action, and to share our knowledge, passing it onto the next generation. Revision and accumulation of knowledge happens because the people of the next generation are embarked on with that knowledge without the need to discover or invent it by themselves from scratch. This is our cumulative culture, a body of information transferred from individual to individual through means other than genetic transmission, namely but chiefly by using our supple languages (Hiraiwa-Hasegawa 2019: 173). Cultural behavior is, then, not unique to humans, there is culture in a number of divergent species, including nonhuman primates and cetaceans \n",
      "                    (Andrews and Beck 2018: 7). But it seems that we are the only species that has (at least highly developed) cumulative cultures which are improved through time by adding discoveries and inventions (Hiraiwa-Hasegawa 2019: 173; for a critical reply, cf. Brown 2018). Furthermore, the significance of language can, for instance, be expressed by the interpretation of Gardner's third and our second form of intelligence, i.e., mathematics, as a language-at least, it is uncontentious that language development and mathematics are closely nested \n",
      "                    (Knight and Hargis 1977: 424). Charles \n",
      "                    Darwin (1871) himself suggested that some of our \"certain higher mental powers\" might be \"the result of the continued use of a perfect language\".\n",
      "                \n",
      "Paragraph: Gardner invokes evidence to underpin the existence of the eight relatively independent intelligences. One type of evidence, for example, consists of neuropsychological data showing that damage to certain areas of the brain impairs some abilities, but not others \n",
      "                    (Davidson and Downing 2000: 44). In other words, the mind seems, to some extent, to be organized according to the content areas, and each module is based on its own neural structures-the ancillary phrase \"to some extent\" is important here because other empirical results suggest to spell the end of the \"modularity\" hypothesis or Swiss Army Knife view of the brain \n",
      "                    (Marcus 2004: 131). Another source of evidence in favor of MI exhibits the uneven performance of autistic children (ibid.). Yet, without further elaboration of the different elements of each model, a specification of how the elements interact and are (cor-) related to each other, and a thorough examination of what mental components or intelligences might be missing, the picture remains incomplete since it is not clear how to operationalize or completely disconfirm the models. Moreover, we ought to come back to the meta-level repeatedly by raising the general question of how intelligent those models of intelligence truly are.\n",
      "                \n",
      "Paragraph: Much work on intelligence and the brain where it is embedded has been anthropocentric-\"intelligence, the ability to make human-like decisions\" \n",
      "                    (Mindell 2015: 12)-or, when open-minded, on nonhuman \"prim\"ates (from \"primus\"). However, more recently it has been recognized that looking at ourselves or looking at our close relatives like apes and monkeys would never be enough \n",
      "                    (Krubitzer 2015: 186). Even though primates' brains are extremely complex, they are also very similar to ours; and there are salient insights to be gleaned from a wide variety of species-to begin with, high intelligence does not need to reside in a central brain as the lesson of octopi teaches us, which are among the few animals on Earth that can learn by imitation (Godfrey-Smith 2018; Wells 1966). We can already hypothesize that there is no single or optimal way to exhibit or build intelligence.\n",
      "                \n",
      "\n",
      "Head: Concept clarification: artificial general intelligence, strong AI, superintelligence, and singularity\n",
      "Paragraph: We identify four waves of AI development: the first between the 1950s and 1990s is marked by so-called good old-fashioned AI (GOFAI, cf. Haugeland 1997), and currently, since the late 1990s, we have been living in a time of the machine learning paradigm, the second wave. If the next, third, wave AI after the machine learning paradigm is about more general intelligence compared to today where AI systems can either \"play\" Go or chess or write op-eds for the Guardian (Marcus 2020), then the fourth wave is about strong intelligence in artifacts or, simply, about strong AI. Broad intelligence, I suppose, will be reached earlier since it would consolidate extant machine capabilities (like not just \"playing\" chess, but also Go), whereas we are not anywhere near to endowing machines with fully-fledged understanding which is on a higher level (see Sect. 2.1. and Fig. \n",
      "                    1) and which is indispensable for strong AI. But what is strong AI? \n",
      "                    Searle (1980: 417) invoked a distinction between strong AI and weak AI. Strong AI is the thesis that \"the appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states\"; and not just a mind, but a bona fide mind in the sense of playing a proper causal role for the way in which it influences the world (Kistler 2016). Can mentality be reproduced in computational machines or, couched in different terms, can computational systems behave like cognitive systems, exhibiting and duplicating, among others, the creative and flexible behavior that humans display \n",
      "                    (Chalmers 1996: 313)? The strong AI hypothesis is that such computer programs are (technically) possible. Strong AI, as a research program, is the attempt to make computer programs that think with the same depth and richness that humans do. It seeks to beget such artificial persons: machines that have all the mental powers we have, sometimes including \"phenomenal consciousness\" (Bringsjord and Govindarajulu 2018).\n",
      "                \n",
      "Paragraph: Weak AI purports only that computers, we are all too well acquainted with, provide an expedient tool for rigorous formulation and testing of hypotheses about the mind \n",
      "                    (Robinson 2015: 65). This dichotomy we can muster together with narrow vs. general AI which then results in the following figure.\n",
      "                \n",
      "Paragraph: In light of the alleged accelerating advancements in disruptive technologies, not limited to AI, but also counting genetic engineering and nanotechnology, the notion of singularity was brought into wider circulation by \n",
      "                    Vinge (1993), understood as a \"rupture in the fabric of human history\" as \n",
      "                    Kurzweil (2006: 9) stresses. More precisely, singularity hypotheses allude to either one of two distinct and very different scenarios. The one whose discussion we can skip is explored by transhumanists who envisage the amplification of human cognitive capabilities through human enhancement technologies, leading to the arrival of a posthuman race \n",
      "                    (Kurzweil 2006;\n",
      "                    Pearce, 2012). We skip it because the focus in this paper is on synthetic intelligence as proposed by the great John Haugeland.\n",
      "                \n",
      "Paragraph: The other, radically different scenario, which is of higher relevance for our purposes, postulates that, at some future (omega) point S, AI in the sense of software-based synthetic minds materializes as the \"singular\" outcome of accelerating advancements in computer technology \n",
      "                    (Eden et al. 2012: 1). This singularity, it is said, results from an \"intelligence explosion\" (Good 1965): a process in which AIs enter a \"runaway reaction\" of self-enhancement cycles, \"with each new and more intelligent generation appearing faster than its predecessor\" \n",
      "                    (Eden et al. 2012: 2). Against this background, we can state that the emergence of strong AI coincides with S, whereupon immediately thereafter Good's intelligence explosion sets in, with the consequence that AI is reaching a superhuman level of intelligence \"that, stuck as we are in the mud of our limited mentation, we can't fathom\" (Bringsjord and Govindarajulu 2018). This coincidence is what we assume from now on so that strong AI and (synthetic) superintelligence are not the same-synthetic because, so Fig. \n",
      "                    1 The three-rung causal ladder. Source: Pearl 2018a: 28 the hybris goes, biological evolution cannot produce such a leap forward (at least not in reasonable time). Instead, the distinct phenomena are closely tied together. On the one hand, the latter (superintelligence) is a specification, a subset of the former (strong AI). On the other, within the singularity narrative, the latter follows on and from the former, i.e., both temporally and logically.\n",
      "                \n",
      "Paragraph: In essence, the argument runs like this in the words of \n",
      "                    Eden et al. (2012: 2): \"(1) The study of the history of technology reveals that technological progress has long been accelerating. (2) There are good reasons to think that this acceleration will continue for at least several more decades.\n",
      "                \n",
      "Paragraph: (3) If it does continue, our technological achievements will become so great that our bodies, minds, societies, and economies will be radically transformed. (4) Therefore, it is likely that this disruptive transformation will occur.\" Or a bit more formally, in the spirit of \n",
      "                    Good (1965) and in the words of \n",
      "                    Chalmers (2010), respectively:\n",
      "                \n",
      "Paragraph: Premise 1:\n",
      "Paragraph: There will be SAI (created by HI and such that SAI = HI; and due to SAI S will occur) Premise 2:\n",
      "Paragraph: If there is SAI, there will be SAI+ (created by SAI) Premise 3:\n",
      "Paragraph: If there is SAI+, there will be SAI++ (created by SAI+) Conclusion:\n",
      "Paragraph: There will be SAI++ (= superintelligence will occur, sometimes also denoted by S or singularity; cf. \n",
      "                    Bringsjord and Govindarajulu, , 2018) In this argument, \"SAI\" is strong artificial intelligence at the level of, and created by, human persons (\"HI\"), \"SAI + \" is strong artificial intelligence with super-human performance \n",
      "                    (Rajani 2011), and \"SAI ++ \" amounts to strong super-human intelligence constitutive of the intelligence explosion or of superintelligence. The key process is presumably the creation of the first class of SAI. Critics of singularity dismiss these premises as speculative and empirically unsound (e.g., \n",
      "                    Horgan 2008;\n",
      "                    Plebe and Perconti 2012;\n",
      "                    Modis 2012).\n",
      "                \n",
      "Paragraph: Apart from the twin notions of acceleration and discontinuity, accounts of singularity seem to dissent from each other on quite a number of aspects: causes and consequences, empirical content of the conjecture, on the timescale (e.g., an event or a period), and even on its nature: e.g., the dual use of S in the previous argument or the arrival of Homo Deus vs. of (super-) strong AI (not belonging to the genus Homo)? These dissents, casting doubt whether there is a coherent notion of singularity at all, are paired with a plethora of open guiding questions for research such as, what, if anything, can be said to be accelerating?\n",
      "Paragraph: To prevent this Babylonian confusion of tongues to grow any further, we thus suggest specifying the key terms as follows.\n",
      "Paragraph: We first propose to specify \n",
      "                    Searle's (1980: 417) notion of strong AI as follows: An AI agent X is a strong AI (SAI) if, and only if, X covers all three levels of Pearl's causal hierarchy (see Fig. \n",
      "                    1) for the eight human intelligences of Gardner's theory of human intelligences: linguistic, logicalmathematical, spatial, bodily-kinesthetic, musical, intrapersonal, interpersonal, and naturalist intelligence.\n",
      "                \n",
      "Paragraph: A second clarification concerns then the concept \"superintelligent AI\" (SIAI): X is a SIAI if, and only if, X covers all three levels of Pearl's causal hierarchy for the eight human intelligences of Gardner's theory of multiple intelligences and at least one additional and distinct intelligence on par with the eight or only those eight intelligences with a superhuman performance for at least one of the four intelligences (\"super-human performance\" as coined by Rajani 2011) and no sub-human performance for any of the intelligences.\n",
      "Paragraph: Finally, the adjusted definition of (technological) singularity runs as follows: an event E qualifies as a singularity S if, and only if, SAI emerges in E and SIAI directly thereafter, whereby \"directly\" signifies that there is either a direct causal relationship or a short causal chain between SAI and SIAI in the sense that the former brings about the latter.\n",
      "Paragraph: (For the sake of completeness, \"artificial general intelligence\" (AGI) brings up the rear even though it is not at stake in the following chapter 4, but in order to sharpen the demarcation lines between the terms: X is a AGI if, and only if, X is not a SAI and covers more than one intelligence for possibly varying causal learning capabilities. We concede that this initial definition is not satisfactory and in need of an overhaul by future work because, while it is clear what multiple intelligences stand for in the human case (cf. \n",
      "                    Gardner 1983\n",
      "                    Gardner /2011) and also more or less clear in the animal case \n",
      "                    (cf. Hodos 1988: 100f.;\n",
      "                    and Wasserman and Zentall's, 2006), it is not so clear in the machine case. Following the thrust of \n",
      "                    Crosby (2020) and his Animal-AI Olympics, we suggest that for the time being we orient ourselves in this regard).\n",
      "                \n",
      "\n",
      "Head: Reviewing three arguments in the debate on singularity and strong AI\n",
      "Paragraph: The next three subchapters portray one argument in favor of reckoning with SAI and a singularity S. (4.1.). The last two subchapters are devoted to the opposite standpoint, sketching two reasons sowing the seeds of doubt about the occurrence of S and SAI. In both cases, we pin down the arguments by bringing in our precise definitions from Sect. 3. \n",
      "                    Moravec (1998\n",
      "                    Moravec ( , 1999) ) informs us that since the speed of computer hardware doubles every 18 to 24 months (in accordance with Moore's Law, which we revisit below and which has apparently held in the past), \"fourth generation\" AI will soon enough exceed humans in all respects, from running companies to writing novels \n",
      "                    (Bringsjord and Govindarajulu 2018). These AI systems, so the story goes, will evolve to such lofty cognitive heights that we will stand to them as single-cell organisms stand to us today (ibid.).\n",
      "                \n",
      "\n",
      "Head: Hardware-based arguments by Moravec and Kurzweil\n",
      "\n",
      "Head: Presentation of the argument\n",
      "Paragraph: The hardware-based argument for singularity rests on a solid foundation in the sense that it is quite common to hear intelligence explained in part as some form of mental speed \n",
      "                    (Berger 1982). From Aristotle or Hobbes (1651/1885), who thought intelligence was the speed with which one thought followed on from another, to modern studies in the neuropsychology and psychophysiology of human intelligence, it has been indicated that higher mental ability is, at least in part, determined by speed of information processing \n",
      "                    (Vernon et al. 2000: 255). Above all, the singularity community has wholeheartedly fallen this construal of intelligence. For instance, Loosemore and Goertzel (2012: 88) write short-sightedly (as we notice in the discussion part of Moravec's argument): \"There are two possible types of intelligence speedup: one due to faster operation of an intelligent system (clock speed increase) and one due to an improvement in the type of mechanisms that implement the thought processes ('depth of thought' increase).\"\n",
      "                    foot_0 Or as \n",
      "                    Modis (2012: 331) boils down long passages to a short operational definition: \"Intelligence according to the singularitarians is measured by the speed of calculation.\" This broad reception of the identification of intelligence with mental speed propelled and imbued \n",
      "                    Moravec's (1998\n",
      "                    Moravec's ( , 1999) and \n",
      "                    Kurzweil's (2006) view that S is \"near\", whereby Kurzweil modified the hardware-based argument to evade some criticism. \n",
      "                    Moravec (1988\n",
      "                    Moravec ( : 61, 1998: 4) : 4) probably originated the hardware-based argument or the argument of comparative computational power and memory to vindicate S: Moravec (1998: 1) hypothesizes that \"the performance of AI machines tends to improve at the same pace that AI researchers get access to faster hardware\" where performance is operationalized as the power (bits per second) and memory capacity (bits) of machines. He then not only compares and rates the performance of some natural organisms (from nematodes to whales) and \"intelligent\" artifacts like the Deep Blue chess machine in this regard of computational power and memory. But, on top of that, he relies on those measures to assess biological and artificial systems in terms of their cognitive capabilities.\n",
      "                \n",
      "Paragraph: The former is per se unproblematic, the latter as well as the following are not. \n",
      "                    Moravec (1988: 68) is not content with describing and interpreting the status quo as well as past developments, but adds projections and extrapolations (which are always exposed to criticism since they deal more with assumptions than data or facts) on the basis of which he proclaims human-machine equivalence in terms of general intellectual performance in less than 30 years (i.e., in our decade of the 2020s; Moravec 1998: 1). He seems to build his bold AI optimism on \"[s]teady improvements in mechanical and electromechanical calculators before World War II [which] had increased the speed of calculation a thousandfold over manual methods from 1900 to 1940. The pace quickened with the appearance of electronic computers during the war, and 1940 to 1980 saw a millionfold proliferation.\" \n",
      "                    (Moravec 1998: 5). Above all, he points to an \"industry given\" (ibid.), namely that \"[c]omputers doubled in capacity every two years after the war\" (ibid.), a pace that has become better associated with Moore's law.\n",
      "                \n",
      "Paragraph: Moore's law is named after one of the founders of the Intel microprocessor manufacturing company, and states that the number of transistors in a dense integrated circuit, i.e., the computational capacities (e.g., electronic component densities and electronic signal processing speeds) of integrated circuits double about every two years. The density of components on an integrated circuit is closely tied to the price-performance of computing power. The law was established because it has been observed that the number of transistors in Intel microprocessors has in fact doubled every two years since the early 1970s \n",
      "                    (Modis 2012: 316). \n",
      "                    3The hardware-based argument can thus be distilled as follows:\n",
      "                \n",
      "Paragraph: Premise The singularity S will be reached\n",
      "Paragraph: Our formal comment on C1 aside, C1 has also been under attack content-wise, rendering the collapse of the argument inescapable. For at least four decades, computing power has increased exponentially, roughly in accordance with Moore's law. However, a speed bump is on the horizon as an end to Moore's law is probable: \"Though several information technologies have been advanced at an exponential or superexponential [i.e., hyperbolic, C.H.] rate for many decades, this trend may not hold for much longer\" \n",
      "                    (Muehlhauser and Salamon 2012: 21;\n",
      "                    cf. also Mack 2011;\n",
      "                    Walsh 2017: 181).\n",
      "                \n",
      "Paragraph: Growth processes, including Moore's law, that (for some time) are observed to follow exponential patterns eventually reveal themselves to be following S-curves thus banning runaway situations which would be prescribed by a singularity S (Modis 2012: 311): \"It is now unanimously expected that this growth pattern [according to Moore's law] will eventually turn into an S-curve and reach a ceiling\" (ibid.: 316). (In this context, allow me also the mathematical subtlety that, unlike the advocates of a technological singularity, one should not speak of exponential but hyperbolic growth if one believes in singularity, since the increase of an exponential function is relatively slow and always finite.)\n",
      "Paragraph: If we assume for a transient moment that the soundness of the hardware-based argument would only hinge on the empirical support for C1 (which is what Kurzweil 2012, seems to be implying), \n",
      "                    Kurzweil's (2006) version of the hardware-based argument would not be jeopardized since the feared breakdown of Moore's law would not affect his train of thought. \"The Singularity is the result of the Law of Accelerating Returns (LOAR)\" \n",
      "                    (Kurzweil 2012: 343), spanning multiple exponential trends, that may or may not turn out to be S-curves, and not just a single growth process like of the doubling of transistors in dense integrated circuits (which Moore's law refers to). The LOAR certainly does not imply that every individual exponential trend goes on indefinitely. Instead, \n",
      "                    Kurzweil (2006: 83)\n",
      "                    emphasizes: A specific paradigm (a method or approach to solving a problem, e.g., shrinking transistors on an integrated circuit as an approach to making more powerful computers) provides exponential growth until the method exhausts its potential. When this happens, a paradigm shift (i.e., a fundamental change in the approach) occurs, which enables exponential growth to continue.\n",
      "                \n",
      "Paragraph: In other words, when Kurzweil spells out computer hardware advancements according to his LOAR, then he delineates a pattern of ongoing exponential growth made up of a cascade of S-curves, each of them related to one out of many what he calls paradigms. Where could another boost for hardware development, another \"paradigm\", come from? Perhaps, from a new kind of computing dubbed quantum computing. Its essential feature is easy enough to grasp at the intuitive level, e.g. following \n",
      "                    Walsh (2017: 184) or \n",
      "                    Garis and Halioris (2009: 489):\n",
      "                \n",
      "Paragraph: [Our conventional c]omputers today work by converting information to a series of binary digits, or bits, and operating on these bits using integrated circuits (ICs) containing billions of transistors. Each bit has only two possible values, 0 or 1. Through manipulations of these so-called binary representations, computers [do all their computations]. A quantum computer also represents information as a series of bits, called quantum bits, or qubits. Like a normal bit, a qubit can be either 0 or 1, but unlike a normal bit, which can only be 0 or 1, a qubit can also be in a state where it is both at the same time [a superposition between the two states of zero and one]. When extended to systems of many qubits, this ability to be in all possible binary states at the same time gives rise to the potential computational power of quantum computing (National Academies of Sciences: Engineering, and Medicine, 2019: 24), which could be \"truly trillions of trillions of trillions of times above those of current classical computing capacities\" \n",
      "                    (Garis and Halioris 2009: 489). Quantum computers could be exponentially faster than conventional computers \n",
      "                    (Walsh 2017: 184).\n",
      "                \n",
      "\n",
      "Head: Discussion of the argument\n",
      "Paragraph: At the risk of stating the obvious, \"[t]he chief challenges in AI, relative to the human case, consist in finding the right computer programs, not faster and faster computers upon which to implement these programs\" \n",
      "                    (Bringsjord et al. 2012: 81). We dispel the myth that better hardware entails more intelligence and, ultimately, S. The Moravec-Kurzweil argument is not sound or incisive. Other than that, the idea here and in the subsequent subchapters is not to discuss the respective arguments at length or even comprehensively. Instead, we plainly illuminate the argument(s) from the stance of our definitions from Sect. 3. This restriction implicates for this first argument that we make do with three brief remarks.\n",
      "                \n",
      "Paragraph: Firstly, the intelligence explosion, unleashed by S and culminating in SIAIs, and the speed explosion, characterized by colossal hardware improvements (along with software improvements which are fatally neglected by the hardwarebased arguments), are logically independent of each other. In principle, there could be an intelligence explosion without a speed explosion and a speed explosion without an intelligence explosion. AI may have an advantage over human brains when it comes to data storage and the speed of data processing. But storage capacity and speed do not mean proliferated intelligence.\n",
      "Paragraph: Speed deserves only secondary attention, speed matters for intelligence only in the ceteris paribus sense (see also our definition of SIAI): all other things being equal, the faster the test subject performs on an adequate task, the smarter she is.\n",
      "Paragraph: A further pervasive fallacy which thus underlies this singularity idea reliant on Moravec's hardware-based argument is the monolithic view of intelligence that moreover usually confounds the subject with the intellectual faculty itself. To grosso modo extrapolate from success in one aspect relevant to cognition (like better hardware) to success in all aspects of cognition is to succumb to the illusion of progress. In other words, C3, which presupposes human-level learning capabilities for at least eight intelligences, does not follow from C2.\n",
      "Paragraph: Finally, computational capacities either just represent a tiny fraction of the gamut of intelligence (i.e., computation as a cognitive trait or, when interpreted even more narrowly, computation as one pillar of logical-mathematical intelligence). Or computing is taken as such a basic and abstract unit that the mind itself is treated as a computational system (e.g., see the computational metaphor or the computational theory of mind; Rescorla 2020). \n",
      "                    4 Either way, computational capacities per se are irrelevant to the level of intelligence.\n",
      "                \n",
      "Paragraph: With regard to the multidimensionality of intelligence, systems' mere computational power leaves us in the dark about their causal learning capabilities which, following Pearl, we identified as the principal theme of intelligence. Today's deep learning systems like GPT-3 or AlphaGo and their relatives excel at computing; yet, no matter how much more computational power and speed they gain (ceteris paribus), they will never get past level one (the level of associations, correlations, seeing, and observing, see 2.1.).\n",
      "Paragraph: Hence, SAI, S, and SIAI, as specified in this paper, remain at an unattainable distance; Moravec, Kurzweil, and adherents pose utterly deceptive questions with their argument.\n",
      "\n",
      "Head: The Gödelian attacks\n",
      "Paragraph: To begin with, everyone can concord that Kurt Gödel's contributions to formal logic as a discipline of mathematics, in particular his Incompleteness Theorems \n",
      "                    (Gödel 1931), are a terrific achievement. But AI is not formal logics or a discipline of mathematics for that matter, which prompts the question to what extent Gödel developed an argument against strong AI. The simple answer is, he has not. The mystery about how this answer goes together with the title of this subchapter (with Gödel's name in it) is dissipated though once we note that \"no mathematical result has ever had extra-mathematical outcomes remotely comparable to Gödel's Theorem [as the conjunction of the two]\" \n",
      "                    (Berto 2011: xiif.). In the aftermath of the release of the Gödelian Symphony (ibid.), famous theses based upon, or allegedly following from, the incompleteness theorems were enacted in fields as different as the philosophy of mathematics, philosophy of mind, even sociology and politics, which must have provoked \n",
      "                    Franzén (2005) to title his book: Gödel's Theorem: An Incomplete Guide to Its Use and Abuse.\n",
      "                \n",
      "Paragraph: And indeed, in (at least prima facie) stark contrast to obvious and curious misapprehensions of Gödel's findings, the connection between formal systems, i.e. what his work is actually about, and computers is not difficult to make out because the former and the latter are simply equivalent if the latter are seen as Turing machines-but beware of an inflationary use \n",
      "                    (cf. Sloman 2002). This is not the place to attempt a full definition of Turing machines or formal systems, but three essential features can capture the basic idea: \"(i) they are token-manipulation systems; (ii) they are digital; and (iii) they are medium independent\" \n",
      "                    (Haugeland 1997: 8f.). Some philosophers, physicists and mathematicians, in particular \n",
      "                    Lucas (1961), \n",
      "                    Penrose (1989\n",
      "                    Penrose ( , 1994\n",
      "                    Penrose ( , 1996)), and \n",
      "                    Koellner (2018a, b), have then attempted to derive an argument to the effect that no computing machine can ever reach \"human-level intelligence\" (not only of actual, but of idealized humans, but not in the sense pertinent to our definition of SAI which already points to a harsh criticism of Gödelian arguments from our stance) or, at the very least, that the human mind is irreducible to any computing machine.\n",
      "                \n",
      "\n",
      "Head: Presentation of the argument\n",
      "Paragraph: In nuce, the Gödelian arguments (from \n",
      "                    Lucas 1961\n",
      "                    , to Koellner 2018a, b) are addressing-and affirming-the question of whether the incompleteness theorems imply that \"the mind cannot be mechanized\" which ought to be specified as \"the mathematical outputs of the idealized human mind do not coincide with the mathematical outputs of any idealized finite machine\" \n",
      "                    (Koellner 2018a: 338).\n",
      "                \n",
      "Paragraph: The story begins with Gödel who proved in 1931 that for any consistent formal system powerful enough to do a certain sort of arithmetic like the Principia Mathematica, there will be a true sentence-the system's Gödel sentence -that the system cannot prove (for more detailed and accurate accounts of his proof, cf. Nagel and Newman 2001, or Raatikainen 2020). Gödel thought that his incompleteness theorems had bearing on the question of mechanism, of whether the human mathematician can be replaced by a machine, and he thought that \"will never be possible\" \n",
      "                    (Gödel in Tieszen 2011: 179;\n",
      "                    cf. also Wang 1996: 193).\n",
      "                \n",
      "Paragraph: But as usually, Gödel was cautious and his position was quite subtle -even though he went so far as to call his finding, the disjunction (see the next sentence), a \"mathematically established fact\" \n",
      "                    (Gödel 1951\n",
      "                    (Gödel /1995: 310): 310). He himself refrained from arguing that his incompleteness theorems implied that \"the mind cannot be mechanized\" (in the sense of Koellner 2018a: 338, quoted in the first paragraph); he contended, rather, that they implied a weaker, disjunctive conclusion, what I, Feferman and others called \"Gödel's Disjunction\". The disjunction concerns two central philosophical claims: \"Either the human mind surpasses all machines (to be more precise: it can decide more numbertheoretical questions than any machine), or else there exist number-theoretical questions undecidable for the human mind\" \n",
      "                    (Gödel in Wang 1996: 185). The disjunction states that at least one of these claims must hold-put differently, it states that either \"the mind cannot be mechanized\" or \"mathematical truth outstrips the idealized human mind\" \n",
      "                    (Koellner 2018a: 339).\n",
      "                \n",
      "Paragraph: The first to exceed that prudency and to produce a fullfledged Gödelian argument against SAI-i.e., to establish that Gödel's incompleteness theorems imply that the first disjunct holds-was the Oxford philosopher J. R. \n",
      "                    Lucas (1961). Lucas' talk of 1959 and the subsequent publication in 1961 was widely criticized in the literature-incisively by \n",
      "                    Benacerraf 1967; and most eloquently by \n",
      "                    Hofstadter's (1979: 465f.) \"Passion According to Lucas\". Yet, Lucas initiated a debate that has yielded more formidable arguments. One of Lucas' indefatigable defenders is the newly minted Nobel prize laureate in physics Roger Penrose, whose first attempt to vindicate Lucas was a Gödelian attack on SAI articulated in his The Emperor \n",
      "                    's New Mind (1989). This first attempt fell short, and Penrose published a more elaborate and more fastidious Gödelian case, expressed in Chapters 2 and 3 of his Shadows of the \n",
      "                    Mind (1994). \n",
      "                    Penrose (1996: 3.2) distills this argument to its essentials. Here is this version, verbatim (restated in different terms in \n",
      "                    Franzén, 2005: 120):\n",
      "                \n",
      "Paragraph: We try to suppose that the totality of methods of (unassailable) mathematical reasoning that are in principle humanly accessible can be encapsulated in some (not necessarily computational) sound formal system FF. A human mathematician, if presented with FF, could argue as follows (bearing in mind that the phrase \"I am FF\" is merely a shorthand for \"FF encapsulates all the humanly accessible methods of mathematical proof\"): (A) \"Though I don't know that I necessarily am FF, I conclude that if I were, then the system FF would have to be sound and, more to the point, F′F′ would have to be sound, where F′F′ is FF supplemented by the further assertion \"I am FF.\" I perceive that it follows from the assumption that I am FF that the Gödel statement G(F′) G(F′) would have to be true and, furthermore, that it would not be a consequence of F′F′. But I have just perceived that \"If I happened to be FF, then G(F′)G(F′) would have to be true,\" and perceptions of this nature would be precisely what F′F′ is supposed to achieve. Since I am therefore capable of perceiving something beyond the powers of F′F′, I deduce that I cannot be FF after all. Moreover, this applies to any other (Gödelizable) system, in place of FF.\"\n",
      "\n",
      "Head: Discussion of the argument\n",
      "Paragraph: The close examination of the cogency of that sophisticated argument for the first disjunct becomes very technical and elaborate as the argument involves sentences that are provably indeterminate (just as the Liar sentence itself), and it applies to these sentences inference rules that are legitimate only when applied to determinate sentences \n",
      "                    (Koellner 2018b: 458). I do not have the faintest intent of entering that debate, Kafka's castle, as the hope would be foolish of finding our way back out again by dint of pure reason expressed by and confined to text of a page or less in this discussion part. Koellner's two-piece paper is, in my view, a brilliant piece of reasoning, and so is \n",
      "                    Penrose's (1994/96) argument. However, the former with its ramifications-e.g., he arrives at a disjunctive conclusion himself (2018b)-and utmost delicacy in mathematical logic is delicate to evaluate in respect to the overarching, relatively fuzzy question of why S and SAI are impossible. The latter might not be sufficiently independent in 1 3 the sense that, if the previous Gödelian arguments are overturned, not much evidence for buying into \n",
      "                    Penrose's (1994/96) argument is left \n",
      "                    (Chalmers 1995).\n",
      "                \n",
      "Paragraph: Instead, I summarize that the assessment of Gödel's work is ongoing and not completed and I contribute to it by four more short comments in reference to my own paper on that matter. Firstly, the Gödelian arguments against SAI, so far, do not appear to carry much force. Those attempts suffer from the shortcoming that Gödelian limitations have not been convincingly shown to not apply to humans. Moreover, the theses that Gödel, Lucas, Penrose, and others develop from the incompleteness theorems depend on highly idealized assumptions about both the nature of the human mind and the nature of machines. Coming from our definitions of SAI and S we ought to remain more agnostic though.\n",
      "Paragraph: What about the assumption that the human mind is consistent? In practice, mathematicians certainly make errors and thence arrive at false conclusions that in some cases go long undetected. Penrose, among others, has pointed out that when errors are detected, mathematicians seek out their source and correct them (cf. \n",
      "                    Penrose 1996, pp. 137 ff), and so he has argued that it is reasonable to ascribe self-correctability and hence consistency to our idealized mathematician. But even if such a one can correct all his errors, can he know with mathematical certitude, as required for Gödel's claim, that he is consistent? \n",
      "                    (Feferman, 2007: 15) Secondly, with \n",
      "                    Turing (1950: 445), we note that \"[w]e too often give wrong answers to questions ourselves to be justified in being very pleased at such evidence of fallibility on the part of the machines. Further, our superiority can only be felt on such an occasion in relation to the one machine over which we have scored our petty triumph. There would be no question of triumphing simultaneously over all machines. In short, then, there might be men cleverer than any given machine, but then again there might be other machines cleverer again, and so on.\" It is interesting that the two men who might be said to have endowed the intellectual machinery of that objection to SAI, Gödel (with his proof) and Turing (with his precise definition of the Turing machine), came to opposite philosophical conclusions.\n",
      "                \n",
      "Paragraph: Thirdly, barring the pessimistic notion of the accidental inexplicability of the brain or mind, the project of AI could even receive a boost from Gödel's groundwork on the constructive side which is very much in line with Pearl's thrust in chapter 2.1. If we recognize that Gödel's proof nurtures the notion that \"a high-level view of a system may contain certain explanatory power which simply is absent on the low levels \" \n",
      "                    (Hofstadter 1979: 702), then this reading is immediately reminiscent of Pearl's layered taxonomy of causal learning where AI systems on the third level possess explanatory power which is blatantly missing in our today's deep learning machines on the lower level one (of associations and correlations).\n",
      "                \n",
      "Paragraph: Finally, in light of our plea for the multidirectionality and plurality of intelligence, it is tantamount to hubris to think that mathematics and metamathematics alone could determine what minds in general are capable of and what they are not capable of. With our definitions of SAI in mind (where logical-mathematical intelligence is only one out of eight intelligences), routes towards SAI and S (which are far from being discovered) are not necessarily blocked by Gödelian arguments, no matter if they prove to be sound or not.\n",
      "\n",
      "Head: Searle's Chinese Room thought experiment\n",
      "Paragraph: In what may be the most influential thought experiment in the history of AI \n",
      "                    (Schank and Towle 2000: 344), \n",
      "                    Searle (1980) proposed what has come to be called the Chinese Room experiment.\n",
      "                \n",
      "\n",
      "Head: Presentation of the argument\n",
      "Paragraph: This intriguing and seminal essay on minds, brains, and programs offered an argument against the contention of strong AI. \"The argument\", Searle writes in a brief restatement, \"proceeds by the following thought experiment\": Imagine a native English speaker who knows no Chinese locked in a room full of boxes of Chinese symbols (a data base) together with a book of instructions for manipulating the symbols (the program). Imagine that people outside the room send in other Chinese symbols which, unknown to the person in the room, are questions in Chinese (the input). And imagine that by following the instructions in the program the man in the room is able to pass out Chinese symbols which are correct answers to the questions (the output). The program enables the person in the room to pass the Turing Test for understanding Chinese but he does not understand a word of Chinese. \n",
      "                    (Searle 1999: 115). Now, if we ban physical impossibilities because books like Searle's Pr would easily need to contain more distinct entries than our entire physical universe counts atoms (Levesque 2018: 12), which we may or may not want to accept in a thought experiment, what is the celebrated internal objection to SAI stemming from Searle's scenario? Even if the reader has never heard of the Chinese Room experiment before, (s)he doubtless can see the basic idea: that S(earle) in the box is supposed to be everything a computer can becomposed of a data base, as well as the program, receiving inputs, generating outputs-and his externally observable behavior is perfect. And yet, Searle claims that S(earle) does not understand Chinese, and so no computer could have such understanding. S(earle) is mindlessly moving squiggle-squoggles around (to borrow his words), and, according to the argument, that is all computers do, fundamentally. Hence, they necessarily lack understanding and, consequently, SAI. The thought experiment is summarized in Fig. \n",
      "                    2.\n",
      "                \n",
      "Paragraph: Searle's conclusion on the constructive side: The Chinese Room demonstrates that something more is needed for intentionality than formal computations. And that \"something\" is, following Searle, the causal powers of neuroprotein. Our main takeaway from his imaginative (albeit ethnocentric) illustration is quite tangible-simulation is not the real thing. Merely shifting symbols around in a way that looks like (linguistic) understanding is not sufficient for it. A computer, as Terry \n",
      "                    Winograd (1990: 187) reminds us, does not understand the linguistic tokens it processes, it merely \"manipulates symbols without respect to their interpretation.\" \"[S] ymbol manipulators do not understand the story\" \n",
      "                    (Penrose 1989: 25).\n",
      "                \n",
      "\n",
      "Head: Discussion of the argument\n",
      "Paragraph: Searle was attacking a by now largely superseded understanding of AI, i.e., GOFAI (good old-fashioned AI). Nonetheless, the Chinese Room spawned a flourishing philosophical industry whose mills are still spinning merrily. Many readers acknowledged that Searle's empty-symbolism argument proved just what he said it proved, while not less readers saw it as fundamentally wrong-headed (Boden 2015: 98). On top of that, those who saw it as going astray gave different accounts of just what was fatal with it, and to some Searle (2014) has replied too. This is not the place to summarize the ever-lengthening debate or to rehearse what is wrong with Searle's Chinese Room argument (for an account at length cf. Cole 2020). Instead, we poke three holes in Searle's original argument (against the backdrop of our definitions) in the following and derive some learnings.\n",
      "Paragraph: Firstly, we concord that understanding is indispensable for SAI: no SAI without understanding. We diverge from \n",
      "                    Searle (1980) though when it comes to the issue what understanding is. Searle's point is that the mere carrying out of a successful algorithm does not in itself imply that any understanding has taken place \n",
      "                    (Penrose 1989: 24). Searle appears to take intentionality as the definitive mark of understanding and, ultimately, of intelligence. With this he is not alone. \"Intentionality\", said Franz \n",
      "                    Brentano (1874\n",
      "                    Brentano ( /1973)), \"is the mark of the mental\". By this, he meant that everything mental has intentionality, and nothing else does \n",
      "                    (Haugeland 1997: 4). Yet, Searle appears to neglect that some philosophers have argued for intentionality to be grounded in our evolutionary history \n",
      "                    (Millikan 1984). If that is so and since AI as a science is still in its infancy, only evolved AI systems and robots could even be candidates for the possession of intentionality (Boden 2015: 99). Searle's point might thus be unfair and reliant on too strong assumptions.\n",
      "                \n",
      "Paragraph: We, by contrast, took another, earlier exit (out of the Searlian edifice) in this paper by discarding the identification of understanding with intentionality right away because the latter presupposes that an agent possesses inner or mental states which would expel many machines (and probably many animals) in the sense of different kinds of intelligence ex ante, i.e., on dogmatic grounds. If we embark on the endeavor of making sense of human, animal and machine intelligence with preformed concepts (of understanding or intelligence for that matter) that are not even applicable to the objects of investigation, then the whole journey is thwarted before it has even begun. Furthermore, we argued following Pearl in 2.1. that understanding is sufficient for intelligence, but not necessary; and, conversely, it is necessary for SAI, but not sufficient for it: understanding is sufficient for intelligence because we saw in Fig. \n",
      "                    1 that creatures which understand and imagine are clearly intelligent (humans and Einsteins); at the same time, this figure also indicates that understanding is not necessary as other creatures like animals and AI systems do not have understanding (through counterfactual thinking), but still can be meaningfully said to be (less) intelligent. Given the definition of SAI in Sect. 3, understanding is necessary for a machine to be a SAI, but it is not sufficient because there is not a single, but eight different intelligences.\n",
      "                \n",
      "Paragraph: So, shall we just conclude that our and Searle's (1980) understanding of \"understanding\", and \"intelligence\", respectively, are incompatible since they rest on different foundations? Not really. It is neither prerequisite nor desirable to stop at that point, the latter not least due to the observation that \"[u]nderstanding can still sound frighteningly unempirical and elusive\" \n",
      "                    (Dehn and Schank 1982: 365)\n",
      "                    earle) is the native English speaker who knows no Chinese and who is locked in the room, and Q is the Chinese interrogator. \"o\" stands for \"output\", \"i\" for \"input\". \"Base\" is the \"data base\", and \"Pr\" the \"program\" former as \n",
      "                    Searle (1984) suggests another reading of \"understanding\", namely understanding as semantics, which is in harmony with the Chinese Room argument and allows for a more revealing comparison with our reasoning. The reader surely presages that we would decline the premise based on this reading: in lieu of \"syntax is not sufficient for semantics\" (which is what the Chinese Room argument would assert), we proclaim that \"syntax can mirror semantics\", that \"syntax can constitute semantics\". How? We specified this verdict in chapter 2.1. by appealing to programming more causal learning competence into current AI systems (so that they reach the third levels in our universal taxonomy, see Fig. \n",
      "                    1).\n",
      "                \n",
      "Paragraph: By this, we do not mean that mere programs, which are abstract computational objects and purely syntactic, are candidates for possession of comprehension. The crucial role of implementation has to be respected since implementations can have semantic content. Searle's Chinese Room argument \"gains its purchase on our intuitions by implementing the program in a bizarre way that obscures the realization of the relevant causal dynamics [a sense of 'syntax', so to say, in which implementations are syntactic]\" \n",
      "                    (Chalmers 1996: 325). Implementations of programs are, by contrast, i.e., contra Searle's account, concrete systems with causal dynamics, and are not purely syntactic. In virtue of the causal heft of those implementations in the real world, comprehension can emerge, and we spelled out what requirements have to be met to make it happen. Focalizing thereby on the physical, organic and chemical structure (\"the causal powers of neuroprotein\") is chauvinistic.\n",
      "                \n",
      "Paragraph: Understanding is not a matter of black and white, but, following the well-tested Darwinian perspective of gradualism, it comes in degrees. Understanding entails making inferences and results in the ability to make further inferences. There are, of course, a great many possible levels of understanding and, accordingly, different kinds of inference lead to different depths of understanding. So we have argued.\n",
      "Paragraph: Secondly, even more from our today's standpoint in the midst of the predominance of machine and deep learning, Searle is attacking a straw man. Even though \n",
      "                    Newell and Simon (1963), as well as their GOFAI co-pioneers John McCarthy and Marvin Minsky, undoubtedly believed that AI systems of a certain complexity would be really SAIs (see also Simon whom we quoted in the abstract). Despite the apparent relevance of Searle's argument for at least those addressees, they did not have abstract, uninterpreted, Turing computation solely in mind, which holds even more for today's AI researchers. For example, Boden's (2015) sketch of Newell and Simon's semantic theory suggests that they were not primarily concerned with computation as uninterpreted Turing computation. What is more, other AI scientists, most notably Judea Pearl whose pathbreaking work directly fed into our definitions, have offered causal (intentional) accounts of computation, sometimes explicitly denying that AI is mainly concerned with Turing computation \n",
      "                    (Sloman 2002).\n",
      "                \n",
      "Paragraph: \"One of the most notorious failures of the early days of computers was machine translation. […] What the machine translation programs lacked \n",
      "                    […] was any sense of the meaning of the texts they were translating\" \n",
      "                    (Dehn and Schank 1982: 366). GOFAIs like Weizenbaum's ELIZA, Winograd's SHRDLU, or \n",
      "                    Schank and Abelson's (1977: 67) daring thesis that \"most of understanding is script-based\" set the stage for, and embed \n",
      "                    Searle's (1980) essay in in the historical context. Yet, today in the second wave, AI comprises different and more diverse architectures (not just symbolic and connectionist approaches, but also numerous more nuances), and deep learning is much more successful at machine translation. In nuce, \"the [S]AI thesis is so plausible precisely because the class of computational systems is so wide\" \n",
      "                    (Chalmers 1996: 332). The trite homogeneity of AI systems of the past might have inspired or reinforced Searle, but how can he cope with the wild heterogeneity of systems that characterize the new paradigm? Is repeating the old message enough? First, a digital computer is a syntactical machine. It manipulates symbols and does nothing else. For this reason, the project of creating human intelligence by designing a computer program that will pass the Turing Test, the project I baptized years ago as Strong Artificial Intelligence (Strong AI), is doomed from the start. The appropriately programmed computer has a syntax but no semantics. \n",
      "                    (Searle 2014: 3).\n",
      "                \n",
      "Paragraph: When we bemoan that Alexa, Siri, and their relatives of the second AI wave do not know what they are talking about when they \"tell\" you about the weather forecast or about what wine goes with your meal-or to that matter, that their utterances matter only under interpretation by us -, then we are not referring to formality. Unlike Searle, we do not make the case that a formal system cannot have real semantics, since the interpretations are unanchored, and can be assigned at whim: \"I would go to court to deny that the symbols in present day AI systems are 'formal' in [the Searlian] sense. Some contemporary systems, in particular, are plugged into the world in such a way that their symbols are unambiguously grounded.\" \n",
      "                    (Cantwell Smith 2019: 79).\n",
      "                \n",
      "Paragraph: As a final upshot of the debate we wish to point out that at least some philosophers, being vocal about AI, lack the technical knowledge in computer science to assess the activities and progress in the field. To those who refuse to live in the present, they are more foolish commentators than experts. Then, against the principle of charity or of vouchsafing the benefit of a doubt, they simplistically take it for granted that all computation is Turing computation, and as such semantically empty; that there is erroneously just the abstract, in lieu of the implementations of programs where the implementation relation relates the abstract and concrete domains.\n",
      "\n",
      "Head: Conclusion\n",
      "Paragraph: The often nebulous terms \"Strong AI\" (SAI), \"Superintelligence\" (SIAI), \"Singularity\" (S), and \"Artificial General Intelligence\" (AGI) were specified and put to work. Based on our contribution to concept clarification in Sect. 3, we reviewed three arguments from philosophy of AI. We found that none of the three arguments portrayed and discussed is sound. The conclusion is that there appear to be neither enforcers of singularity S or strong AI SAI, nor any in-principle barriers to the ambitions of SAI.\n",
      "Paragraph: My own take on S and SAI is that I do not relegate the possibility that AI will eventually reach human or superhuman intelligences. However, I am also convinced that there will be no uncontrolled exponential growth. Given empirical evidence, it is much more likely that we humans will have to program most of the intelligence into the AIs ourselves. Scientific knowledge, commonsense, education, and innate templates are all indispensable for achieving SAI; and, as we learned from Pearl, only creatures that are already on the third rung of the causal ladder (i.e., humans) can pass it on.\n",
      "Paragraph: Our experience with most AI systems so far suggests that the marginal yield is rapidly decreasing and frequent trend changes are taking place, which will not spare deep learning as one of the most popular and hyped applications of AI nowadays \n",
      "                    (Marcus 2018). Initially, we pick all the lowhanging fruits (e.g., text translations with DeepL Translate) and generate progress swiftly, but then we run into difficulties: what about many more use cases?\n",
      "                \n",
      "Paragraph: Maybe global AI may improve infinitely, but to what extent its overall intelligence increases could be limited. If, for instance, each generation increases by 50% compared to the previous one, then, according to old insights such as from Zeno's \"paradox\" on Achilles and the tortoise, the initial intelligence can at most double, because the infinite sum adds up to a maximum of 2.\n",
      "Paragraph: The declaration that SAI and S can happen concerns still most distant possible worlds and is rather uninteresting because it lacks operational significance. However, anything beyond is long on faith, and short on rigorous argument.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "# Function to extract text from an element, including nested tags\n",
    "def get_full_text(element):\n",
    "    if element is None:\n",
    "        return ''\n",
    "    # Start with the element text, if any\n",
    "    text = element.text or ''\n",
    "    # Iterate through any children and append their text\n",
    "    for child in element:\n",
    "        # Add child's text (before tag)\n",
    "        text += get_full_text(child)\n",
    "        # Add child's tail text (after tag)\n",
    "        if child.tail:\n",
    "            text += child.tail\n",
    "    return text\n",
    "\n",
    "# Extract required elements\n",
    "title = get_full_text(root.find('.//tei:titleStmt/tei:title', namespaces))\n",
    "publisher = get_full_text(root.find('.//tei:publicationStmt/tei:publisher', namespaces))\n",
    "date = get_full_text(root.find('.//tei:publicationStmt/tei:date', namespaces))\n",
    "\n",
    "# Extract author information\n",
    "author_elem = root.find('.//tei:author/tei:persName', namespaces)\n",
    "author = \" \".join(filter(None, [\n",
    "    get_full_text(author_elem.find('tei:forename[@type=\"first\"]', namespaces)),\n",
    "    get_full_text(author_elem.find('tei:forename[@type=\"middle\"]', namespaces)),\n",
    "    get_full_text(author_elem.find('tei:surname', namespaces))\n",
    "]))\n",
    "\n",
    "# Extract keywords\n",
    "keywords = [get_full_text(term) for term in root.findall('.//tei:keywords/tei:term', namespaces)]\n",
    "\n",
    "# Extract abstract\n",
    "abstract_elem = root.find('.//tei:abstract/tei:div/tei:p', namespaces)\n",
    "abstract = get_full_text(abstract_elem)\n",
    "\n",
    "# Recursive function to extract headings and paragraphs from the body\n",
    "def extract_body_content(element):\n",
    "    content = []\n",
    "    for div in element.findall('tei:div', namespaces):\n",
    "        head = get_full_text(div.find('tei:head', namespaces))\n",
    "        paragraphs = [get_full_text(p) for p in div.findall('tei:p', namespaces)]\n",
    "        content.append({\n",
    "            'head': head,\n",
    "            'paragraphs': paragraphs\n",
    "        })\n",
    "        # Recursive call to capture nested content\n",
    "        content.extend(extract_body_content(div))\n",
    "    return content\n",
    "\n",
    "# Extract content from the body\n",
    "body_content = extract_body_content(root.find('.//tei:body', namespaces))\n",
    "\n",
    "# Print extracted data\n",
    "print(\"Title:\", title)\n",
    "print(\"Publisher:\", publisher)\n",
    "print(\"Date:\", date)\n",
    "print(\"Author:\", author)\n",
    "print(\"Keywords:\", keywords)\n",
    "print(\"Abstract:\", abstract)\n",
    "print(\"\\nBody Content:\")\n",
    "for section in body_content:\n",
    "    print(\"\\nHead:\", section['head'])\n",
    "    for paragraph in section['paragraphs']:\n",
    "        print(\"Paragraph:\", paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb50a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Bibliographic Entry:\n",
      "K Andrews, J Beck (Introduction) None, , pp 1–10\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "# Locate the first bibliographic entry within listBibl\n",
    "list_bibl = root.find('.//tei:listBibl', namespaces)\n",
    "first_entry = list_bibl.findall('tei:biblStruct', namespaces)[0]\n",
    "\n",
    "# Extracting author names\n",
    "authors = []\n",
    "for author in first_entry.findall('.//tei:author/tei:persName', namespaces):\n",
    "    forenames = [name.text for name in author.findall('tei:forename', namespaces)]\n",
    "    surname = author.find('tei:surname', namespaces).text\n",
    "    full_name = \" \".join(forenames + [surname])\n",
    "    authors.append(full_name)\n",
    "\n",
    "# Extracting title, publisher, location, pages\n",
    "title = first_entry.find('.//tei:title', namespaces).text\n",
    "publisher = first_entry.find('.//tei:monogr/tei:imprint/tei:publisher', namespaces)\n",
    "location = first_entry.find('.//tei:monogr/tei:imprint/tei:pubPlace', namespaces).text if first_entry.find('.//tei:monogr/tei:imprint/tei:pubPlace', namespaces) else \"\"\n",
    "pages = first_entry.find('.//tei:monogr/tei:imprint/tei:biblScope[@unit=\"page\"]', namespaces)\n",
    "page_range = f\"pp {pages.get('from')}–{pages.get('to')}\" if pages is not None else \"\"\n",
    "\n",
    "# Format and print the result\n",
    "formatted_authors = \", \".join(authors)\n",
    "formatted_bibl_entry = f\"{formatted_authors} ({title}) {publisher}, {location}, {page_range}\"\n",
    "\n",
    "print(\"First Bibliographic Entry:\")\n",
    "print(formatted_bibl_entry)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
