{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "745eb47a",
   "metadata": {},
   "source": [
    "# Data Indexing, Data Retrieval and Generation\n",
    "\n",
    "There are two central steps involved:\n",
    "\n",
    "\n",
    "**Data Indexing:**\n",
    "1. Documents are loaded and split into smaller text chunks.\n",
    "2. Text chunks are converted into vector embeddings and stored in a vector database (Vector DB) next to their respective text chunks.\n",
    "\n",
    "**Data Retrieval and Generation:**\n",
    "1. A user query is embedded and used to retrieve relevant text chunks from the Vector DB.\n",
    "2. Retrieved chunks are processed by a large language model (LLM) to generate a contextually relevant response.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "**Coding sources**\n",
    "\n",
    "I extend the code provided and explained in the following YouTube Video: \n",
    "\n",
    "- RAG Langchain Python Project: Easy AI/Chat For Your Docs: https://www.youtube.com/watch?v=tcqEUSNCn8I\n",
    "    + GitHub: https://github.com/pixegami/langchain-rag-tutorial\n",
    "\n",
    "\n",
    "## problem: incompatibility between packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## could be necessary to downgrade package:\n",
    "# pip uninstall langchain-core\n",
    "# pip install langchain-core==0.3.10\n",
    "## or install older version of chromadb:\n",
    "# pip install --upgrade chromadb==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de6bc2",
   "metadata": {},
   "source": [
    "## Get API, local supabase server key(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f150b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Assuming 'src' is one level down (in the current directory or a subdirectory)\n",
    "path_to_src = os.path.join('../..','src')  # Moves one level down to 'src' folder\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(path_to_src)\n",
    "\n",
    "# Now you can import your API_key module\n",
    "import API_key as key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f770440",
   "metadata": {},
   "source": [
    "## include self-written functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4eadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.forChromaApproach as di_drg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb2d8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\DATEN\\PHD\\WORKSHOPS\\introductory workshop in LLMs\\4_summarizingLiterature\\RAG\n"
     ]
    }
   ],
   "source": [
    "# Print the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce202d6",
   "metadata": {},
   "source": [
    "# Data Indexing\n",
    "## Data Preperation: Documents are loaded and split into smaller text chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dbd003",
   "metadata": {},
   "source": [
    "**load_pdfs_by_filename**: Loads and stores PDF pages by filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e9dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 110 0 (offset 0)\n",
      "Ignoring wrong pointing object 244 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 1319 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 44 0 (offset 0)\n",
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 118 0 (offset 0)\n",
      "Ignoring wrong pointing object 438 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 199 0 (offset 0)\n",
      "Ignoring wrong pointing object 331 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 150 0 (offset 0)\n",
      "Ignoring wrong pointing object 232 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 135 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 12 65536 (offset 0)\n",
      "Ignoring wrong pointing object 41 65536 (offset 0)\n",
      "Ignoring wrong pointing object 45 65536 (offset 0)\n",
      "Ignoring wrong pointing object 49 65536 (offset 0)\n",
      "Ignoring wrong pointing object 53 65536 (offset 0)\n",
      "Ignoring wrong pointing object 57 65536 (offset 0)\n",
      "Ignoring wrong pointing object 61 65536 (offset 0)\n",
      "Ignoring wrong pointing object 65 65536 (offset 0)\n",
      "Ignoring wrong pointing object 69 65536 (offset 0)\n",
      "Ignoring wrong pointing object 73 65536 (offset 0)\n",
      "Ignoring wrong pointing object 77 65536 (offset 0)\n",
      "Ignoring wrong pointing object 81 65536 (offset 0)\n",
      "Ignoring wrong pointing object 85 65536 (offset 0)\n",
      "Ignoring wrong pointing object 89 65536 (offset 0)\n",
      "Ignoring wrong pointing object 93 65536 (offset 0)\n",
      "Ignoring wrong pointing object 97 65536 (offset 0)\n",
      "Ignoring wrong pointing object 101 65536 (offset 0)\n",
      "Ignoring wrong pointing object 105 65536 (offset 0)\n",
      "Ignoring wrong pointing object 109 65536 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 49 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 69 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "Ignoring wrong pointing object 153 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PDF: 10.1002_sd.2048.pdf\n",
      "Total Pages: 14\n",
      "\n",
      "PDF: 10.1007_s00146-023-01650-z.pdf\n",
      "Total Pages: 8\n",
      "\n",
      "PDF: 10.1007_s10506-017-9206-9.pdf\n",
      "Total Pages: 15\n",
      "\n",
      "PDF: 10.1007_s11077-022-09452-8.pdf\n",
      "Total Pages: 23\n",
      "\n",
      "PDF: 10.1007_s11569-024-00454-9.pdf\n",
      "Total Pages: 29\n",
      "\n",
      "PDF: 10.1007_s40804-020-00200-0.pdf\n",
      "Total Pages: 27\n",
      "\n",
      "PDF: 10.1017_err.2019.8.pdf\n",
      "Total Pages: 19\n",
      "\n",
      "PDF: 10.1017_err.2021.52.pdf\n",
      "Total Pages: 25\n",
      "\n",
      "PDF: 10.1017_err.2022.14.pdf\n",
      "Total Pages: 16\n",
      "\n",
      "PDF: 10.1017_err.2023.1.pdf\n",
      "Total Pages: 19\n",
      "\n",
      "PDF: 10.1080_13600834.2018.1488659.pdf\n",
      "Total Pages: 19\n",
      "\n",
      "PDF: 10.1080_13669877.2021.1957985.pdf\n",
      "Total Pages: 14\n",
      "\n",
      "PDF: 10.1111_bioe.13124.pdf\n",
      "Total Pages: 9\n",
      "\n",
      "PDF: 10.1111_rego.12512.pdf\n",
      "Total Pages: 30\n",
      "\n",
      "PDF: 10.1111_rego.12563.pdf\n",
      "Total Pages: 18\n",
      "\n",
      "PDF: 10.1111_rego.12568.pdf\n",
      "Total Pages: 22\n",
      "\n",
      "PDF: 10.1177_0266382120923962.pdf\n",
      "Total Pages: 9\n",
      "\n",
      "PDF: 10.1177_2053951719860542.pdf\n",
      "Total Pages: 14\n",
      "\n",
      "PDF: 10.1177_20539517211039493.pdf\n",
      "Total Pages: 5\n",
      "\n",
      "PDF: 10.14658_pupj-jelt-2021-2-2.pdf\n",
      "Total Pages: 20\n",
      "\n",
      "PDF: 10.2139_ssrn.2609777.pdf\n",
      "Total Pages: 49\n",
      "\n",
      "PDF: 10.2139_ssrn.3501410.pdf\n",
      "Total Pages: 26\n",
      "\n",
      "PDF: 10.24251_HICSS.2020.647.pdf\n",
      "Total Pages: 10\n",
      "\n",
      "PDF: 10.24251_HICSS.2021.664.pdf\n",
      "Total Pages: 10\n",
      "\n",
      "PDF: 10.2979_gls.2023.a886162.pdf\n",
      "Total Pages: 27\n",
      "\n",
      "PDF: 10.4324_9780429262081-19.pdf\n",
      "Total Pages: 17\n",
      "\n",
      "PDF: 10.48550_arXiv.2305.02231.pdf\n",
      "Total Pages: 30\n",
      "\n",
      "PDF: doi-10.1017_err.2022.38.pdf\n",
      "Total Pages: 13\n",
      "\n",
      "PDF: white house_AI.pdf\n",
      "Total Pages: 16\n"
     ]
    }
   ],
   "source": [
    "path_to_PDFs = os.path.join('PDFs/AIregulation')  # Moves one level up to 'PDFs' folder\n",
    "\n",
    "\n",
    "pdf_pages = di_drg.load_pdfs_by_filename(path_to_PDFs, verbose=False)\n",
    "\n",
    "# Optional: Print the loaded pages by filename\n",
    "for filename, pages in pdf_pages.items():\n",
    "    print(f\"\\nPDF: {filename}\")\n",
    "    print(f\"Total Pages: {len(pages)}\")\n",
    "    # print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8630b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first PDF of folder: 10.1002_sd.2048.pdf\n",
      "First Page: page_content='RESEARCH ARTICLE\n",
      "Governing Artificial Intelligence to benefit the UN Sustainable\n",
      "Development Goals\n",
      "Jon Truby\n",
      "Law & Development, College of Law, Qatar\n",
      "University, Doha, Qatar\n",
      "Correspondence\n",
      "Jon Truby, Centre for Law & Development,\n",
      "College of Law, Qatar University, PO BOX\n",
      "2713 Doha, Qatar.\n",
      "Email: jon.truby@qu.edu.qa\n",
      "Funding information\n",
      "Qatar National Research Fund, Grant/Award\n",
      "Number: NPRP 11S-1119-170016Abstract\n",
      "Big Tech's unregulated roll-out out of experimental AI poses risks to the achievement of\n",
      "the UN Sustainable Development Goals (SDGs), w ith particular vulnerability for develop-\n",
      "ing countries. The goal of financial inclusion is threatened by the imperfect and\n",
      "ungoverned design and implementation of AI decision-making software making important\n",
      "financial decisions affecting customers. Aut omated decision-makin ga l g o r i t h m sh a v ed i s -\n",
      "played evidence of bias, lack ethical gover nance, and limit transparency in the basis for\n",
      "their decisions, causing unfair outcomes and amplify unequal access to finance. Poverty\n",
      "reduction and sustainable development targets are risked by Big Tech's potential exploita-\n",
      "tion of developing countries by using AI to harvest data and profits. Stakeholder progress\n",
      "toward preventing financial crime and corruptio ni sf u r t h e rt h r e a t e n e db yp o t e n t i a lm i s u s e\n",
      "of AI. In the light of such risks, Big Tech's unscrupulous history means it cannot be trusted\n",
      "to operate without regulatory oversight. The a rticle proposes effective pre-emptive regu-\n",
      "latory options to minimize scenarios of AI dam aging the SDGs. It explores internationally\n",
      "accepted principles of AI gove rnance, and argues for their implementation as regulatory\n",
      "requirements governing AI developers and code rs, with compliance verified through algo-\n",
      "rithmic auditing. Furthermore, it argues t hat AI governance frameworks must require a\n",
      "benefit to the SDGs. The article argues that proactively predicting such problems can\n",
      "enable continued AI innovation through well- designed regulations adhering to interna-\n",
      "tional principles. It highlights risks of unr egulated AI causing harm to human interests,\n",
      "where a public and regulatory backlash may re sult in over-regulation that could damage\n",
      "the otherwise beneficial development of AI.\n",
      "KEYWORDS\n",
      "Artificial intelligence, Big Tech, black box, financial inclusion, financial technology, regulation,\n",
      "SDGs, sustainable development, technology governance\n",
      "1|THE WILD WEST OF UNREGULATED\n",
      "EXPERIMENTAL AI\n",
      "1.1 |Unchecked development context\n",
      "The unchecked advancement of AI (Artificial Intelligence) risks\n",
      "diminishing progress toward the UN Sustainable Development Goals(SDGs) in a number of key target areas, and this risk is enhanced in\n",
      "the developing world (Vinuesa et al., 2020). Promising and feasible\n",
      "possibilities of AI-driven developmental progress are being over-\n",
      "shadowed by the current unfettered experimentation with untested\n",
      "AI technology in markets and societies. “Big Tech ”has proven beyond\n",
      "doubt that it cannot be trusted to self-regulate or adhere to voluntary\n",
      "standards, and in the absence of pre-emptive regulation, trust willReceived: 17 December 2019 Revised: 22 January 2020 Accepted: 5 February 2020\n",
      "DOI: 10.1002/sd.2048\n",
      "This is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any me dium,\n",
      "provided the original work is properly cited.\n",
      "© 2020 The Authors. Sustainable Development published by ERP Environment and John Wiley & Sons Ltd\n",
      "946 Sustainable Development. 2020;28:946 –959. wileyonlinelibrary.com/journal/sd\n",
      "' metadata={'source': 'PDFs/AIregulation\\\\10.1002_sd.2048.pdf', 'page': 0} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming pdf_chunks is the dictionary containing chunks for each PDF\n",
    "first_key = list(pdf_pages.keys())[0]  # Get the first PDF filename\n",
    "print(\"first PDF of folder:\", first_key)\n",
    "first_pdf_pages = pdf_pages[first_key]  # Get the chunks for the first PDF\n",
    "\n",
    "\n",
    "# Print the first page\n",
    "print(\"First Page:\", first_pdf_pages[0], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d581a",
   "metadata": {},
   "source": [
    "**split_pdf_pages_into_chunks**: Splits and stores PDF pages into chunks by filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c2bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PDF: 10.1002_sd.2048.pdf\n",
      "Total Chunks: 254\n",
      "\n",
      "PDF: 10.1007_s00146-023-01650-z.pdf\n",
      "Total Chunks: 136\n",
      "\n",
      "PDF: 10.1007_s10506-017-9206-9.pdf\n",
      "Total Chunks: 120\n",
      "\n",
      "PDF: 10.1007_s11077-022-09452-8.pdf\n",
      "Total Chunks: 256\n",
      "\n",
      "PDF: 10.1007_s11569-024-00454-9.pdf\n",
      "Total Chunks: 405\n",
      "\n",
      "PDF: 10.1007_s40804-020-00200-0.pdf\n",
      "Total Chunks: 248\n",
      "\n",
      "PDF: 10.1017_err.2019.8.pdf\n",
      "Total Chunks: 181\n",
      "\n",
      "PDF: 10.1017_err.2021.52.pdf\n",
      "Total Chunks: 285\n",
      "\n",
      "PDF: 10.1017_err.2022.14.pdf\n",
      "Total Chunks: 182\n",
      "\n",
      "PDF: 10.1017_err.2023.1.pdf\n",
      "Total Chunks: 241\n",
      "\n",
      "PDF: 10.1080_13600834.2018.1488659.pdf\n",
      "Total Chunks: 184\n",
      "\n",
      "PDF: 10.1080_13669877.2021.1957985.pdf\n",
      "Total Chunks: 161\n",
      "\n",
      "PDF: 10.1111_bioe.13124.pdf\n",
      "Total Chunks: 162\n",
      "\n",
      "PDF: 10.1111_rego.12512.pdf\n",
      "Total Chunks: 416\n",
      "\n",
      "PDF: 10.1111_rego.12563.pdf\n",
      "Total Chunks: 290\n",
      "\n",
      "PDF: 10.1111_rego.12568.pdf\n",
      "Total Chunks: 337\n",
      "\n",
      "PDF: 10.1177_0266382120923962.pdf\n",
      "Total Chunks: 116\n",
      "\n",
      "PDF: 10.1177_2053951719860542.pdf\n",
      "Total Chunks: 195\n",
      "\n",
      "PDF: 10.1177_20539517211039493.pdf\n",
      "Total Chunks: 66\n",
      "\n",
      "PDF: 10.14658_pupj-jelt-2021-2-2.pdf\n",
      "Total Chunks: 147\n",
      "\n",
      "PDF: 10.2139_ssrn.2609777.pdf\n",
      "Total Chunks: 424\n",
      "\n",
      "PDF: 10.2139_ssrn.3501410.pdf\n",
      "Total Chunks: 282\n",
      "\n",
      "PDF: 10.24251_HICSS.2020.647.pdf\n",
      "Total Chunks: 135\n",
      "\n",
      "PDF: 10.24251_HICSS.2021.664.pdf\n",
      "Total Chunks: 147\n",
      "\n",
      "PDF: 10.2979_gls.2023.a886162.pdf\n",
      "Total Chunks: 195\n",
      "\n",
      "PDF: 10.4324_9780429262081-19.pdf\n",
      "Total Chunks: 163\n",
      "\n",
      "PDF: 10.48550_arXiv.2305.02231.pdf\n",
      "Total Chunks: 496\n",
      "\n",
      "PDF: doi-10.1017_err.2022.38.pdf\n",
      "Total Chunks: 154\n",
      "\n",
      "PDF: white house_AI.pdf\n",
      "Total Chunks: 135\n"
     ]
    }
   ],
   "source": [
    "pdf_chunks = di_drg.split_pdf_pages_into_chunks(pdf_pages, chunk_size=500, chunk_overlap=150, verbose=False)\n",
    "\n",
    "# Optional: Print a summary of chunks created per PDF\n",
    "for filename, chunks in pdf_chunks.items():\n",
    "    print(f\"\\nPDF: {filename}\")\n",
    "    print(f\"Total Chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe313b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first PDF of folder: 10.1002_sd.2048.pdf\n",
      "\n",
      "First Chunk: page_content='RESEARCH ARTICLE\n",
      "Governing Artificial Intelligence to benefit the UN Sustainable\n",
      "Development Goals\n",
      "Jon Truby\n",
      "Law & Development, College of Law, Qatar\n",
      "University, Doha, Qatar\n",
      "Correspondence\n",
      "Jon Truby, Centre for Law & Development,\n",
      "College of Law, Qatar University, PO BOX\n",
      "2713 Doha, Qatar.\n",
      "Email: jon.truby@qu.edu.qa\n",
      "Funding information\n",
      "Qatar National Research Fund, Grant/Award\n",
      "Number: NPRP 11S-1119-170016Abstract' metadata={'source': 'PDFs/AIregulation\\\\10.1002_sd.2048.pdf', 'page': 0} \n",
      "\n",
      "\n",
      "Second Chunk: page_content='2713 Doha, Qatar.\n",
      "Email: jon.truby@qu.edu.qa\n",
      "Funding information\n",
      "Qatar National Research Fund, Grant/Award\n",
      "Number: NPRP 11S-1119-170016Abstract\n",
      "Big Tech's unregulated roll-out out of experimental AI poses risks to the achievement of\n",
      "the UN Sustainable Development Goals (SDGs), w ith particular vulnerability for develop-\n",
      "ing countries. The goal of financial inclusion is threatened by the imperfect and\n",
      "ungoverned design and implementation of AI decision-making software making important' metadata={'source': 'PDFs/AIregulation\\\\10.1002_sd.2048.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# Assuming pdf_chunks is the dictionary containing chunks for each PDF\n",
    "first_key = list(pdf_chunks.keys())[0]  # Get the first PDF filename\n",
    "print(\"first PDF of folder:\", first_key)\n",
    "first_pdf_chunks = pdf_chunks[first_key]  # Get the chunks for the first PDF\n",
    "\n",
    "# Access the first and second chunks\n",
    "first_chunk = first_pdf_chunks[0]\n",
    "second_chunk = first_pdf_chunks[1]\n",
    "\n",
    "# Print the first two chunks\n",
    "print(\"\\nFirst Chunk:\", first_chunk, \"\\n\\n\")\n",
    "print(\"Second Chunk:\", second_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506bbb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page content: RESEARCH ARTICLE\n",
      "Governing Artificial Intelligence to benefit the UN Sustainable\n",
      "Development Goals\n",
      "Jon Truby\n",
      "Law & Development, College of Law, Qatar\n",
      "University, Doha, Qatar\n",
      "Correspondence\n",
      "Jon Truby, Centre for Law & Development,\n",
      "College of Law, Qatar University, PO BOX\n",
      "2713 Doha, Qatar.\n",
      "Email: jon.truby@qu.edu.qa\n",
      "Funding information\n",
      "Qatar National Research Fund, Grant/Award\n",
      "Number: NPRP 11S-1119-170016Abstract \n",
      "\n",
      "\n",
      "metadata: {'source': 'PDFs/AIregulation\\\\10.1002_sd.2048.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"page content:\", first_chunk.page_content, \"\\n\\n\")\n",
    "print(\"metadata:\", first_chunk.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4ca22",
   "metadata": {},
   "source": [
    "## Data Storage: Text chunks are converted into vector embeddings and stored in a vector database (Vector DB) next to their respective text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acaaa689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DATEN\\PHD\\WORKSHOPS\\introductory workshop in LLMs\\4_summarizingLiterature\\RAG\\src\\forChromaApproach.py:90: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=OpenAIEmbeddings(api_key=openAI_key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sources in DB: 3\n",
      "\n",
      "Sources:\n",
      " ['PDFs/AIregulation\\\\10.1007_s10506-017-9206-9.pdf', 'PDFs/AIregulation\\\\10.1002_sd.2048.pdf', 'PDFs/AIregulation\\\\10.1007_s00146-023-01650-z.pdf']\n",
      "\n",
      "Cleaned sources:\n",
      " ['10.1007_s10506-017-9206-9.pdf', '10.1002_sd.2048.pdf', '10.1007_s00146-023-01650-z.pdf']\n"
     ]
    }
   ],
   "source": [
    "path_to_Chroma = os.path.join('DB_Chroma')  # Moves one level up to 'PDFs' folder\n",
    "\n",
    "sources_DB = di_drg.inspect_chrom(CHROMA_PATH=path_to_Chroma, openAI_key=key.openAI_key)\n",
    "print(\"Number of sources in DB:\", len(sources_DB))\n",
    "print(\"\\nSources:\\n\", sources_DB)\n",
    "\n",
    "# Remove the \"PDFs\\\\\" prefix from all entries\n",
    "cleaned_sources_DB = [pdf.replace('PDFs\\\\', '').replace('PDFs/AIregulation\\\\', '') for pdf in sources_DB]\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nCleaned sources:\\n\", cleaned_sources_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc9dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PDF '10.1007_s11077-022-09452-8.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1007_s11077-022-09452-8.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DATEN\\PHD\\WORKSHOPS\\introductory workshop in LLMs\\4_summarizingLiterature\\RAG\\src\\forChromaApproach.py:70: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 256 chunks to DB_Chroma.\n",
      "The PDF '10.1007_s11569-024-00454-9.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1007_s11569-024-00454-9.pdf\n",
      "Saved 405 chunks to DB_Chroma.\n",
      "The PDF '10.1007_s40804-020-00200-0.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1007_s40804-020-00200-0.pdf\n",
      "Saved 248 chunks to DB_Chroma.\n",
      "The PDF '10.1017_err.2019.8.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1017_err.2019.8.pdf\n",
      "Saved 181 chunks to DB_Chroma.\n",
      "The PDF '10.1017_err.2021.52.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1017_err.2021.52.pdf\n",
      "Saved 285 chunks to DB_Chroma.\n",
      "The PDF '10.1017_err.2022.14.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1017_err.2022.14.pdf\n",
      "Saved 182 chunks to DB_Chroma.\n",
      "The PDF '10.1017_err.2023.1.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1017_err.2023.1.pdf\n",
      "Saved 241 chunks to DB_Chroma.\n",
      "The PDF '10.1080_13600834.2018.1488659.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1080_13600834.2018.1488659.pdf\n",
      "Saved 184 chunks to DB_Chroma.\n",
      "The PDF '10.1080_13669877.2021.1957985.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1080_13669877.2021.1957985.pdf\n",
      "Saved 161 chunks to DB_Chroma.\n",
      "The PDF '10.1111_bioe.13124.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1111_bioe.13124.pdf\n",
      "Saved 162 chunks to DB_Chroma.\n",
      "The PDF '10.1111_rego.12512.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1111_rego.12512.pdf\n",
      "Saved 416 chunks to DB_Chroma.\n",
      "The PDF '10.1111_rego.12563.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1111_rego.12563.pdf\n",
      "Saved 290 chunks to DB_Chroma.\n",
      "The PDF '10.1111_rego.12568.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1111_rego.12568.pdf\n",
      "Saved 337 chunks to DB_Chroma.\n",
      "The PDF '10.1177_0266382120923962.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1177_0266382120923962.pdf\n",
      "Saved 116 chunks to DB_Chroma.\n",
      "The PDF '10.1177_2053951719860542.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1177_2053951719860542.pdf\n",
      "Saved 195 chunks to DB_Chroma.\n",
      "The PDF '10.1177_20539517211039493.pdf' is not included in the DB, as such:\n",
      "create DB for 10.1177_20539517211039493.pdf\n",
      "Saved 66 chunks to DB_Chroma.\n",
      "The PDF '10.14658_pupj-jelt-2021-2-2.pdf' is not included in the DB, as such:\n",
      "create DB for 10.14658_pupj-jelt-2021-2-2.pdf\n",
      "Saved 147 chunks to DB_Chroma.\n",
      "The PDF '10.2139_ssrn.2609777.pdf' is not included in the DB, as such:\n",
      "create DB for 10.2139_ssrn.2609777.pdf\n",
      "Saved 424 chunks to DB_Chroma.\n",
      "The PDF '10.2139_ssrn.3501410.pdf' is not included in the DB, as such:\n",
      "create DB for 10.2139_ssrn.3501410.pdf\n",
      "Saved 282 chunks to DB_Chroma.\n",
      "The PDF '10.24251_HICSS.2020.647.pdf' is not included in the DB, as such:\n",
      "create DB for 10.24251_HICSS.2020.647.pdf\n",
      "Saved 135 chunks to DB_Chroma.\n",
      "The PDF '10.24251_HICSS.2021.664.pdf' is not included in the DB, as such:\n",
      "create DB for 10.24251_HICSS.2021.664.pdf\n",
      "Saved 147 chunks to DB_Chroma.\n",
      "The PDF '10.2979_gls.2023.a886162.pdf' is not included in the DB, as such:\n",
      "create DB for 10.2979_gls.2023.a886162.pdf\n",
      "Saved 195 chunks to DB_Chroma.\n",
      "The PDF '10.4324_9780429262081-19.pdf' is not included in the DB, as such:\n",
      "create DB for 10.4324_9780429262081-19.pdf\n",
      "Saved 163 chunks to DB_Chroma.\n",
      "The PDF '10.48550_arXiv.2305.02231.pdf' is not included in the DB, as such:\n",
      "create DB for 10.48550_arXiv.2305.02231.pdf\n",
      "Saved 496 chunks to DB_Chroma.\n",
      "The PDF 'doi-10.1017_err.2022.38.pdf' is not included in the DB, as such:\n",
      "create DB for doi-10.1017_err.2022.38.pdf\n",
      "Saved 154 chunks to DB_Chroma.\n",
      "The PDF 'white house_AI.pdf' is not included in the DB, as such:\n",
      "create DB for white house_AI.pdf\n",
      "Saved 135 chunks to DB_Chroma.\n"
     ]
    }
   ],
   "source": [
    "# if you want to remove your DB:\n",
    "## di_drg.remove_chrom(CHROMA_PATH=path_to_Chroma)\n",
    "\n",
    "# pdf_chunks is a dictionary as such we can run over the keys:\n",
    "for pdf in pdf_chunks.keys():\n",
    "    if pdf not in cleaned_sources_DB:\n",
    "        print(f\"The PDF '{pdf}' is not included in the DB, as such:\")\n",
    "        print(\"create DB for\", pdf)\n",
    "        di_drg.save_to_chrom(chunks=pdf_chunks[pdf], CHROMA_PATH=path_to_Chroma, openAI_key=key.openAI_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd7dba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sources in DB: 29\n",
      "\n",
      "Sources:\n",
      " ['PDFs/AIregulation\\\\10.1017_err.2021.52.pdf', 'PDFs/AIregulation\\\\10.2979_gls.2023.a886162.pdf', 'PDFs/AIregulation\\\\10.1177_20539517211039493.pdf', 'PDFs/AIregulation\\\\10.1111_rego.12563.pdf', 'PDFs/AIregulation\\\\10.1017_err.2019.8.pdf', 'PDFs/AIregulation\\\\10.2139_ssrn.2609777.pdf', 'PDFs/AIregulation\\\\10.24251_HICSS.2020.647.pdf', 'PDFs/AIregulation\\\\10.1007_s11077-022-09452-8.pdf', 'PDFs/AIregulation\\\\10.1007_s11569-024-00454-9.pdf', 'PDFs/AIregulation\\\\doi-10.1017_err.2022.38.pdf', 'PDFs/AIregulation\\\\10.1111_rego.12512.pdf', 'PDFs/AIregulation\\\\10.4324_9780429262081-19.pdf', 'PDFs/AIregulation\\\\10.2139_ssrn.3501410.pdf', 'PDFs/AIregulation\\\\10.1007_s00146-023-01650-z.pdf', 'PDFs/AIregulation\\\\10.1111_rego.12568.pdf', 'PDFs/AIregulation\\\\10.1080_13600834.2018.1488659.pdf', 'PDFs/AIregulation\\\\10.48550_arXiv.2305.02231.pdf', 'PDFs/AIregulation\\\\10.1017_err.2023.1.pdf', 'PDFs/AIregulation\\\\10.1111_bioe.13124.pdf', 'PDFs/AIregulation\\\\10.14658_pupj-jelt-2021-2-2.pdf', 'PDFs/AIregulation\\\\10.1002_sd.2048.pdf', 'PDFs/AIregulation\\\\10.1080_13669877.2021.1957985.pdf', 'PDFs/AIregulation\\\\10.1007_s10506-017-9206-9.pdf', 'PDFs/AIregulation\\\\10.1177_0266382120923962.pdf', 'PDFs/AIregulation\\\\10.1007_s40804-020-00200-0.pdf', 'PDFs/AIregulation\\\\white house_AI.pdf', 'PDFs/AIregulation\\\\10.1017_err.2022.14.pdf', 'PDFs/AIregulation\\\\10.24251_HICSS.2021.664.pdf', 'PDFs/AIregulation\\\\10.1177_2053951719860542.pdf']\n"
     ]
    }
   ],
   "source": [
    "sources_DB = di_drg.inspect_chrom(CHROMA_PATH=path_to_Chroma, openAI_key=key.openAI_key)\n",
    "print(\"Number of sources in DB:\", len(sources_DB))\n",
    "print(\"\\nSources:\\n\", sources_DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c1316",
   "metadata": {},
   "source": [
    "# Data Retrieval and Generation\n",
    "\n",
    "your prompt template (system message):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7405d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50119e02",
   "metadata": {},
   "source": [
    "your question (user message):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f5db8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question you ask to your DB:\n",
    "question = \"\"\"\n",
    "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9edde",
   "metadata": {},
   "source": [
    "retrieve data (see \"source_page_pairs\" and \"X_hits\") and generate response (see \"response\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615f638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "impact the trust relationship between a human and an arti ﬁcial agent and are aspects that regulation can shape\n",
      "in a direct manner. In democracies, the legal framework can be amended to address novel issues (e.g., proposed\n",
      "AI Act, see Section 4) and the institutional setting changed according to the needs of society. Regulation thus lays\n",
      "down the way in which interactions occur and determines the underlying characteristics of the environment in\n",
      "which trust relationships emerge.\n",
      "\n",
      "---\n",
      "\n",
      "nology to the public sector (Aoki, 2021 , p. 1).\n",
      "The ﬁrst reviewed study by Aoki concerns the introduction of and citizens ’initial public trust in AI chatbots\n",
      "(Aoki, 2021 ). The paper hypothesizes that initial public trust in AI chatbots depends on the area of enquiry and\n",
      "on the purposes communicated to the public for introducing the technology (Aoki, 2021 , p. 1). As with the\n",
      "research by Kennedy et al., the primary object of trust is thus the AI technology. However, the study also tests\n",
      "\n",
      "---\n",
      "\n",
      "2.4. Research questions\n",
      "Considering the analysis above, the AI Act ’s understanding of AI ’s trustworthiness as acceptability of risks com-\n",
      "bined with its predominantly paternalistic approach to risk regulation invites critical re ﬂection. In this article, we\n",
      "will address two (non-exhaustive) research questions.\n",
      "•RQ1: Under what circumstances would the AI Act be able to foster citizens ’well-placed trust in AI?\n",
      "\n",
      "---\n",
      "\n",
      "advantage of providing holistic , contextualised  \n",
      "insights into the development of  trust in AI systems \n",
      "over time . This is likely to provide a more systemic \n",
      "understanding of hitherto underexplored areas such as how st akeholder groups converge and diverge in \n",
      "relation to the ir vulnerabilities , expectations and trust \n",
      "in AI.  \n",
      "It is evident from our review that although several \n",
      "trust challenges  have been raised , many  have not been \n",
      "examined empirically , and few have been examined\n",
      "\n",
      "---\n",
      "\n",
      "13 optimal regulatory measures to accomplish the sought-after aims. Furthermore, under this reasoning, regulatory subjects preferring different aims or regulations can switch towards the regime most suitable to them, akin to a consumer’s choice on the market. As governments avidly look for the most appropriate regulation to ensure Trustworthy AI – enabling the technology to deliver its promised benefits while minimising its risks – regulatory competition leading to an outcome with the best\n",
      "\n",
      "---\n",
      "\n",
      "(AI), many countries and regions are explicitly taking part in a ‘race to AI’. Yet the increased visibility of the technology’s risks has led to ever-louder calls for regulators to look beyond the benefits, and also secure appropriate regulation to ensure AI that is ‘trustworthy’ – i.e. legal, ethical and robust. Besides minimising risks, such regulation could facilitate AI’s uptake, boost legal certainty, and hence also contribute to advancing countries’ position in the race. Consequently,\n",
      "\n",
      "---\n",
      "\n",
      "misguided or, worse, gamed. There remains a threat of misalignment between levels of actual trust and the trust-\n",
      "worthiness of applied AI. The empirical literature further illustrates how domain-speci ﬁc trust in public sector AI\n",
      "is. This casts some doubt on the effectiveness of a horizontal regulatory law such as the AI Act. Even if passed\n",
      "into law, the AI Act proposal thus appears incomplete without further sectoral regulation or standardization.\n",
      "\n",
      "---\n",
      "\n",
      "thus needed.\n",
      "Finally, the AI Act ’s conceptual con ﬂation conceals the need for trustworthy institutions to successfully engineer\n",
      "citizens ’trust in AI. Take the knowledge asymmetries between AI experts and layperson citizens as an example.\n",
      "Average citizens ’lack of understanding how AI systems work may motivate risk regulation which relies heavily on\n",
      "expert judgments, although the broader literature on risk regulation has been debating the paternalistic ﬂavor of this\n",
      "\n",
      "---\n",
      "\n",
      "easily become intertwined, for example when the user provides training data to the developer (de Andrade &\n",
      "Zarra, 2022 ). Moreover, there is no de ﬁned“role”for the addressees or subjects of an AI ’s decision or prediction.\n",
      "Within the limits of our review, these subjects would be the citizens who presumably are expected to trust the AI\n",
      "regulatory system “as a whole. ”This raises questions about the model of risk regulation —paternalistic or\n",
      "participatory —chosen by the European Commission.\n",
      "\n",
      "---\n",
      "\n",
      "Much has been written about the risks posed by artificial intelligence \n",
      "(AI). This article is interested not only in what is known about these \n",
      "risks, but what remains unknown and how that unknowing is and should \n",
      "be approached. By reviewing and expanding on the scientific literature, \n",
      "it explores how social knowledge contributes to the understanding of \n",
      "AI and its regulatory challenges. The analysis is conducted in three steps.\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DATEN\\PHD\\WORKSHOPS\\introductory workshop in LLMs\\4_summarizingLiterature\\RAG\\src\\forChromaApproach.py:147: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response_text = model.predict(prompt)\n"
     ]
    }
   ],
   "source": [
    "response, source_page_pairs, filtered_hits, all_hits = di_drg.retrieveGenerate(query_text=question, prompt_template=PROMPT_TEMPLATE, openAI_key=key.openAI_key, chroma_path=path_to_Chroma, \n",
    "                                                                            docsReturn=10, thresholdSimilarity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5169621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studying laypersons' perceptions of AI regulation is important because it provides insights into how the general public views AI technology, its potential benefits, and risks. Understanding these perceptions is crucial for the successful integration of AI into society because public trust plays a significant role in the adoption and acceptance of new technologies. \n",
      "\n",
      "By studying public perceptions, regulators can tailor their approaches to address concerns and build trust among citizens. This can help in designing regulations that are more effective, transparent, and responsive to the needs and expectations of the public. Additionally, understanding public perceptions can help in identifying potential risks and benefits associated with AI technology, allowing regulators to mitigate risks and maximize the benefits for society.\n",
      "\n",
      "Overall, studying laypersons' perceptions of AI regulation can inform regulatory approaches, enhance public trust, and ensure that the integration of AI technology into society is done in a way that is ethical, responsible, and beneficial for all stakeholders.\n",
      "[('PDFs/AIregulation\\\\10.1111_rego.12568.pdf', 11), ('PDFs/AIregulation\\\\10.1111_rego.12512.pdf', 19), ('PDFs/AIregulation\\\\10.1111_rego.12512.pdf', 5), ('PDFs/AIregulation\\\\10.24251_HICSS.2021.664.pdf', 6), ('PDFs/AIregulation\\\\10.2139_ssrn.3501410.pdf', 12), ('PDFs/AIregulation\\\\10.2139_ssrn.3501410.pdf', 0), ('PDFs/AIregulation\\\\10.1111_rego.12512.pdf', 24), ('PDFs/AIregulation\\\\10.1111_rego.12512.pdf', 25), ('PDFs/AIregulation\\\\10.1111_rego.12512.pdf', 4), ('PDFs/AIregulation\\\\10.1080_13669877.2021.1957985.pdf', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(response)\n",
    "print(source_page_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63242315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "(Document(metadata={'page': 2, 'source': 'PDFs/AIregulation\\\\white house_AI.pdf'}, page_content=\"significantly on public trust and validation, the government's regulatory and non-regulatory \\napproaches to AI should contribute to public trust in AI by promoting reliable, robust, and \\ntrustworthy AI applications. For example, an appropriate regulatory approach that reduces \\naccidents can increase public trust and thereby support the development of industries powered by \\nAI. Regulatory approaches may also be needed to protect reasonable expectations of privacy on\"), 0.8372320426012777)\n"
     ]
    }
   ],
   "source": [
    "print(len(all_hits))\n",
    "print(all_hits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cb6148",
   "metadata": {},
   "source": [
    "## it is possible to further investiagte the results of a single run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f440b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['white house_AI.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12568.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12568.pdf', '10.1111_rego.12568.pdf', 'white house_AI.pdf', '10.1111_rego.12512.pdf', 'white house_AI.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12563.pdf', '10.1177_0266382120923962.pdf', '10.1111_rego.12568.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1080_13669877.2021.1957985.pdf', '10.1080_13669877.2021.1957985.pdf', 'doi-10.1017_err.2022.38.pdf', '10.1111_rego.12512.pdf', '10.24251_HICSS.2021.664.pdf', '10.2139_ssrn.3501410.pdf', '10.1080_13669877.2021.1957985.pdf', '10.1111_rego.12512.pdf', '10.2979_gls.2023.a886162.pdf', '10.24251_HICSS.2021.664.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.24251_HICSS.2021.664.pdf', '10.1111_rego.12568.pdf', '10.2139_ssrn.3501410.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12563.pdf', '10.24251_HICSS.2021.664.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1007_s11569-024-00454-9.pdf', '10.1017_err.2021.52.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.48550_arXiv.2305.02231.pdf', 'white house_AI.pdf', '10.1111_rego.12512.pdf', '10.2139_ssrn.3501410.pdf', '10.1111_rego.12512.pdf', '10.2139_ssrn.3501410.pdf', '10.1111_rego.12512.pdf', '10.48550_arXiv.2305.02231.pdf', '10.2139_ssrn.3501410.pdf', '10.2139_ssrn.3501410.pdf', '10.24251_HICSS.2021.664.pdf', 'white house_AI.pdf', '10.1111_rego.12512.pdf', '10.1080_13669877.2021.1957985.pdf', '10.48550_arXiv.2305.02231.pdf', '10.48550_arXiv.2305.02231.pdf', '10.48550_arXiv.2305.02231.pdf', '10.1111_rego.12512.pdf', '10.2139_ssrn.3501410.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', 'white house_AI.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12568.pdf', '10.2979_gls.2023.a886162.pdf', '10.2139_ssrn.3501410.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12568.pdf', '10.1111_rego.12563.pdf', '10.1111_rego.12568.pdf', '10.1111_rego.12512.pdf', '10.1111_rego.12563.pdf', '10.1111_rego.12568.pdf', '10.1080_13669877.2021.1957985.pdf', '10.1111_rego.12512.pdf', '10.4324_9780429262081-19.pdf', '10.24251_HICSS.2021.664.pdf', '10.24251_HICSS.2020.647.pdf', '10.1111_rego.12512.pdf']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store all sources\n",
    "sources = []\n",
    "\n",
    "# Loop through each tuple and extract the source\n",
    "for doc, score in all_hits:\n",
    "    source = doc.metadata.get('source')  # Access the 'source' key from the metadata\n",
    "    if source is not None:\n",
    "        sources.append(source)\n",
    "\n",
    "# Print the list of sources\n",
    "sources = [source.replace('PDFs\\\\', '').replace('PDFs/AIregulation\\\\', '') for source in sources]\n",
    "\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3225f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            File Name  Frequency  Chunk Length PDF  \\\n",
      "1              10.1111_rego.12512.pdf         37               416   \n",
      "0                  white house_AI.pdf          6               135   \n",
      "7         10.24251_HICSS.2021.664.pdf          6               147   \n",
      "5   10.1080_13669877.2021.1957985.pdf          5               161   \n",
      "8            10.2139_ssrn.3501410.pdf          8               282   \n",
      "2              10.1111_rego.12568.pdf          9               337   \n",
      "3              10.1111_rego.12563.pdf          4               290   \n",
      "9        10.2979_gls.2023.a886162.pdf          2               195   \n",
      "12      10.48550_arXiv.2305.02231.pdf          5               496   \n",
      "4        10.1177_0266382120923962.pdf          1               116   \n",
      "14        10.24251_HICSS.2020.647.pdf          1               135   \n",
      "6         doi-10.1017_err.2022.38.pdf          1               154   \n",
      "13       10.4324_9780429262081-19.pdf          1               163   \n",
      "11            10.1017_err.2021.52.pdf          1               285   \n",
      "10     10.1007_s11569-024-00454-9.pdf          1               405   \n",
      "\n",
      "    Chunk Percentage  \n",
      "1               8.89  \n",
      "0               4.44  \n",
      "7               4.08  \n",
      "5               3.11  \n",
      "8               2.84  \n",
      "2               2.67  \n",
      "3               1.38  \n",
      "9               1.03  \n",
      "12              1.01  \n",
      "4               0.86  \n",
      "14              0.74  \n",
      "6               0.65  \n",
      "13              0.61  \n",
      "11              0.35  \n",
      "10              0.25  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Counting the frequency of each file\n",
    "file_count = Counter(sources)\n",
    "\n",
    "# Creating a DataFrame from the frequency count\n",
    "frequency_df = pd.DataFrame(file_count.items(), columns=['File Name', 'Frequency'])\n",
    "\n",
    "# Adding a new column for chunk lengths\n",
    "frequency_df[\"Chunk Length PDF\"] = 0\n",
    "\n",
    "# Loop through pdf_chunks and update the DataFrame\n",
    "for filename, chunks in pdf_chunks.items():\n",
    "    frequency_df.loc[frequency_df[\"File Name\"] == filename, \"Chunk Length PDF\"] = len(chunks)\n",
    "\n",
    "frequency_df[\"Chunk Percentage\"] = ((frequency_df[\"Frequency\"] / frequency_df[\"Chunk Length PDF\"]) * 100).round(2)\n",
    "\n",
    "frequency_df = frequency_df.sort_values(by=\"Chunk Percentage\", ascending=False)\n",
    "print(frequency_df)\n",
    "\n",
    "# Saving the DataFrame to an Excel file\n",
    "frequency_df.to_excel(\"outputs_ChromaApproach/file_frequency_table.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f95b74",
   "metadata": {},
   "source": [
    "## loop through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcc6dc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "targeted approach to policymakers to debate how to streamline regulatory efforts for future AI governance.\n",
      "Keywords: artiﬁcial intelligence, automation, human-automation trust, regulation of technology, trust, trustworthy AI.\n",
      "1. Introduction\n",
      "In May 2021, the EU Executive Vice-President, Margrethe Vestager, held a speech in which she asked: “Do\n",
      "Europeans trust technology? ”After noting several large discrepancies within member states but an overall low\n",
      "\n",
      "---\n",
      "\n",
      "research by Kennedy et al., the primary object of trust is thus the AI technology. However, the study also tests\n",
      "the variation in the degree of initial public trust in AI chatbots relative to the public trust in human administra-\n",
      "tors (Aoki, 2021 , p. 4), thus providing insights into the changes in perceived trust once the technology is being\n",
      "introduced to an institution. Aoki ﬁnds that the public ’s trust in AI chatbots is lower for some areas of enquiry\n",
      "\n",
      "---\n",
      "\n",
      "across the literature dif ﬁcult, even more so than in the normative batch of papers.\n",
      "Second, initial research on the acceptance of AI in the public sector suggests that AI is perceived differently\n",
      "from existing software systems, not least because of its recognized ability to circumstantially adapt its behavior\n",
      "(Gesk & Leyer, 2022 , p. 3). Moreover, trust in public institutions is closely linked to their perceived legitimacy.\n",
      "\n",
      "---\n",
      "\n",
      "ful convictions at the cost of preventing wrongful acquittals (see, e.g., Volokh, 1997 ). Trust perceptions are likely\n",
      "to change and further differentiate as AI continues to be used more widely. Tracking these changes empirically\n",
      "presupposes of course transparency about the utilization of AI in public institutions.\n",
      "Research outside of the ﬁnal sample seems to partly reach different conclusions than the reviewed normative\n",
      "\n",
      "---\n",
      "\n",
      "This article therefore aims to provide an intervention into the EU ’s policy effort to develop “trustworthy AI ”by\n",
      "risk regulation based on a review of the multi-disciplinary literature on trust. Instead of working out a coherent\n",
      "theory of trust, it aims to demonstrate the conceptual futility of labeling a complex AI system “trustworthy ”prior\n",
      "to placing it on the market.\n",
      "We limit our analysis to the use of AI in public institutions. The potential of AI for the public sector is rap-\n",
      "\n",
      "---\n",
      "\n",
      "blishing trustworthiness in public sector AI systems. This preference is visible in the importance attached to pub-\n",
      "lic accountability, informed consent, and the public communication of the use and failures of AI. This creates\n",
      "some tension with the expertocratic model of risk regulation pursued in the AI Act (see Section 2.3).\n",
      "Nevertheless, there appears to be consensus in the literature that well-placed trust in AI systems in the public\n",
      "\n",
      "---\n",
      "\n",
      "regulation is more likely to also in ﬂuence trust on AI (e.g., regulating the types of tasks that AI may ful ﬁll) and those where\n",
      "its in ﬂuence on trust is more limited (e.g., measures that increase awareness of complacency and automation biases). Our\n",
      "analysis underscores the critical role of nuanced regulation in shaping the human-automation relationship and offers a\n",
      "targeted approach to policymakers to debate how to streamline regulatory efforts for future AI governance.\n",
      "\n",
      "---\n",
      "\n",
      "significantly on public trust and validation, the government's regulatory and non-regulatory \n",
      "approaches to AI should contribute to public trust in AI by promoting reliable, robust, and \n",
      "trustworthy AI applications. For example, an appropriate regulatory approach that reduces \n",
      "accidents can increase public trust and thereby support the development of industries powered by \n",
      "AI. Regulatory approaches may also be needed to protect reasonable expectations of privacy on\n",
      "\n",
      "---\n",
      "\n",
      "supports the uptake of AI in the domain of justice (European Commission, 2018 ).\n",
      "While making AI trustworthy has garnered substantial political momentum, equal attention needs to be paid\n",
      "to AI ’s potential to erode the trustworthiness of public institutions and, with it, their own ability to produce trust\n",
      "in the population (Bod /C19o,2021 ). Without trust, the public sector risks losing support and compliance by citizens.\n",
      "\n",
      "---\n",
      "\n",
      "impact the trust relationship between a human and an arti ﬁcial agent and are aspects that regulation can shape\n",
      "in a direct manner. In democracies, the legal framework can be amended to address novel issues (e.g., proposed\n",
      "AI Act, see Section 4) and the institutional setting changed according to the needs of society. Regulation thus lays\n",
      "down the way in which interactions occur and determines the underlying characteristics of the environment in\n",
      "which trust relationships emerge.\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "Connecting the Dots in Trustworthy Artificial Intelligence\n",
      "trust; concealed behavioral factors behind the acceptability\n",
      "of risks; and the need for impartial intermediaries.\n",
      "Despitetheseandothercurvesintheroad,regulationcan\n",
      "be an unquestionable driving force to consolidate and put\n",
      "all these diverging voices on the same page. Regulation has\n",
      "favoredconsensusaboutthebenefitsandrestrictionsoftech-\n",
      "nological advances that have evolved faster than expected,\n",
      "\n",
      "---\n",
      "\n",
      "with participants trusting universities more than private companies as developers of AI.\n",
      "As mentioned, the emergence of trust is regularly the result of correlated effects from institutional and inter-\n",
      "personal trust as well as trust in technology itself (cf. Section 3.3). Perceptions of the trustworthiness of AI in the\n",
      "public sector will often depend on institutional trust in government (Chen et al., 2021 ; Chen & Wen, 2021 ). In\n",
      "\n",
      "---\n",
      "\n",
      "for reviewing trust research in the context of AI. The paper then uses those variables for a narrative review of prior research\n",
      "on trust and trustworthiness in AI in the public sector. Finally, it relates the ﬁndings of the review to the EU ’s AI policy. Its\n",
      "prospects to successfully engineer citizen ’s trust are uncertain. There remains a threat of misalignment between levels of actual\n",
      "trust and the trustworthiness of applied AI.\n",
      "\n",
      "---\n",
      "\n",
      "guage of creating “trustworthy AI ”through regulation thus tends to overstate its claim.\n",
      "5.2. Threat of misalignment between trustworthiness and degrees of trust\n",
      "As mentioned, trustworthiness and actual trust levels can be misaligned. Whenever trust in a public institution is\n",
      "lowered after the implementation of a “trustworthy ”AI system, citizens will be disincentivized to rely on the pub-\n",
      "\n",
      "---\n",
      "\n",
      "misguided or, worse, gamed. There remains a threat of misalignment between levels of actual trust and the trust-\n",
      "worthiness of applied AI. The empirical literature further illustrates how domain-speci ﬁc trust in public sector AI\n",
      "is. This casts some doubt on the effectiveness of a horizontal regulatory law such as the AI Act. Even if passed\n",
      "into law, the AI Act proposal thus appears incomplete without further sectoral regulation or standardization.\n",
      "\n",
      "---\n",
      "\n",
      "academia on trust in automation and AI (Glikson & Woolley, 2020 ; Kaur et al., 2022 ; Yang & Wibowo, 2022 )\n",
      "and within the political discourse (HLEG, 2019 ; see Section 4). Particularly, policymakers are fearful that without\n",
      "proper regulation, society will trust AI too little to reap its bene ﬁts or, on the contrary, that society might trust\n",
      "AI too much (especially in case of errors or AI hallucinations). In short, these concerns center around the notion\n",
      "\n",
      "---\n",
      "\n",
      "work suggesting that “a clear regulatory framework would build trust among consumers and \n",
      "businesses in AI, and therefore speed up the uptake of the technology” (European Commission, \n",
      "2020a: 9-10). For this regulatory framework, the Commission proposes ‘a risk-based approach’ \n",
      "that would strike a balance between being “effective to achieve its objectives while not being \n",
      "excessively prescriptive so that it could create a disproportionate burden” (European Commis-\n",
      "\n",
      "---\n",
      "\n",
      "1. The necessity and complexity of AI liability regimes\n",
      "While AI brings promises of economic and social benefits in a vast range of industries and\n",
      "social contexts, its regulation is necessary because of the equally compelling risks posed by\n",
      "AI to individuals and society. Commonly recognised AI risks include the threat to funda-\n",
      "mental rights, such as privacy, and to individual and public safety and interests.19\n",
      "Regulating AI remains complex, however, because of the importance of balancing the\n",
      "\n",
      "---\n",
      "\n",
      "regulation may be appropriate in some cases. Agencies should consider new regulation only \n",
      "after they have decided, in light of the foregoing section and other considerations, that Federal \n",
      "regulation is necessary. \n",
      "1. Public Trust in AI \n",
      "AI is expected to have a positive impact across many sectors of social and economic life, \n",
      "including employment, transportation, education, finance, healthcare, personal security, and\n",
      "\n",
      "---\n",
      "\n",
      "currentmovementsaroundaninternationalregulationand\n",
      "our positioning based on the previous analyses.\n",
      "By bridging the gap from theory (AI Principles, Ethics,\n",
      "andKeyRequirements)topractice(ResponsibleAISystems\n",
      "and Regulation), our holistic view offered in this work aims\n",
      "to ultimately highlight the importance of all these elements\n",
      "in the development and integration of human-centered AI-\n",
      "based systems into the everyday life of humans, in a natural\n",
      "and sustainable way.\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "actual outcomes of AI and citizens ’broader attitude toward the technology will be crucial. Note that citizens ’per-\n",
      "ceptions of a technology and its risks could be vastly different from those of experts. It is the latter, however, who\n",
      "the AI Act tasks with making normative judgments about the acceptability of risks.\n",
      "The AI Act relies on a complex web of trust relationships which it only implicitly and insuf ﬁciently differenti-\n",
      "\n",
      "---\n",
      "\n",
      "linked citizen-consumer trust and innovation goals in a utilitarian manner: “Building an ecosystem of trust …should\n",
      "give citizens the con ﬁdence to take up AI applications and give companies and public organizations the legal certainty\n",
      "to innovate using AI ”(European Commission, 2020, p. 4). Another Commission of ﬁcial summarizes the “trust-creat-\n",
      "ing”role of the regulation ’sh i g h - r i s kf o c u sa sf o l l o w s : “if people do not trust technology, that will slow down its\n",
      "\n",
      "---\n",
      "\n",
      "effects of using an AI to provide public services in these domains. Horizontal regulation such as the AI Act can\n",
      "thus only ever be a ﬁrst step to signaling the trustworthiness of a particular AI system.\n",
      "At the same time, many empirical surveys on people ’s trust in AI will be too generic to provide conclusive\n",
      "evidence on citizens ’trust in a particular AI system deployed in the public sector (O ’Neill, 2012 ). Survey items\n",
      "\n",
      "---\n",
      "\n",
      "of Al on society. Of the four causes, regulation is clearly the strongest\n",
      "driver. This means that if people believed that the Al regulation in place\n",
      "was adequate, then they would have a better opinion on the other three\n",
      "items. In other words, at least according to this survey, the EU\n",
      "Commission has all reasons to focus on the regulation of Al as a way to\n",
      "enhance trust in Al.\n",
      "20. Inglehart, supra note 13.\n",
      "21. Nicole Gillespie et al., Trust in Artificial Intelligence: A Five Country Study, KPMG\n",
      "\n",
      "---\n",
      "\n",
      "Much has been written about the risks posed by artificial intelligence \n",
      "(AI). This article is interested not only in what is known about these \n",
      "risks, but what remains unknown and how that unknowing is and should \n",
      "be approached. By reviewing and expanding on the scientific literature, \n",
      "it explores how social knowledge contributes to the understanding of \n",
      "AI and its regulatory challenges. The analysis is conducted in three steps.\n",
      "\n",
      "---\n",
      "\n",
      "and standard-setting leadership within international fora, governments’ regulatory approaches to secure Trustworthy AI are slowly converging. The question then remains: is this trend desirable?  5. Regulatory Competition: a desirability? Bearing in mind the significant risks that the use of AI can bring forth, for instance in terms of adverse impacts on fundamental rights and democracy, a converging approach towards global requirements that is able to tackle those risks seems to be a welcome\n",
      "\n",
      "---\n",
      "\n",
      "The effort to develop “trustworthy AI ”through regulatory laws such as the AI Act acknowledges a need for AI to\n",
      "be trusted if it is to be widely adopted. This obviously presupposes AI to be a possible object of trust. As men-\n",
      "tioned, some philosophers deny this possibility. In policy, however, trust is considered a key element in relation-\n",
      "ships between humans as well as humans and technology (Robinson, 2020 ). To capture this regulatory intention,\n",
      "\n",
      "---\n",
      "\n",
      "guage of creating “trustworthy AI ”through regulation thus tends to overstate its claim.\n",
      "5.2. Threat of misalignment between trustworthiness and degrees of trust\n",
      "As mentioned, trustworthiness and actual trust levels can be misaligned. Whenever trust in a public institution is\n",
      "lowered after the implementation of a “trustworthy ”AI system, citizens will be disincentivized to rely on the pub-\n",
      "\n",
      "---\n",
      "\n",
      "easily become intertwined, for example when the user provides training data to the developer (de Andrade &\n",
      "Zarra, 2022 ). Moreover, there is no de ﬁned“role”for the addressees or subjects of an AI ’s decision or prediction.\n",
      "Within the limits of our review, these subjects would be the citizens who presumably are expected to trust the AI\n",
      "regulatory system “as a whole. ”This raises questions about the model of risk regulation —paternalistic or\n",
      "participatory —chosen by the European Commission.\n",
      "\n",
      "---\n",
      "\n",
      "blishing trustworthiness in public sector AI systems. This preference is visible in the importance attached to pub-\n",
      "lic accountability, informed consent, and the public communication of the use and failures of AI. This creates\n",
      "some tension with the expertocratic model of risk regulation pursued in the AI Act (see Section 2.3).\n",
      "Nevertheless, there appears to be consensus in the literature that well-placed trust in AI systems in the public\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "important to understand how different governing strategies are interpreted and acted upon by \n",
      "others are also important.\n",
      "To develop relevant regulation of AI demands not only social knowledge about their perva -\n",
      "siveness, economic embeddedness and fragmented regulatory response, but a social \n",
      "non-knowledge that is attuned to their complexity, and inhuman and incomprehensible\n",
      "\n",
      "---\n",
      "\n",
      "contribution to the regulation of AI.\n",
      "Social knowledge of AI risks\n",
      "Alongside the recent resurgence of AI, there has been a rise in public perception of AI risks \n",
      "(Neri and Cozman 2020 ), and academic literature promoting safer and fairer AI (e.g., Scherer \n",
      "2016 ; Boddington 2017 ; Corbett-Davies and Goel 2018 ; Benjamin 2019 ). This interest in risk \n",
      "and risk management varies from the mundane to the speculative. Philosopher Nick Bostrom\n",
      "\n",
      "---\n",
      "\n",
      "affects its ability to perform well (Nye Jr., 1997 ). Part of the relevant empirical research proceeds under the rea-\n",
      "sonable assumption that AI needs to add some value to citizens to be accepted. Worsening performance can\n",
      "diminish the perceived value of a public service and can further hurt the institution ’s legitimacy. However, if citi-\n",
      "zens begin to trust AI, then discriminatory and normatively “untrustworthy ”AI practices may be perceived to be\n",
      "\n",
      "---\n",
      "\n",
      "comes ”(Harrison & Luna-Reyes, 2020 , p. 505). While including users and those affected by AI ’s decision-mak-\n",
      "ing, the paper does not clarify how the feedback from non-experts can be utilized so that it increases public trust\n",
      "which is actually justi ﬁable. The authors point to a lack in the literature, as at their time of writing there was little\n",
      "empirical research on how to best implement a participatory model for AI governance (Harrison & Luna-\n",
      "Reyes, 2020 , p. 506).9\n",
      "\n",
      "---\n",
      "\n",
      "research by Kennedy et al., the primary object of trust is thus the AI technology. However, the study also tests\n",
      "the variation in the degree of initial public trust in AI chatbots relative to the public trust in human administra-\n",
      "tors (Aoki, 2021 , p. 4), thus providing insights into the changes in perceived trust once the technology is being\n",
      "introduced to an institution. Aoki ﬁnds that the public ’s trust in AI chatbots is lower for some areas of enquiry\n",
      "\n",
      "---\n",
      "\n",
      "13 optimal regulatory measures to accomplish the sought-after aims. Furthermore, under this reasoning, regulatory subjects preferring different aims or regulations can switch towards the regime most suitable to them, akin to a consumer’s choice on the market. As governments avidly look for the most appropriate regulation to ensure Trustworthy AI – enabling the technology to deliver its promised benefits while minimising its risks – regulatory competition leading to an outcome with the best\n",
      "\n",
      "---\n",
      "\n",
      "widely recognized as an important factor of the perceived acceptability of such risks (Freudenburg, 1993 ;\n",
      "Poortinga & Pidgeon, 2005 , p. 199).\n",
      "This close link between trust, risk regulation, and the perceived acceptability of risks has consequences for the\n",
      "AI Act. Empirical research suggests that trust in institutions is strongly correlated with the perception and accept-\n",
      "ability of risks (Poortinga & Pidgeon, 2005 , p. 200). There is, however, less clarity on the causal relationships\n",
      "\n",
      "---\n",
      "\n",
      "will revisit soon (see Sections 2.3and 5.4). Before that, we will shed light on how the AI Act ’s“risk-based\n",
      "approach ”has important implications for its ability to engineer citizens ’actual trust in AI.\n",
      "2.2. Trust, acceptability, and the regulation of risks\n",
      "Trust is an important topic in risk research (Poortinga & Pidgeon, 2005 , p. 199). Risk scholars address the public\n",
      "sector ’s special role in the reduction of risks based on the states ’duty to protect its citizens from harm (Poortinga\n",
      "\n",
      "---\n",
      "\n",
      "citizens perceive as having improved.\n",
      "Results were further shown to be domain speci ﬁc. Where emotional factors matter such as in parental sup-\n",
      "port, AI in public institutions will likely be trusted less. Some of the normative desiderata of trustworthiness were\n",
      "found to have only small effects, namely the communication of the reasons for the use of AI (except when fail-\n",
      "ures are communicated), transparency, and technological literacy. Future research should thoroughly test these\n",
      "\n",
      "---\n",
      "\n",
      "As regards the AI Act, this raises the question of who is going to be the primary user of AI in public institutions\n",
      "(see Section 2.2). Technology which public servants perceive as useful and user-friendly may not be perceives as\n",
      "such by citizens.\n",
      "4.3.4. Political economy\n",
      "Lastly, the political economy of AI was also considered in the reviewed empirical literature. In a survey on US-\n",
      "American residents, Zhang and Dafoe ﬁnd that Americans have only low to moderate levels of trust in govern-\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "an early stage. AI may not be a new technology92, but the increasingly pervasive use thereof is still relatively new. Furthermore, the impacts it can have on us as individuals, groups and societies – and particularly the negative ones – in the shorter and longer term are still uncertain and not yet fully understood. Just as we are still struggling to grasp those impacts, we are also still struggling to understand how regulation – in its broadest sense – can help us deal therewith and what its\n",
      "\n",
      "---\n",
      "\n",
      "important to understand how different governing strategies are interpreted and acted upon by \n",
      "others are also important.\n",
      "To develop relevant regulation of AI demands not only social knowledge about their perva -\n",
      "siveness, economic embeddedness and fragmented regulatory response, but a social \n",
      "non-knowledge that is attuned to their complexity, and inhuman and incomprehensible\n",
      "\n",
      "---\n",
      "\n",
      "with the public about the benefits and risks of AI in a manner that promotes public trust and \n",
      "understanding of AI. An important opportunity to do this is when publishing requests for \n",
      "information (RFis) in the Federal Register that are related to AI. RFis and similar notices can \n",
      "help ensure that public perceptions of AI are informed by agency risk assessments that are \n",
      "context-specific and based on sound scientific evidence. Agencies should communicate this\n",
      "\n",
      "---\n",
      "\n",
      "blishing trustworthiness in public sector AI systems. This preference is visible in the importance attached to pub-\n",
      "lic accountability, informed consent, and the public communication of the use and failures of AI. This creates\n",
      "some tension with the expertocratic model of risk regulation pursued in the AI Act (see Section 2.3).\n",
      "Nevertheless, there appears to be consensus in the literature that well-placed trust in AI systems in the public\n",
      "\n",
      "---\n",
      "\n",
      "The effort to develop “trustworthy AI ”through regulatory laws such as the AI Act acknowledges a need for AI to\n",
      "be trusted if it is to be widely adopted. This obviously presupposes AI to be a possible object of trust. As men-\n",
      "tioned, some philosophers deny this possibility. In policy, however, trust is considered a key element in relation-\n",
      "ships between humans as well as humans and technology (Robinson, 2020 ). To capture this regulatory intention,\n",
      "\n",
      "---\n",
      "\n",
      "evidence on citizens ’trust in a particular AI system deployed in the public sector (O ’Neill, 2012 ). Survey items\n",
      "such as “I trust the AI science community to do what is right ”(Chen & Wen, 2021 , p. 122) are not differentiating\n",
      "between which members of the AI science community the respondent trusts and to which degree. The policy lan-\n",
      "guage of creating “trustworthy AI ”through regulation thus tends to overstate its claim.\n",
      "\n",
      "---\n",
      "\n",
      "citizens perceive as having improved.\n",
      "Results were further shown to be domain speci ﬁc. Where emotional factors matter such as in parental sup-\n",
      "port, AI in public institutions will likely be trusted less. Some of the normative desiderata of trustworthiness were\n",
      "found to have only small effects, namely the communication of the reasons for the use of AI (except when fail-\n",
      "ures are communicated), transparency, and technological literacy. Future research should thoroughly test these\n",
      "\n",
      "---\n",
      "\n",
      "proposing in the field of Artificial Intelligence is to \"increment trust in\n",
      "the use of artificial intelligence.\"1 Therefore, this paper explores the\n",
      "issue of trust and Al. The questions that it attempts to answer are the\n",
      "following. Why is trust important? Why is trust important, in\n",
      "particular, in the domain of Al? How does the EU Commission intend to\n",
      "achieve the objective of incrementing trust in the use of Al? Will the\n",
      "proposed regulatory framework achieve its proclaimed end?\n",
      "\n",
      "---\n",
      "\n",
      "roll-out of safe AI systems and build trust among potential users. ”2\n",
      "The drivers behind the focus on trust in automation,3and more speci ﬁcally in AI, are plentiful: The rapid\n",
      "development of AI-based tools and embodiment of technology (e.g., within social robots) has changed our rela-\n",
      "tionship with technology. Today, technological artifacts are more and more perceived as “interaction partners ”or\n",
      "\n",
      "---\n",
      "\n",
      "research by Kennedy et al., the primary object of trust is thus the AI technology. However, the study also tests\n",
      "the variation in the degree of initial public trust in AI chatbots relative to the public trust in human administra-\n",
      "tors (Aoki, 2021 , p. 4), thus providing insights into the changes in perceived trust once the technology is being\n",
      "introduced to an institution. Aoki ﬁnds that the public ’s trust in AI chatbots is lower for some areas of enquiry\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "these relevant risk factors. Fourth, for some funda -\n",
      "mental societal values such as the common good, not \n",
      "enough research, consolidated knowledge and above \n",
      "all public discourse and consensus with regard to AI \n",
      "applications are available to select appropriate inter -\n",
      "pretations and speciﬁcations for regulating the risks \n",
      "of AI applications.\n",
      "Necessary Normative Choices in the Design \n",
      "of Risk Regulation\n",
      "Designing risk regulation, including risk assessment\n",
      "\n",
      "---\n",
      "\n",
      "will revisit soon (see Sections 2.3and 5.4). Before that, we will shed light on how the AI Act ’s“risk-based\n",
      "approach ”has important implications for its ability to engineer citizens ’actual trust in AI.\n",
      "2.2. Trust, acceptability, and the regulation of risks\n",
      "Trust is an important topic in risk research (Poortinga & Pidgeon, 2005 , p. 199). Risk scholars address the public\n",
      "sector ’s special role in the reduction of risks based on the states ’duty to protect its citizens from harm (Poortinga\n",
      "\n",
      "---\n",
      "\n",
      "As regards the AI Act, this raises the question of who is going to be the primary user of AI in public institutions\n",
      "(see Section 2.2). Technology which public servants perceive as useful and user-friendly may not be perceives as\n",
      "such by citizens.\n",
      "4.3.4. Political economy\n",
      "Lastly, the political economy of AI was also considered in the reviewed empirical literature. In a survey on US-\n",
      "American residents, Zhang and Dafoe ﬁnd that Americans have only low to moderate levels of trust in govern-\n",
      "\n",
      "---\n",
      "\n",
      "and the legal and ethical principles of society are not con-\n",
      "travened. As we are still very much in the innovation stage,\n",
      "it is also clear that the regulations we put in place now will\n",
      "be subject to ongoing review and adaptation.\n",
      "Why do we need regulation?\n",
      "Key potential harms caused by AI which are regularly cited\n",
      "are bias and consequent discrimination, the trustworthiness\n",
      "of decisions rendered by AI and ML technologies, data\n",
      "privacy and protection, and the threat of cybercrime.\n",
      "\n",
      "---\n",
      "\n",
      "work suggesting that “a clear regulatory framework would build trust among consumers and \n",
      "businesses in AI, and therefore speed up the uptake of the technology” (European Commission, \n",
      "2020a: 9-10). For this regulatory framework, the Commission proposes ‘a risk-based approach’ \n",
      "that would strike a balance between being “effective to achieve its objectives while not being \n",
      "excessively prescriptive so that it could create a disproportionate burden” (European Commis-\n",
      "\n",
      "---\n",
      "\n",
      "across the literature dif ﬁcult, even more so than in the normative batch of papers.\n",
      "Second, initial research on the acceptance of AI in the public sector suggests that AI is perceived differently\n",
      "from existing software systems, not least because of its recognized ability to circumstantially adapt its behavior\n",
      "(Gesk & Leyer, 2022 , p. 3). Moreover, trust in public institutions is closely linked to their perceived legitimacy.\n",
      "\n",
      "---\n",
      "\n",
      "•RQ1: Under what circumstances would the AI Act be able to foster citizens ’well-placed trust in AI?\n",
      "•RQ2: Are there additional requirements of trustworthiness which have not been properly accounted for by\n",
      "the EU ’s regulatory approach towards AI?\n",
      "As outlined in the introduction, our interest lies with AI implemented in the public sector. Answering these ques-\n",
      "tions requires engaging with the complex state of trust research. As a ﬁrst step of our review, we ﬁrst propose a\n",
      "\n",
      "---\n",
      "\n",
      "This article therefore aims to provide an intervention into the EU ’s policy effort to develop “trustworthy AI ”by\n",
      "risk regulation based on a review of the multi-disciplinary literature on trust. Instead of working out a coherent\n",
      "theory of trust, it aims to demonstrate the conceptual futility of labeling a complex AI system “trustworthy ”prior\n",
      "to placing it on the market.\n",
      "We limit our analysis to the use of AI in public institutions. The potential of AI for the public sector is rap-\n",
      "\n",
      "---\n",
      "\n",
      "an early stage. AI may not be a new technology92, but the increasingly pervasive use thereof is still relatively new. Furthermore, the impacts it can have on us as individuals, groups and societies – and particularly the negative ones – in the shorter and longer term are still uncertain and not yet fully understood. Just as we are still struggling to grasp those impacts, we are also still struggling to understand how regulation – in its broadest sense – can help us deal therewith and what its\n",
      "\n",
      "---\n",
      "\n",
      "Secondly, the Commission assumes that its tight regulation of high-risk AI systems —and the simultaneous out-\n",
      "lawing of a few extreme cases of unacceptable risks —cangenerate higher trust levels among citizens who “will be more\n",
      "ready to accept AI ”so long the regulation offers “something to believe in ”(IP-04). The 2020 White Paper already\n",
      "linked citizen-consumer trust and innovation goals in a utilitarian manner: “Building an ecosystem of trust …should\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "1. Introduction\n",
      "We need to understand the possibilities and limitations of AI systems as a means to build the future\n",
      "we want. AI High Level Expert Group (2019, p. 15)\n",
      "By striving towards human-centric AI based on trust, we safeguard the respect for our core societal values and\n",
      "carve out a distinctive trademark for Europe and its industry as a leader in cutting-edge AI that can be trusted\n",
      "throughout the world. European Commission (2019, p. 9)\n",
      "\n",
      "---\n",
      "\n",
      "is ever more highlighted as a component that can be such deal-breaker – after all, who wishes to invest in or use a technology that cannot be trusted? Furthermore, the lack of trust in AI-systems hampers their uptake and hence their potentially benefits. Therefore, the adoption of regulation to ensure ‘Trustworthy AI’ through various regulatory modalities is prominently on governments’ agenda as one of the most direct tools to shape AI stakeholders’ behaviour.43 The concept of Trustworthy AI is\n",
      "\n",
      "---\n",
      "\n",
      "attempt to signal the trustworthiness of AI through its pro-\n",
      "posed regulation: the uncertainty about the antecedents of\n",
      "perceivedtrustinpublicinstitutionsthatutilizeAI;thethreat\n",
      "of misalignment between trustworthiness and degrees of\n",
      "N. Díaz-Rodríguez, J. Del Ser et al.: Preprint submitted to Elsevier Page 25 of 30\n",
      "\n",
      "---\n",
      "\n",
      "theworldofAI,withinterestintrustworthyAIfromaholis-\n",
      "ticperspective.Awell-roundedanalysisofwhattrustmeans\n",
      "in AI-based systems and its requirements as the one offered\n",
      "in this manuscript is a key for the design and development\n",
      "of responsible AI systems throughout their life cycle. We\n",
      "should not regulate scientific progress, but rather products\n",
      "and its usage. As we emphasize in this paper, regulation\n",
      "is the key for consensus, and for this purpose, trustworthy\n",
      "\n",
      "---\n",
      "\n",
      "will revisit soon (see Sections 2.3and 5.4). Before that, we will shed light on how the AI Act ’s“risk-based\n",
      "approach ”has important implications for its ability to engineer citizens ’actual trust in AI.\n",
      "2.2. Trust, acceptability, and the regulation of risks\n",
      "Trust is an important topic in risk research (Poortinga & Pidgeon, 2005 , p. 199). Risk scholars address the public\n",
      "sector ’s special role in the reduction of risks based on the states ’duty to protect its citizens from harm (Poortinga\n",
      "\n",
      "---\n",
      "\n",
      "thiness of AI through its proposed regulation.\n",
      "5.1. Uncertain antecedents of trust\n",
      "Much remains unknown about the antecedents of perceived trust in public institutions which utilize AI. As men-\n",
      "tioned, not a single study in the reviewed empirical sample has been conducted with EU citizen participants. Of\n",
      "\n",
      "---\n",
      "\n",
      "thus needed.\n",
      "Finally, the AI Act ’s conceptual con ﬂation conceals the need for trustworthy institutions to successfully engineer\n",
      "citizens ’trust in AI. Take the knowledge asymmetries between AI experts and layperson citizens as an example.\n",
      "Average citizens ’lack of understanding how AI systems work may motivate risk regulation which relies heavily on\n",
      "expert judgments, although the broader literature on risk regulation has been debating the paternalistic ﬂavor of this\n",
      "\n",
      "---\n",
      "\n",
      "the tripartite propositions-regulation-trust relation.\n",
      "5. Conclusion\n",
      "The term “trustworthy AI ”has entered the regulatory discourse (HLEG, 2019 ). With it, numerous discussions on\n",
      "how to ensure trustworthy AI and enable trusting intelligent machines have emerged. Such discussions are not\n",
      "surprising in light of the technological advances and shifts in perception of AI: With more and more arti ﬁcial\n",
      "\n",
      "---\n",
      "\n",
      "in the empirical literature. Moreover, trust proves to be context-dependent.\n",
      "The proposed AI Act aims to harmonize regulation for all AI systems by establishing a layered regulatory\n",
      "structure for different levels of risk. Obviously, legislation with such a wide scope needs to remain highly general.\n",
      "It will hardly be sensitive enough to the differential degrees to which citizens would want particular public ser-\n",
      "\n",
      "---\n",
      "\n",
      "average citizen and the ambiguous effects which measures such as transparency can have. The empirical literature\n",
      "is less coherent. However, it contains ample support for humans remaining in the AI-supported decision loop.\n",
      "Trust, however, does not always emerge out of citizens ’rational deliberation. Human trust in AI could thus be\n",
      "misguided or, worse, gamed. There remains a threat of misalignment between levels of actual trust and the trust-\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "and other) consequences that may ensue from their (non-)intervention. When conducting such exercise regarding the opportunities and risks raised by AI, regulators face a number of challenges, which will be briefly touched upon here below.  2.2 Regulating AI - Not a walk in the park Over the last years, AI has drawn significant attention from researchers, companies, investors, governments and – thanks to quite some media attention22 – increasingly also citizens. Yet despite all this attention,\n",
      "\n",
      "---\n",
      "\n",
      "misguided or, worse, gamed. There remains a threat of misalignment between levels of actual trust and the trust-\n",
      "worthiness of applied AI. The empirical literature further illustrates how domain-speci ﬁc trust in public sector AI\n",
      "is. This casts some doubt on the effectiveness of a horizontal regulatory law such as the AI Act. Even if passed\n",
      "into law, the AI Act proposal thus appears incomplete without further sectoral regulation or standardization.\n",
      "\n",
      "---\n",
      "\n",
      "effects of using an AI to provide public services in these domains. Horizontal regulation such as the AI Act can\n",
      "thus only ever be a ﬁrst step to signaling the trustworthiness of a particular AI system.\n",
      "At the same time, many empirical surveys on people ’s trust in AI will be too generic to provide conclusive\n",
      "evidence on citizens ’trust in a particular AI system deployed in the public sector (O ’Neill, 2012 ). Survey items\n",
      "\n",
      "---\n",
      "\n",
      "these relevant risk factors. Fourth, for some funda -\n",
      "mental societal values such as the common good, not \n",
      "enough research, consolidated knowledge and above \n",
      "all public discourse and consensus with regard to AI \n",
      "applications are available to select appropriate inter -\n",
      "pretations and speciﬁcations for regulating the risks \n",
      "of AI applications.\n",
      "Necessary Normative Choices in the Design \n",
      "of Risk Regulation\n",
      "Designing risk regulation, including risk assessment\n",
      "\n",
      "---\n",
      "\n",
      "significantly on public trust and validation, the government's regulatory and non-regulatory \n",
      "approaches to AI should contribute to public trust in AI by promoting reliable, robust, and \n",
      "trustworthy AI applications. For example, an appropriate regulatory approach that reduces \n",
      "accidents can increase public trust and thereby support the development of industries powered by \n",
      "AI. Regulatory approaches may also be needed to protect reasonable expectations of privacy on\n",
      "\n",
      "---\n",
      "\n",
      "ing”role of the regulation ’sh i g h - r i s kf o c u sa sf o l l o w s : “if people do not trust technology, that will slow down its\n",
      "uptake …it is important that people think: okay, the way in wh ich AI is developed and used in Europe is properly\n",
      "regulated, so we can trust that this is okay ”(IP-02). A more critical member of the AIHLEG sees a subordination of\n",
      "rights protection to innovation goals in the Commission ’sd eﬁnition of “trustworthy ”AI:“The industry is preparing a\n",
      "\n",
      "---\n",
      "\n",
      "Much has been written about the risks posed by artificial intelligence \n",
      "(AI). This article is interested not only in what is known about these \n",
      "risks, but what remains unknown and how that unknowing is and should \n",
      "be approached. By reviewing and expanding on the scientific literature, \n",
      "it explores how social knowledge contributes to the understanding of \n",
      "AI and its regulatory challenges. The analysis is conducted in three steps.\n",
      "\n",
      "---\n",
      "\n",
      "with the public about the benefits and risks of AI in a manner that promotes public trust and \n",
      "understanding of AI. An important opportunity to do this is when publishing requests for \n",
      "information (RFis) in the Federal Register that are related to AI. RFis and similar notices can \n",
      "help ensure that public perceptions of AI are informed by agency risk assessments that are \n",
      "context-specific and based on sound scientific evidence. Agencies should communicate this\n",
      "\n",
      "---\n",
      "\n",
      "advantage of providing holistic , contextualised  \n",
      "insights into the development of  trust in AI systems \n",
      "over time . This is likely to provide a more systemic \n",
      "understanding of hitherto underexplored areas such as how st akeholder groups converge and diverge in \n",
      "relation to the ir vulnerabilities , expectations and trust \n",
      "in AI.  \n",
      "It is evident from our review that although several \n",
      "trust challenges  have been raised , many  have not been \n",
      "examined empirically , and few have been examined\n",
      "\n",
      "---\n",
      "\n",
      "guage of creating “trustworthy AI ”through regulation thus tends to overstate its claim.\n",
      "5.2. Threat of misalignment between trustworthiness and degrees of trust\n",
      "As mentioned, trustworthiness and actual trust levels can be misaligned. Whenever trust in a public institution is\n",
      "lowered after the implementation of a “trustworthy ”AI system, citizens will be disincentivized to rely on the pub-\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "advantage of providing holistic , contextualised  \n",
      "insights into the development of  trust in AI systems \n",
      "over time . This is likely to provide a more systemic \n",
      "understanding of hitherto underexplored areas such as how st akeholder groups converge and diverge in \n",
      "relation to the ir vulnerabilities , expectations and trust \n",
      "in AI.  \n",
      "It is evident from our review that although several \n",
      "trust challenges  have been raised , many  have not been \n",
      "examined empirically , and few have been examined\n",
      "\n",
      "---\n",
      "\n",
      "guage of creating “trustworthy AI ”through regulation thus tends to overstate its claim.\n",
      "5.2. Threat of misalignment between trustworthiness and degrees of trust\n",
      "As mentioned, trustworthiness and actual trust levels can be misaligned. Whenever trust in a public institution is\n",
      "lowered after the implementation of a “trustworthy ”AI system, citizens will be disincentivized to rely on the pub-\n",
      "\n",
      "---\n",
      "\n",
      "As regards the AI Act, this raises the question of who is going to be the primary user of AI in public institutions\n",
      "(see Section 2.2). Technology which public servants perceive as useful and user-friendly may not be perceives as\n",
      "such by citizens.\n",
      "4.3.4. Political economy\n",
      "Lastly, the political economy of AI was also considered in the reviewed empirical literature. In a survey on US-\n",
      "American residents, Zhang and Dafoe ﬁnd that Americans have only low to moderate levels of trust in govern-\n",
      "\n",
      "---\n",
      "\n",
      "average citizen and the ambiguous effects which measures such as transparency can have. The empirical literature\n",
      "is less coherent. However, it contains ample support for humans remaining in the AI-supported decision loop.\n",
      "Trust, however, does not always emerge out of citizens ’rational deliberation. Human trust in AI could thus be\n",
      "misguided or, worse, gamed. There remains a threat of misalignment between levels of actual trust and the trust-\n",
      "\n",
      "---\n",
      "\n",
      "adequacy of AI regulation and governance to be the\n",
      "strongest predictor of trust in AI systems [ 94]. It may\n",
      "be more important and ef ficient  to make AI systems\n",
      "verifiably trustworthy via appropriate governance\n",
      "rather than seek explanations for specific outcomes\n",
      "[45]. Governance that  encourages collaboration\n",
      "among key stakeholders , supports the recognition and\n",
      "removal of bia s, and clarifies  the appropriate control\n",
      "over and use of personal information has been\n",
      "\n",
      "---\n",
      "\n",
      "13 optimal regulatory measures to accomplish the sought-after aims. Furthermore, under this reasoning, regulatory subjects preferring different aims or regulations can switch towards the regime most suitable to them, akin to a consumer’s choice on the market. As governments avidly look for the most appropriate regulation to ensure Trustworthy AI – enabling the technology to deliver its promised benefits while minimising its risks – regulatory competition leading to an outcome with the best\n",
      "\n",
      "---\n",
      "\n",
      "research by Kennedy et al., the primary object of trust is thus the AI technology. However, the study also tests\n",
      "the variation in the degree of initial public trust in AI chatbots relative to the public trust in human administra-\n",
      "tors (Aoki, 2021 , p. 4), thus providing insights into the changes in perceived trust once the technology is being\n",
      "introduced to an institution. Aoki ﬁnds that the public ’s trust in AI chatbots is lower for some areas of enquiry\n",
      "\n",
      "---\n",
      "\n",
      "work suggesting that “a clear regulatory framework would build trust among consumers and \n",
      "businesses in AI, and therefore speed up the uptake of the technology” (European Commission, \n",
      "2020a: 9-10). For this regulatory framework, the Commission proposes ‘a risk-based approach’ \n",
      "that would strike a balance between being “effective to achieve its objectives while not being \n",
      "excessively prescriptive so that it could create a disproportionate burden” (European Commis-\n",
      "\n",
      "---\n",
      "\n",
      "academia on trust in automation and AI (Glikson & Woolley, 2020 ; Kaur et al., 2022 ; Yang & Wibowo, 2022 )\n",
      "and within the political discourse (HLEG, 2019 ; see Section 4). Particularly, policymakers are fearful that without\n",
      "proper regulation, society will trust AI too little to reap its bene ﬁts or, on the contrary, that society might trust\n",
      "AI too much (especially in case of errors or AI hallucinations). In short, these concerns center around the notion\n",
      "\n",
      "---\n",
      "\n",
      "to grasp those impacts, we are also still struggling to understand how regulation – in its broadest sense – can help us deal therewith and what its effects will be. In its policy recommendations, the European Commission’s High-Level Expert Group on AI described it as follows: ‘[…] little evidence is available to inform policy-making, due to the novelty of the technology, the lack of thorough and systematic understanding of its impacts and associated business models, and the unpredictability of\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Number of possible relevant text chunks found with a threshold similarity of 0.8: 88\n",
      "Query: Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "significantly on public trust and validation, the government's regulatory and non-regulatory \n",
      "approaches to AI should contribute to public trust in AI by promoting reliable, robust, and \n",
      "trustworthy AI applications. For example, an appropriate regulatory approach that reduces \n",
      "accidents can increase public trust and thereby support the development of industries powered by \n",
      "AI. Regulatory approaches may also be needed to protect reasonable expectations of privacy on\n",
      "\n",
      "---\n",
      "\n",
      "it explores how social knowledge contributes to the understanding of \n",
      "AI and its regulatory challenges. The analysis is conducted in three steps. \n",
      "First, the article investigates risks associated with AI and shows how \n",
      "social scientists have challenged technically-oriented approaches that \n",
      "treat the social instrumentally. It then identifies the invisible and visible \n",
      "characteristics of AI, and argues that not only is it hard for outsiders to\n",
      "\n",
      "---\n",
      "\n",
      "et al., 2002 , p. 2425).\n",
      "For the AI Act as a piece of risk regulation which aims to foster trust in AI, both causal relationships hold\n",
      "important implications. First, if trust in institutions determines the acceptability of AI ’s risks, then the AI Act\n",
      "itself needs to be trusted to be successful. Second, if the perceived acceptability of risk determines trust, then the\n",
      "actual outcomes of AI and citizens ’broader attitude toward the technology will be crucial. Note that citizens ’per-\n",
      "\n",
      "---\n",
      "\n",
      "is ever more highlighted as a component that can be such deal-breaker – after all, who wishes to invest in or use a technology that cannot be trusted? Furthermore, the lack of trust in AI-systems hampers their uptake and hence their potentially benefits. Therefore, the adoption of regulation to ensure ‘Trustworthy AI’ through various regulatory modalities is prominently on governments’ agenda as one of the most direct tools to shape AI stakeholders’ behaviour.43 The concept of Trustworthy AI is\n",
      "\n",
      "---\n",
      "\n",
      "impact the trust relationship between a human and an arti ﬁcial agent and are aspects that regulation can shape\n",
      "in a direct manner. In democracies, the legal framework can be amended to address novel issues (e.g., proposed\n",
      "AI Act, see Section 4) and the institutional setting changed according to the needs of society. Regulation thus lays\n",
      "down the way in which interactions occur and determines the underlying characteristics of the environment in\n",
      "which trust relationships emerge.\n",
      "\n",
      "---\n",
      "\n",
      "Nevertheless, there appears to be consensus in the literature that well-placed trust in AI systems in the public\n",
      "sector requires institutions of public accountability. Participation, however, faces knowledge asymmetries between\n",
      "laypeople citizens and AI developers/users. The suggestion to develop a behavioral notion of “trust-based ”con-\n",
      "sent resembles approaches in the philosophical literature which aim to address knowledge asymmetries between\n",
      "\n",
      "---\n",
      "\n",
      "misguided or, worse, gamed. There remains a threat of misalignment between levels of actual trust and the trust-\n",
      "worthiness of applied AI. The empirical literature further illustrates how domain-speci ﬁc trust in public sector AI\n",
      "is. This casts some doubt on the effectiveness of a horizontal regulatory law such as the AI Act. Even if passed\n",
      "into law, the AI Act proposal thus appears incomplete without further sectoral regulation or standardization.\n",
      "\n",
      "---\n",
      "\n",
      "and standard-setting leadership within international fora, governments’ regulatory approaches to secure Trustworthy AI are slowly converging. The question then remains: is this trend desirable?  5. Regulatory Competition: a desirability? Bearing in mind the significant risks that the use of AI can bring forth, for instance in terms of adverse impacts on fundamental rights and democracy, a converging approach towards global requirements that is able to tackle those risks seems to be a welcome\n",
      "\n",
      "---\n",
      "\n",
      "to grasp those impacts, we are also still struggling to understand how regulation – in its broadest sense – can help us deal therewith and what its effects will be. In its policy recommendations, the European Commission’s High-Level Expert Group on AI described it as follows: ‘[…] little evidence is available to inform policy-making, due to the novelty of the technology, the lack of thorough and systematic understanding of its impacts and associated business models, and the unpredictability of\n",
      "\n",
      "---\n",
      "\n",
      "an early stage. AI may not be a new technology92, but the increasingly pervasive use thereof is still relatively new. Furthermore, the impacts it can have on us as individuals, groups and societies – and particularly the negative ones – in the shorter and longer term are still uncertain and not yet fully understood. Just as we are still struggling to grasp those impacts, we are also still struggling to understand how regulation – in its broadest sense – can help us deal therewith and what its\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: \n",
      "Why is it important to study laypersons' perceptions of AI regulation, especially focusing on their trust levels, perceived benefits and risks, and how these perceptions impact the successful integration of AI into society? Please discuss how understanding public perceptions can inform regulatory approaches, enhance public trust, and address potential risks and benefits for society.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "                                        Response LLM  \\\n",
      "0  Studying laypersons' perceptions of AI regulat...   \n",
      "1  Studying laypersons' perceptions of AI regulat...   \n",
      "2  Studying laypersons' perceptions of AI regulat...   \n",
      "3  Studying laypersons' perceptions of AI regulat...   \n",
      "4  Studying laypersons' perceptions of AI regulat...   \n",
      "5  Studying laypersons' perceptions of AI regulat...   \n",
      "6  Studying laypersons' perceptions of AI regulat...   \n",
      "7  Studying laypersons' perceptions of AI regulat...   \n",
      "8  Studying laypersons' perceptions of AI regulat...   \n",
      "9  Studying laypersons' perceptions of AI regulat...   \n",
      "\n",
      "                                      Sources, Pages  \n",
      "0  [(PDFs/AIregulation\\10.1111_rego.12568.pdf, 0)...  \n",
      "1  [(PDFs/AIregulation\\10.48550_arXiv.2305.02231....  \n",
      "2  [(PDFs/AIregulation\\10.1111_rego.12512.pdf, 4)...  \n",
      "3  [(PDFs/AIregulation\\10.1080_13669877.2021.1957...  \n",
      "4  [(PDFs/AIregulation\\10.2139_ssrn.3501410.pdf, ...  \n",
      "5  [(PDFs/AIregulation\\10.1007_s11569-024-00454-9...  \n",
      "6  [(PDFs/AIregulation\\10.1111_rego.12563.pdf, 0)...  \n",
      "7  [(PDFs/AIregulation\\10.2139_ssrn.3501410.pdf, ...  \n",
      "8  [(PDFs/AIregulation\\10.24251_HICSS.2021.664.pd...  \n",
      "9  [(PDFs/AIregulation\\white house_AI.pdf, 2), (P...  \n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Run the function multiple times and store the outputs\n",
    "for _ in range(10):  # Replace 5 with the number of iterations you want to run\n",
    "    response, source_page_pairs, filtered_hits, all_hits = di_drg.retrieveGenerate(query_text=question, prompt_template=PROMPT_TEMPLATE, openAI_key=key.openAI_key, chroma_path=path_to_Chroma, \n",
    "                                                                            docsReturn=10, thresholdSimilarity=0.8)\n",
    "    results.append({\"Response LLM\": response, \"Sources, Pages\": source_page_pairs})\n",
    "\n",
    "# Convert the results list into a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Saving the DataFrame to an Excel file\n",
    "df.to_excel(\"outputs_ChromaApproach/file_LLMs_calls2.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
